{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60bb0afb-b16d-432c-9167-214597e3c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime, itertools\n",
    "from prophet.plot import plot_yearly, plot_weekly, plot_plotly, plot_components_plotly\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f202be27-70ac-4270-9ce0-4ea13df2e2a5",
   "metadata": {},
   "source": [
    "# Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b161fe20-f137-47a2-9f73-0f066cc02cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(\"..\", \"data\")\n",
    "fp = os.path.join(DATA_DIR, \"hydrograph-excel-sheet-tp-cleaned.xlsx\")\n",
    "xl = pd.ExcelFile(fp)\n",
    "gages = xl.sheet_names\n",
    "hydro_data = {s: xl.parse(s) for s in gages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5bfeffd-24ae-417c-978f-4d290a6eae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_sheet(sheet_name: str, src_data: dict):\n",
    "    src_df = src_data[sheet_name]\n",
    "    \n",
    "    # Check lengths of columns, some contain only notes so will be\n",
    "    # much less than 100 and need to be dropped. Most columns\n",
    "    # should have 365/366 values but a few are missing and need to be filled.\n",
    "    col_lengths = {c: sum(src_df[c].notna()) for c in src_df.columns}\n",
    "    keep_cols = [c for c, l in col_lengths.items() if l > 100]\n",
    "    \n",
    "    # Check columns are all in the correct order to combine:\n",
    "    assert \"time\" in keep_cols[0].lower()\n",
    "    correct_order = {\"time\": \"ft\", \"ft\": \"discharge\", \"discharge\": \"time\"}\n",
    "    for i, col in enumerate(keep_cols[:-1]):\n",
    "        next_col = keep_cols[i+1]\n",
    "        for key in correct_order.keys():\n",
    "            if key in col.lower():\n",
    "                should_be = correct_order[key]\n",
    "                assert should_be in next_col.lower(), sheet_name\n",
    "    \n",
    "    # Iterate through columns and collect data:\n",
    "    data_subsets = list()\n",
    "    for start_col in range(0, len(keep_cols), 3):\n",
    "        df_columns = keep_cols[start_col: start_col+3]\n",
    "        subset = src_df[df_columns]\n",
    "        rename = dict(zip(subset.columns, [\"time\", \"ft\", \"m3\"]))\n",
    "        subset = subset.rename(columns=rename).dropna(how=\"all\")\n",
    "        data_subsets.append(subset)\n",
    "        \n",
    "    # Combine to a single df:\n",
    "    final =  pd.concat(data_subsets).reset_index(drop=True)\n",
    "    final[\"gage\"] = sheet_name\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04bf589b-0861-4c39-b06b-33e52e45bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sheets = list()\n",
    "for sname in gages:\n",
    "    all_sheets.append(flatten_sheet(sname, hydro_data)) \n",
    "df = pd.concat(all_sheets).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03c3799e-18a5-4325-bfa5-e99a4c827a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date, max_date = min(df[\"time\"]), max(df[\"time\"])\n",
    "all_dates = [min_date.to_pydatetime()]\n",
    "while all_dates[-1] < max_date:\n",
    "    all_dates.append(all_dates[-1] + datetime.timedelta(days=1))\n",
    "    \n",
    "full_index = list(itertools.product(df[\"gage\"].unique(), all_dates))\n",
    "df = df.set_index([\"gage\", \"time\"])\n",
    "df = df.reindex(full_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6218a26c-40da-4c03-9d86-3b0bd33f27ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "gage_list = df.index.get_level_values('gage').unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07dd5e6a-dc36-4c85-9309-665b53ef6e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11402000',\n",
       " '11318500',\n",
       " '11266500',\n",
       " '11208000',\n",
       " '11202710',\n",
       " '11185500',\n",
       " '11189500']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gage_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00420397-4daa-4d8d-a52e-b8389e96f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gage_ts = df.loc[gage_list[0]].reset_index(drop = False)\n",
    "gage_ts.rename(columns = {'time':'ds', 'ft': 'y'}, inplace = True)\n",
    "min_date = gage_ts['ds'].min()\n",
    "max_date = gage_ts['ds'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0086842-8bac-4fda-9570-aa7ae24bbea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ft</th>\n",
       "      <th>m3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gage</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">11402000</th>\n",
       "      <th>1984-10-01</th>\n",
       "      <td>54.00</td>\n",
       "      <td>1.529110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-10-02</th>\n",
       "      <td>52.00</td>\n",
       "      <td>1.472476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-10-03</th>\n",
       "      <td>49.00</td>\n",
       "      <td>1.387525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-10-04</th>\n",
       "      <td>49.00</td>\n",
       "      <td>1.387525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-10-05</th>\n",
       "      <td>48.00</td>\n",
       "      <td>1.359209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">11189500</th>\n",
       "      <th>2018-09-26</th>\n",
       "      <td>2.86</td>\n",
       "      <td>0.080986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-27</th>\n",
       "      <td>2.78</td>\n",
       "      <td>0.078721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-28</th>\n",
       "      <td>2.99</td>\n",
       "      <td>0.084667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-29</th>\n",
       "      <td>3.12</td>\n",
       "      <td>0.088349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-30</th>\n",
       "      <td>3.34</td>\n",
       "      <td>0.094578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86926 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ft        m3\n",
       "gage     time                       \n",
       "11402000 1984-10-01  54.00  1.529110\n",
       "         1984-10-02  52.00  1.472476\n",
       "         1984-10-03  49.00  1.387525\n",
       "         1984-10-04  49.00  1.387525\n",
       "         1984-10-05  48.00  1.359209\n",
       "...                    ...       ...\n",
       "11189500 2018-09-26   2.86  0.080986\n",
       "         2018-09-27   2.78  0.078721\n",
       "         2018-09-28   2.99  0.084667\n",
       "         2018-09-29   3.12  0.088349\n",
       "         2018-09-30   3.34  0.094578\n",
       "\n",
       "[86926 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00895bc8-c711-4262-b7b7-08700808fa33",
   "metadata": {},
   "source": [
    "# Generate Multivariate Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6610c8e7-5284-4349-bc62-4a97e2beed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "gage_df = df.loc[gage_list[0]].reset_index(drop = False)[['time','ft']]\n",
    "gage_df.rename(columns = {'ft':f'ft_{gage_list[0]}'}, inplace = True)\n",
    "for gage_num in gage_list[1:]:\n",
    "    new_gage_df =  df.loc[gage_num].reset_index(drop = False)[['time','ft']]\n",
    "    new_gage_df.rename(columns = {'ft':f'ft_{gage_num}'}, inplace = True)\n",
    "    gage_df = gage_df.merge(new_gage_df, on = 'time', how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e0fd5df-4025-46ef-8c77-8904a5131766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>ft_11402000</th>\n",
       "      <th>ft_11318500</th>\n",
       "      <th>ft_11266500</th>\n",
       "      <th>ft_11208000</th>\n",
       "      <th>ft_11202710</th>\n",
       "      <th>ft_11185500</th>\n",
       "      <th>ft_11189500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984-10-01</td>\n",
       "      <td>54.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984-10-02</td>\n",
       "      <td>52.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>279.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1984-10-03</td>\n",
       "      <td>49.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>284.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984-10-04</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>291.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984-10-05</td>\n",
       "      <td>48.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  ft_11402000  ft_11318500  ft_11266500  ft_11208000  ft_11202710  \\\n",
       "0 1984-10-01         54.0         10.0         53.0          1.7          NaN   \n",
       "1 1984-10-02         52.0         12.0         52.0          1.4          NaN   \n",
       "2 1984-10-03         49.0         14.0         51.0          1.4          NaN   \n",
       "3 1984-10-04         49.0         13.0         49.0          1.4          NaN   \n",
       "4 1984-10-05         48.0         14.0         46.0          1.4          NaN   \n",
       "\n",
       "   ft_11185500  ft_11189500  \n",
       "0        256.0         39.0  \n",
       "1        279.0         42.0  \n",
       "2        284.0         45.0  \n",
       "3        291.0         47.0  \n",
       "4        281.0         50.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gage_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad2d6d74-5bb0-488a-a4b9-5889b0d4d3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time           0\n",
       "ft_11402000    0\n",
       "ft_11318500    0\n",
       "ft_11266500    0\n",
       "ft_11208000    0\n",
       "ft_11202710    0\n",
       "ft_11185500    0\n",
       "ft_11189500    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most 4 years data seems to have no missing values\n",
    "gage_df.iloc[-365 * 4:].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34ae46aa-fd40-44d4-bec3-2342fed5d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gage_df = gage_df.iloc[-365 * 4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2f7d7a-4049-4003-b914-5904a10e1941",
   "metadata": {},
   "source": [
    "## Baseline Prophet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c54a4a0-a5c8-402a-ab29-2b9ff7b84bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_params = {'seasonality_mode':'multiplicative'}\n",
    "horizon = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4236136-4c81-44d6-8286-d93e6e3e4f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "gage_df.rename(columns = {'time':'ds', 'ft_11402000': 'y'}, inplace = True)\n",
    "gage_train = gage_df.iloc[: -horizon,:]\n",
    "gage_test = gage_df.iloc[-horizon:,:]\n",
    "m = Prophet(**selected_params).fit(gage_train) # **best_params\n",
    "future = m.make_future_dataframe(periods=horizon)\n",
    "forecast = m.predict(future)\n",
    "gage_test['yhat_corrected'] = forecast.iloc[-horizon:]['yhat'].apply(lambda x : max(x,0)).values\n",
    "gage_test['yhat'] = forecast.iloc[-horizon:]['yhat'].values\n",
    "forecast['yhat_corrected'] = forecast['yhat'].apply(lambda x : max(x,0))\n",
    "\n",
    "# gage_test.drop(columns = ['m3'], inplace = True)\n",
    "\n",
    "# if show_plots:\n",
    "#     fig1 = m.plot_components(forecast)\n",
    "#     fig2 = m.plot(forecast)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(gage_test['y'], gage_test['yhat_corrected']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbe5b25e-4688-4f63-a321-07d0ded12f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.947919918866564"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d223fe-03fe-4d79-802e-79491e2b67c5",
   "metadata": {},
   "source": [
    "# Multivariate Seq2Seq Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9f206eee-3cf7-4d0a-9926-28ce43fe1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ff5beff9-e123-4b9a-9aa3-dbdad5401274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_series(series, n_past, n_future):\n",
    "  #\n",
    "  # n_past ==> no of past observations\n",
    "  #\n",
    "  # n_future ==> no of future observations \n",
    "  #\n",
    "    X, y = list(), list()\n",
    "    for window_start in range(len(series)):\n",
    "        past_end = window_start + n_past\n",
    "        future_end = past_end + n_future\n",
    "        if future_end > len(series):\n",
    "            break\n",
    "        # slicing the past and future parts of the window\n",
    "        past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
    "        X.append(past)\n",
    "        y.append(future)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a32bd937-fee6-46c4-9c9e-16e288300bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_past = 28\n",
    "n_future = 14 \n",
    "n_features = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c79e2dc2-263b-4584-9b35-678877147b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gage_df[4:]) * 0.8 // 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5a066f3b-e058-4db8-a4e3-f7c9e05b36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_gage = '11402000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "af0dceed-bf3a-4e99-8b69-38d98fb4d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(gage_df[4:]) * 0.8 // 7)\n",
    "train_df,test_df = gage_df[4:train_size], gage_df[train_size:] \n",
    "\n",
    "\n",
    "feature_cols = [f for f in gage_df.columns if 'ft' in f ]\n",
    "\n",
    "train = train_df[feature_cols]\n",
    "test = test_df[feature_cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e6ed3374-5a07-4671-98d2-d504790ba5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = split_series(train.values,n_past, n_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bc418729-2b65-4c10-b5a6-cb0874a44e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 30. ,  28.6,  27.1, ...,  30.8,  30. ,  28.3],\n",
       "       [ 28.6,  27.1,  28.6, ...,  30. ,  28.3,  28. ],\n",
       "       [ 27.1,  28.6,  27. , ...,  28.3,  28. ,  27.6],\n",
       "       ...,\n",
       "       [117. , 109. , 104. , ...,  84.1,  80.2,  77.3],\n",
       "       [109. , 104. ,  98.3, ...,  80.2,  77.3,  75. ],\n",
       "       [104. ,  98.3,  94.2, ...,  77.3,  75. ,  73. ]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "90b77a12-9cf4-4747-8da9-1dcf3057ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_target_col = 1\n",
    "\n",
    "\n",
    "X_train, y_train = split_series(train.values,n_past, n_future)\n",
    "y_train = y_train[:,:,0]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],n_features))\n",
    "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], num_target_col))\n",
    "X_test, y_test = split_series(test.values,n_past, n_future)\n",
    "y_test = y_test[:,:,0]\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],n_features))\n",
    "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], num_target_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a51f74fd-b420-4f38-b5ad-6d2ad5164279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 28, 7)]      0           []                               \n",
      "                                                                                                  \n",
      " lstm_12 (LSTM)                 [(None, 100),        43200       ['input_5[0][0]']                \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " repeat_vector_4 (RepeatVector)  (None, 14, 100)     0           ['lstm_12[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_13 (LSTM)                 (None, 14, 100)      80400       ['repeat_vector_4[0][0]',        \n",
      "                                                                  'lstm_12[0][1]',                \n",
      "                                                                  'lstm_12[0][2]']                \n",
      "                                                                                                  \n",
      " time_distributed_4 (TimeDistri  (None, 14, 1)       101         ['lstm_13[0][0]']                \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 123,701\n",
      "Trainable params: 123,701\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# E1D1\n",
    "# n_features ==> no of features at each timestep in the data.\n",
    "#\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "encoder_l1 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "\n",
    "#\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs1[0])\n",
    "\n",
    "#\n",
    "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_outputs1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_target_col))(decoder_l1)\n",
    "\n",
    "#\n",
    "model_e1d1 = tf.keras.models.Model(encoder_inputs,decoder_outputs1)\n",
    "\n",
    "#\n",
    "model_e1d1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ae9c99d9-90f3-4ccd-93c6-33fc02bfbc2b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "4/4 - 4s - loss: 207.0541 - val_loss: 301.7996 - lr: 0.0010 - 4s/epoch - 895ms/step\n",
      "Epoch 2/25\n",
      "4/4 - 0s - loss: 205.0027 - val_loss: 300.7076 - lr: 9.0000e-04 - 322ms/epoch - 81ms/step\n",
      "Epoch 3/25\n",
      "4/4 - 0s - loss: 203.2384 - val_loss: 299.5133 - lr: 8.1000e-04 - 316ms/epoch - 79ms/step\n",
      "Epoch 4/25\n",
      "4/4 - 0s - loss: 201.6620 - val_loss: 298.3487 - lr: 7.2900e-04 - 316ms/epoch - 79ms/step\n",
      "Epoch 5/25\n",
      "4/4 - 0s - loss: 200.2641 - val_loss: 297.2867 - lr: 6.5610e-04 - 326ms/epoch - 81ms/step\n",
      "Epoch 6/25\n",
      "4/4 - 0s - loss: 199.0406 - val_loss: 296.3249 - lr: 5.9049e-04 - 321ms/epoch - 80ms/step\n",
      "Epoch 7/25\n",
      "4/4 - 0s - loss: 197.9667 - val_loss: 295.5030 - lr: 5.3144e-04 - 323ms/epoch - 81ms/step\n",
      "Epoch 8/25\n",
      "4/4 - 0s - loss: 197.0508 - val_loss: 294.8387 - lr: 4.7830e-04 - 318ms/epoch - 80ms/step\n",
      "Epoch 9/25\n",
      "4/4 - 0s - loss: 196.2960 - val_loss: 294.2892 - lr: 4.3047e-04 - 318ms/epoch - 80ms/step\n",
      "Epoch 10/25\n",
      "4/4 - 0s - loss: 195.6904 - val_loss: 293.8486 - lr: 3.8742e-04 - 315ms/epoch - 79ms/step\n",
      "Epoch 11/25\n",
      "4/4 - 0s - loss: 195.2005 - val_loss: 293.4990 - lr: 3.4868e-04 - 315ms/epoch - 79ms/step\n",
      "Epoch 12/25\n",
      "4/4 - 0s - loss: 194.8033 - val_loss: 293.1995 - lr: 3.1381e-04 - 320ms/epoch - 80ms/step\n",
      "Epoch 13/25\n",
      "4/4 - 0s - loss: 194.4755 - val_loss: 292.9422 - lr: 2.8243e-04 - 324ms/epoch - 81ms/step\n",
      "Epoch 14/25\n",
      "4/4 - 0s - loss: 194.2018 - val_loss: 292.7354 - lr: 2.5419e-04 - 319ms/epoch - 80ms/step\n",
      "Epoch 15/25\n",
      "4/4 - 0s - loss: 193.9720 - val_loss: 292.5621 - lr: 2.2877e-04 - 322ms/epoch - 81ms/step\n",
      "Epoch 16/25\n",
      "4/4 - 0s - loss: 193.7758 - val_loss: 292.4077 - lr: 2.0589e-04 - 327ms/epoch - 82ms/step\n",
      "Epoch 17/25\n",
      "4/4 - 0s - loss: 193.6074 - val_loss: 292.2808 - lr: 1.8530e-04 - 329ms/epoch - 82ms/step\n",
      "Epoch 18/25\n",
      "4/4 - 0s - loss: 193.4610 - val_loss: 292.1736 - lr: 1.6677e-04 - 317ms/epoch - 79ms/step\n",
      "Epoch 19/25\n",
      "4/4 - 0s - loss: 193.3336 - val_loss: 292.0822 - lr: 1.5009e-04 - 319ms/epoch - 80ms/step\n",
      "Epoch 20/25\n",
      "4/4 - 0s - loss: 193.2223 - val_loss: 292.0005 - lr: 1.3509e-04 - 325ms/epoch - 81ms/step\n",
      "Epoch 21/25\n",
      "4/4 - 0s - loss: 193.1242 - val_loss: 291.9269 - lr: 1.2158e-04 - 345ms/epoch - 86ms/step\n",
      "Epoch 22/25\n",
      "4/4 - 0s - loss: 193.0378 - val_loss: 291.8622 - lr: 1.0942e-04 - 321ms/epoch - 80ms/step\n",
      "Epoch 23/25\n",
      "4/4 - 0s - loss: 192.9619 - val_loss: 291.8077 - lr: 9.8477e-05 - 323ms/epoch - 81ms/step\n",
      "Epoch 24/25\n",
      "4/4 - 0s - loss: 192.8955 - val_loss: 291.7608 - lr: 8.8629e-05 - 325ms/epoch - 81ms/step\n",
      "Epoch 25/25\n",
      "4/4 - 0s - loss: 192.8368 - val_loss: 291.7458 - lr: 7.9766e-05 - 324ms/epoch - 81ms/step\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
    "model_e1d1.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.Huber())\n",
    "history_e1d1=model_e1d1.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),batch_size=32,verbose=2,callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f8f384a0-0383-475f-9628-857ae1a867be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 28, 7)]      0           []                               \n",
      "                                                                                                  \n",
      " lstm_30 (LSTM)                 [(None, 28, 100),    43200       ['input_10[0][0]']               \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " lstm_31 (LSTM)                 [(None, 100),        80400       ['lstm_30[0][0]']                \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " repeat_vector_9 (RepeatVector)  (None, 14, 100)     0           ['lstm_31[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_32 (LSTM)                 (None, 14, 100)      80400       ['repeat_vector_9[0][0]',        \n",
      "                                                                  'lstm_30[0][1]',                \n",
      "                                                                  'lstm_30[0][2]']                \n",
      "                                                                                                  \n",
      " lstm_33 (LSTM)                 (None, 14, 100)      80400       ['lstm_32[0][0]',                \n",
      "                                                                  'lstm_31[0][1]',                \n",
      "                                                                  'lstm_31[0][2]']                \n",
      "                                                                                                  \n",
      " time_distributed_9 (TimeDistri  (None, 14, 1)       101         ['lstm_33[0][0]']                \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 284,501\n",
      "Trainable params: 284,501\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# E2D2\n",
    "# n_features ==> no of features at each timestep in the data.\n",
    "#\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "encoder_l1 = tf.keras.layers.LSTM(100,return_sequences = True, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "encoder_l2 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
    "encoder_states2 = encoder_outputs2[1:]\n",
    "#\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n",
    "#\n",
    "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_l2 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_l1,initial_state = encoder_states2)\n",
    "decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_target_col))(decoder_l2)\n",
    "#\n",
    "model_e2d2 = tf.keras.models.Model(encoder_inputs,decoder_outputs2)\n",
    "#\n",
    "model_e2d2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "792cf2ba-be12-4911-98e8-4f7bb8601870",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 - 8s - loss: 207.4010 - val_loss: 301.0645 - lr: 0.0010 - 8s/epoch - 2s/step\n",
      "Epoch 2/50\n",
      "4/4 - 1s - loss: 204.6772 - val_loss: 298.1414 - lr: 9.0000e-04 - 664ms/epoch - 166ms/step\n",
      "Epoch 3/50\n",
      "4/4 - 1s - loss: 201.9614 - val_loss: 295.4402 - lr: 8.1000e-04 - 647ms/epoch - 162ms/step\n",
      "Epoch 4/50\n",
      "4/4 - 1s - loss: 200.0234 - val_loss: 293.6553 - lr: 7.2900e-04 - 652ms/epoch - 163ms/step\n",
      "Epoch 5/50\n",
      "4/4 - 1s - loss: 198.4533 - val_loss: 292.3246 - lr: 6.5610e-04 - 653ms/epoch - 163ms/step\n",
      "Epoch 6/50\n",
      "4/4 - 1s - loss: 197.1731 - val_loss: 291.3375 - lr: 5.9049e-04 - 651ms/epoch - 163ms/step\n",
      "Epoch 7/50\n",
      "4/4 - 1s - loss: 196.1783 - val_loss: 290.6245 - lr: 5.3144e-04 - 653ms/epoch - 163ms/step\n",
      "Epoch 8/50\n",
      "4/4 - 1s - loss: 195.4269 - val_loss: 290.1049 - lr: 4.7830e-04 - 649ms/epoch - 162ms/step\n",
      "Epoch 9/50\n",
      "4/4 - 1s - loss: 194.8558 - val_loss: 289.7147 - lr: 4.3047e-04 - 652ms/epoch - 163ms/step\n",
      "Epoch 10/50\n",
      "4/4 - 1s - loss: 194.4127 - val_loss: 289.4130 - lr: 3.8742e-04 - 649ms/epoch - 162ms/step\n",
      "Epoch 11/50\n",
      "4/4 - 1s - loss: 194.0622 - val_loss: 289.1747 - lr: 3.4868e-04 - 645ms/epoch - 161ms/step\n",
      "Epoch 12/50\n",
      "4/4 - 1s - loss: 193.7810 - val_loss: 288.9834 - lr: 3.1381e-04 - 646ms/epoch - 161ms/step\n",
      "Epoch 13/50\n",
      "4/4 - 1s - loss: 193.5519 - val_loss: 288.8271 - lr: 2.8243e-04 - 649ms/epoch - 162ms/step\n",
      "Epoch 14/50\n",
      "4/4 - 1s - loss: 193.3620 - val_loss: 288.6970 - lr: 2.5419e-04 - 656ms/epoch - 164ms/step\n",
      "Epoch 15/50\n",
      "4/4 - 1s - loss: 193.2020 - val_loss: 288.5870 - lr: 2.2877e-04 - 650ms/epoch - 162ms/step\n",
      "Epoch 16/50\n",
      "4/4 - 1s - loss: 193.0652 - val_loss: 288.4930 - lr: 2.0589e-04 - 652ms/epoch - 163ms/step\n",
      "Epoch 17/50\n",
      "4/4 - 1s - loss: 192.9471 - val_loss: 288.4118 - lr: 1.8530e-04 - 656ms/epoch - 164ms/step\n",
      "Epoch 18/50\n",
      "4/4 - 1s - loss: 192.8443 - val_loss: 288.3412 - lr: 1.6677e-04 - 650ms/epoch - 163ms/step\n",
      "Epoch 19/50\n",
      "4/4 - 1s - loss: 192.7542 - val_loss: 288.2795 - lr: 1.5009e-04 - 652ms/epoch - 163ms/step\n",
      "Epoch 20/50\n",
      "4/4 - 1s - loss: 192.6749 - val_loss: 288.2253 - lr: 1.3509e-04 - 654ms/epoch - 164ms/step\n",
      "Epoch 21/50\n",
      "4/4 - 1s - loss: 192.6048 - val_loss: 288.1775 - lr: 1.2158e-04 - 660ms/epoch - 165ms/step\n",
      "Epoch 22/50\n",
      "4/4 - 1s - loss: 192.5427 - val_loss: 288.1350 - lr: 1.0942e-04 - 650ms/epoch - 162ms/step\n",
      "Epoch 23/50\n",
      "4/4 - 1s - loss: 192.4875 - val_loss: 288.0974 - lr: 9.8477e-05 - 657ms/epoch - 164ms/step\n",
      "Epoch 24/50\n",
      "4/4 - 1s - loss: 192.4382 - val_loss: 288.0640 - lr: 8.8629e-05 - 649ms/epoch - 162ms/step\n",
      "Epoch 25/50\n",
      "4/4 - 1s - loss: 192.3943 - val_loss: 288.0342 - lr: 7.9766e-05 - 657ms/epoch - 164ms/step\n",
      "Epoch 26/50\n",
      "4/4 - 1s - loss: 192.3551 - val_loss: 288.0077 - lr: 7.1790e-05 - 658ms/epoch - 164ms/step\n",
      "Epoch 27/50\n",
      "4/4 - 1s - loss: 192.3201 - val_loss: 287.9840 - lr: 6.4611e-05 - 654ms/epoch - 163ms/step\n",
      "Epoch 28/50\n",
      "4/4 - 1s - loss: 192.2888 - val_loss: 287.9628 - lr: 5.8150e-05 - 653ms/epoch - 163ms/step\n",
      "Epoch 29/50\n",
      "4/4 - 1s - loss: 192.2607 - val_loss: 287.9438 - lr: 5.2335e-05 - 655ms/epoch - 164ms/step\n",
      "Epoch 30/50\n",
      "4/4 - 1s - loss: 192.2356 - val_loss: 287.9269 - lr: 4.7101e-05 - 656ms/epoch - 164ms/step\n",
      "Epoch 31/50\n",
      "4/4 - 1s - loss: 192.2131 - val_loss: 287.9118 - lr: 4.2391e-05 - 651ms/epoch - 163ms/step\n",
      "Epoch 32/50\n",
      "4/4 - 1s - loss: 192.1929 - val_loss: 287.8982 - lr: 3.8152e-05 - 653ms/epoch - 163ms/step\n",
      "Epoch 33/50\n",
      "4/4 - 1s - loss: 192.1747 - val_loss: 287.8860 - lr: 3.4337e-05 - 654ms/epoch - 164ms/step\n",
      "Epoch 34/50\n",
      "4/4 - 1s - loss: 192.1585 - val_loss: 287.8751 - lr: 3.0903e-05 - 673ms/epoch - 168ms/step\n",
      "Epoch 35/50\n",
      "4/4 - 1s - loss: 192.1440 - val_loss: 287.8652 - lr: 2.7813e-05 - 678ms/epoch - 169ms/step\n",
      "Epoch 36/50\n",
      "4/4 - 1s - loss: 192.1308 - val_loss: 287.8564 - lr: 2.5032e-05 - 656ms/epoch - 164ms/step\n",
      "Epoch 37/50\n",
      "4/4 - 1s - loss: 192.1191 - val_loss: 287.8486 - lr: 2.2528e-05 - 665ms/epoch - 166ms/step\n",
      "Epoch 38/50\n",
      "4/4 - 1s - loss: 192.1085 - val_loss: 287.8416 - lr: 2.0276e-05 - 680ms/epoch - 170ms/step\n",
      "Epoch 39/50\n",
      "4/4 - 1s - loss: 192.0990 - val_loss: 287.8351 - lr: 1.8248e-05 - 659ms/epoch - 165ms/step\n",
      "Epoch 40/50\n",
      "4/4 - 1s - loss: 192.0905 - val_loss: 287.8293 - lr: 1.6423e-05 - 676ms/epoch - 169ms/step\n",
      "Epoch 41/50\n",
      "4/4 - 1s - loss: 192.0829 - val_loss: 287.8242 - lr: 1.4781e-05 - 653ms/epoch - 163ms/step\n",
      "Epoch 42/50\n",
      "4/4 - 1s - loss: 192.0760 - val_loss: 287.8196 - lr: 1.3303e-05 - 656ms/epoch - 164ms/step\n",
      "Epoch 43/50\n",
      "4/4 - 1s - loss: 192.0697 - val_loss: 287.8155 - lr: 1.1973e-05 - 664ms/epoch - 166ms/step\n",
      "Epoch 44/50\n",
      "4/4 - 1s - loss: 192.0642 - val_loss: 287.8117 - lr: 1.0775e-05 - 654ms/epoch - 164ms/step\n",
      "Epoch 45/50\n",
      "4/4 - 1s - loss: 192.0592 - val_loss: 287.8083 - lr: 9.6977e-06 - 652ms/epoch - 163ms/step\n",
      "Epoch 46/50\n",
      "4/4 - 1s - loss: 192.0547 - val_loss: 287.8054 - lr: 8.7280e-06 - 657ms/epoch - 164ms/step\n",
      "Epoch 47/50\n",
      "4/4 - 1s - loss: 192.0506 - val_loss: 287.8026 - lr: 7.8552e-06 - 654ms/epoch - 163ms/step\n",
      "Epoch 48/50\n",
      "4/4 - 1s - loss: 192.0469 - val_loss: 287.8002 - lr: 7.0697e-06 - 659ms/epoch - 165ms/step\n",
      "Epoch 49/50\n",
      "4/4 - 1s - loss: 192.0436 - val_loss: 287.7980 - lr: 6.3627e-06 - 663ms/epoch - 166ms/step\n",
      "Epoch 50/50\n",
      "4/4 - 1s - loss: 192.0407 - val_loss: 287.7961 - lr: 5.7264e-06 - 689ms/epoch - 172ms/step\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 0.001 * 0.90 ** x)\n",
    "model_e2d2.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.Huber())\n",
    "history_e2d2=model_e2d2.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test),batch_size=32,\n",
    "                            verbose=2,\n",
    "                            callbacks=[reduce_lr]\n",
    "                           \n",
    "                           \n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "80440028-4c0d-4f81-9423-44ce7c4b4ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 6ms/step\n",
      "40/40 [==============================] - 1s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_e1d1=model_e1d1.predict(X_test)\n",
    "pred_e2d2=model_e2d2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8a126b2a-ba7c-4f58-bc50-98ccd3b6a8c1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11402000\n",
      "Day  1 :\n",
      "MAE-E1D1 :  297.9769618008333, MAE-E2D2 :  290.250578287251\n",
      "RMSE-E1D1 :  803.6363843923265, RMSE-E2D2 :  801.2762807671802\n",
      "Day  2 :\n",
      "MAE-E1D1 :  295.59245080911916, MAE-E2D2 :  289.5263081514826\n",
      "RMSE-E1D1 :  802.4403500935558, RMSE-E2D2 :  801.0282227438339\n",
      "Day  3 :\n",
      "MAE-E1D1 :  294.1107213255128, MAE-E2D2 :  289.31910013790997\n",
      "RMSE-E1D1 :  801.8148975904329, RMSE-E2D2 :  800.9717194068028\n",
      "Day  4 :\n",
      "MAE-E1D1 :  293.1807324345856, MAE-E2D2 :  289.24049499295563\n",
      "RMSE-E1D1 :  801.4857741337978, RMSE-E2D2 :  800.9565979276231\n",
      "Day  5 :\n",
      "MAE-E1D1 :  292.5367703472017, MAE-E2D2 :  289.20610580155113\n",
      "RMSE-E1D1 :  801.3003250474559, RMSE-E2D2 :  800.951813870225\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "for index,i in enumerate([target_gage]):\n",
    "    print(i)\n",
    "    for j in range(1,6):\n",
    "        print(\"Day \",j,\":\")\n",
    "        print(\"MAE-E1D1 : \",mean_absolute_error(y_test[:,j-1,index],pred_e1d1[:,j-1,index]),end=\", \")\n",
    "        print(\"MAE-E2D2 : \",mean_absolute_error(y_test[:,j-1,index],pred_e2d2[:,j-1,index]))\n",
    "        print(\"RMSE-E1D1 : \",np.sqrt(mean_squared_error(y_test[:,j-1,index],pred_e1d1[:,j-1,index])),end=\", \")\n",
    "        print(\"RMSE-E2D2 : \",np.sqrt(mean_squared_error(y_test[:,j-1,index],pred_e2d2[:,j-1,index])))\n",
    "        \n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "bc4bf957-b55a-4f4e-b864-65861ac465c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56.5, 49.3, 47.2, ..., 72.2, 80.5, 66.3],\n",
       "       [49.3, 47.2, 37.4, ..., 80.5, 66.3, 57.6],\n",
       "       [47.2, 37.4, 38.3, ..., 66.3, 57.6, 52.1],\n",
       "       ...,\n",
       "       [15.4, 16.7, 16.4, ..., 23.1, 22.8, 20.9],\n",
       "       [16.7, 16.4, 15.4, ..., 22.8, 20.9, 17.4],\n",
       "       [16.4, 15.4, 15.5, ..., 20.9, 17.4, 18.4]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.reshape(y_test.shape[0],y_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "748a6eb1-98da-4b2c-84c9-06a7090fb92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.8944957,  4.5569706,  6.342183 , ..., 13.40007  , 13.481923 ,\n",
       "        13.556736 ],\n",
       "       [ 2.8296351,  4.465993 ,  6.227646 , ..., 13.348536 , 13.439354 ,\n",
       "        13.51803  ],\n",
       "       [ 2.6753986,  4.1722727,  5.824697 , ..., 13.22309  , 13.316338 ,\n",
       "        13.388272 ],\n",
       "       ...,\n",
       "       [ 8.4440775, 11.652467 , 13.163033 , ..., 15.257128 , 15.259778 ,\n",
       "        15.261188 ],\n",
       "       [ 8.514966 , 11.692306 , 13.180721 , ..., 15.260813 , 15.263212 ,\n",
       "        15.264516 ],\n",
       "       [ 8.6357355, 11.781409 , 13.227747 , ..., 15.2690115, 15.271357 ,\n",
       "        15.272633 ]], dtype=float32)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_e1d1.reshape(pred_e1d1.shape[0],pred_e1d1.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7d35b6-a6c8-4f38-993e-7e959b03460d",
   "metadata": {},
   "source": [
    "## Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d0e0f7bd-f17f-4c4a-b64a-67aa69ec71ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "biweekly_error = []\n",
    "for pred, ground_truth in zip(pred_e1d1.reshape(pred_e1d1.shape[0],pred_e1d1.shape[1]),\n",
    "                              y_test.reshape(y_test.shape[0],y_test.shape[1])):\n",
    "    rmse = np.sqrt(mean_squared_error(pred, ground_truth))\n",
    "    biweekly_error.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ea80701d-3089-4f7b-a8ec-bf25bc6d2307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "55054828-f2ba-4334-8f52-32d55f6e2dc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'filter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-080e2431efd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'filter'"
     ]
    }
   ],
   "source": [
    "a = [99,4,5,7,0,1]\n",
    "a.filter(a<5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "24849b5d-0097-4d0c-b6c4-01b4e77f2255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(biweekly_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c77088e5-c8f9-4b93-9bd3-9abdc61ad415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampled_biweekly_error = [n for n in biweekly_error if n < 100]\n",
    "sns.histplot(sampled_biweekly_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4c45ac-edcf-49d3-a5c5-2568a3eeadcf",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "404ca1dc-7cac-45a2-947a-0c627b52c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gage_df = df.loc[gage_list[0]].reset_index(drop = False)[['time','ft']]\n",
    "gage_df.rename(columns = {'ft':f'ft_{gage_list[0]}'}, inplace = True)\n",
    "for gage_num in gage_list[1:]:\n",
    "    new_gage_df =  df.loc[gage_num].reset_index(drop = False)[['time','ft']]\n",
    "    new_gage_df.rename(columns = {'ft':f'ft_{gage_num}'}, inplace = True)\n",
    "    gage_df = gage_df.merge(new_gage_df, on = 'time', how = 'outer')\n",
    "    \n",
    "gage_df = gage_df.iloc[-365 * 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "71443a7e-7d8b-441f-9721-5a53b8d4c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'ft_11402000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "487b70bc-637f-4018-a04a-7d12d0055021",
   "metadata": {},
   "outputs": [],
   "source": [
    "gage_df['target'] = gage_df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2bba029c-2b93-4f01-8216-ad44ce3a8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_shift = 30\n",
    "target_data = gage_df['target'].shift(time_shift)\n",
    "data = gage_df.iloc[:-time_shift]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8f620cae-2ea7-4c21-aeea-d29d899eb643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>ft_11402000</th>\n",
       "      <th>ft_11318500</th>\n",
       "      <th>ft_11266500</th>\n",
       "      <th>ft_11208000</th>\n",
       "      <th>ft_11202710</th>\n",
       "      <th>ft_11185500</th>\n",
       "      <th>ft_11189500</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>2014-10-02</td>\n",
       "      <td>16.6</td>\n",
       "      <td>2.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.27</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10959</th>\n",
       "      <td>2014-10-03</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.21</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10960</th>\n",
       "      <td>2014-10-04</td>\n",
       "      <td>17.3</td>\n",
       "      <td>2.10</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10961</th>\n",
       "      <td>2014-10-05</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.22</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10962</th>\n",
       "      <td>2014-10-06</td>\n",
       "      <td>17.4</td>\n",
       "      <td>2.60</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.16</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12383</th>\n",
       "      <td>2018-08-27</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.82</td>\n",
       "      <td>40.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.79</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12384</th>\n",
       "      <td>2018-08-28</td>\n",
       "      <td>19.2</td>\n",
       "      <td>5.72</td>\n",
       "      <td>38.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12385</th>\n",
       "      <td>2018-08-29</td>\n",
       "      <td>18.6</td>\n",
       "      <td>5.87</td>\n",
       "      <td>37.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12386</th>\n",
       "      <td>2018-08-30</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.94</td>\n",
       "      <td>36.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12387</th>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>19.8</td>\n",
       "      <td>6.08</td>\n",
       "      <td>35.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1430 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time  ft_11402000  ft_11318500  ft_11266500  ft_11208000  \\\n",
       "10958 2014-10-02         16.6         2.00         11.0          1.5   \n",
       "10959 2014-10-03         18.0         2.00         10.8          1.4   \n",
       "10960 2014-10-04         17.3         2.10         10.7          1.5   \n",
       "10961 2014-10-05         16.0         2.30         10.3          1.5   \n",
       "10962 2014-10-06         17.4         2.60         10.1          1.5   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "12383 2018-08-27         17.0         5.82         40.2          4.1   \n",
       "12384 2018-08-28         19.2         5.72         38.6          4.1   \n",
       "12385 2018-08-29         18.6         5.87         37.7          4.0   \n",
       "12386 2018-08-30         20.0         5.94         36.2          4.1   \n",
       "12387 2018-08-31         19.8         6.08         35.1          4.1   \n",
       "\n",
       "       ft_11202710  ft_11185500  ft_11189500  target  \n",
       "10958         13.0          0.0         2.27    16.6  \n",
       "10959         13.0          0.0         2.21    18.0  \n",
       "10960         13.0          0.0         2.20    17.3  \n",
       "10961         13.0          0.0         2.22    16.0  \n",
       "10962         12.0          0.0         2.16    17.4  \n",
       "...            ...          ...          ...     ...  \n",
       "12383         22.0         55.0         2.79    17.0  \n",
       "12384         23.0         55.0         2.75    19.2  \n",
       "12385         23.0         55.0         2.77    18.6  \n",
       "12386         23.0         52.0         2.48    20.0  \n",
       "12387         23.0         42.0         2.14    19.8  \n",
       "\n",
       "[1430 rows x 9 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "548b20bf-65bb-4c2a-a3e5-c427fd9e23ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ft_11402000',\n",
       " 'ft_11318500',\n",
       " 'ft_11266500',\n",
       " 'ft_11208000',\n",
       " 'ft_11202710',\n",
       " 'ft_11185500',\n",
       " 'ft_11189500']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = data.drop(columns = ['time','target']).columns.tolist()\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0049fae0-ef92-421c-9b6a-d7f18bad96d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_head = data.index[int(0.8*len(data))]\n",
    "\n",
    "df_train = gage_df.loc[:test_head,:]\n",
    "df_test = gage_df.loc[test_head:,:]\n",
    "target_train = target_data.loc[:test_head]\n",
    "target_test = target_data.loc[test_head:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "40985ed5-828b-49ab-8f89-ff0c3d13c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, dataframe, target, features, sequence_length=5):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.sequence_length = sequence_length\n",
    "        self.y = torch.tensor(dataframe[target].values).float()\n",
    "        self.X = torch.tensor(dataframe[features].values).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, i): \n",
    "        if i >= self.sequence_length - 1:\n",
    "            i_start = i - self.sequence_length + 1\n",
    "            x = self.X[i_start:(i + 1), :]\n",
    "        else:\n",
    "            padding = self.X[0].repeat(self.sequence_length - i - 1, 1)\n",
    "            x = self.X[0:(i + 1), :]\n",
    "            x = torch.cat((padding, x), 0)\n",
    "\n",
    "        return x, self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "78d0cd05-8644-4cfa-966f-13b1cf0da35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[22.5000,  2.6000, 10.6000,  1.4000, 14.0000,  0.0000,  2.6600],\n",
      "        [22.5000,  2.7000, 10.5000,  1.4000, 13.0000,  0.0000,  3.1500],\n",
      "        [23.2000,  3.3000, 10.4000,  1.4000, 13.0000,  0.0000,  3.0700],\n",
      "        [35.5000,  3.7000, 10.5000,  1.5000, 14.0000,  0.0000,  3.0300],\n",
      "        [35.0000,  3.7000, 10.7000,  1.5000, 14.0000,  0.0000,  3.1500],\n",
      "        [28.1000,  3.4000, 10.6000,  1.5000, 14.0000,  0.0000,  3.2200],\n",
      "        [26.3000,  3.2000, 10.7000,  1.5000, 14.0000,  0.0000,  3.2400]])\n"
     ]
    }
   ],
   "source": [
    "i = 27\n",
    "sequence_length = 7\n",
    "features = feature_cols\n",
    "target = 'target'\n",
    "\n",
    "train_dataset = SequenceDataset(\n",
    "    df_train,\n",
    "    target=target,\n",
    "    features=features,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "X, y = train_dataset[i]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0aa7fe7f-a1f9-4cc1-9281-99f2b0d0e084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 7, 7])\n",
      "tensor([[[6.9600e+02, 1.7600e+02, 6.0800e+03, 3.4000e+00, 4.0800e+02,\n",
      "          5.6500e+02, 1.2500e+03],\n",
      "         [6.6400e+02, 1.7000e+02, 5.6900e+03, 3.0000e+00, 4.3800e+02,\n",
      "          5.7600e+02, 1.2400e+03],\n",
      "         [5.9100e+02, 1.6400e+02, 3.9200e+03, 3.0000e+00, 4.1100e+02,\n",
      "          5.6000e+02, 1.2300e+03],\n",
      "         [5.3200e+02, 1.5800e+02, 3.4400e+03, 1.3000e+00, 3.7500e+02,\n",
      "          5.5300e+02, 1.1600e+03],\n",
      "         [4.8600e+02, 1.5500e+02, 3.0700e+03, 0.0000e+00, 3.4000e+02,\n",
      "          5.5000e+02, 1.0800e+03],\n",
      "         [4.6300e+02, 1.5400e+02, 2.5800e+03, 0.0000e+00, 3.0100e+02,\n",
      "          5.3000e+02, 1.0200e+03],\n",
      "         [4.7200e+02, 1.5300e+02, 2.3800e+03, 3.1000e+00, 2.8300e+02,\n",
      "          5.2700e+02, 9.7500e+02]],\n",
      "\n",
      "        [[3.6700e+01, 3.8000e+00, 4.0100e+02, 1.1000e+01, 6.1000e+00,\n",
      "          1.9900e+02, 8.7700e+00],\n",
      "         [3.8800e+01, 7.8000e+00, 3.7800e+02, 1.1000e+01, 6.3000e+00,\n",
      "          1.8900e+02, 8.6500e+00],\n",
      "         [4.4800e+01, 1.6000e+01, 4.6700e+02, 1.1000e+01, 7.2000e+00,\n",
      "          1.7900e+02, 8.8300e+00],\n",
      "         [4.6000e+01, 1.2000e+01, 6.0900e+02, 1.1000e+01, 6.2000e+00,\n",
      "          1.6400e+02, 1.0200e+01],\n",
      "         [4.0700e+01, 1.1000e+01, 6.4300e+02, 1.1000e+01, 6.0000e+00,\n",
      "          1.4700e+02, 1.0900e+01],\n",
      "         [3.7500e+01, 9.8000e+00, 5.7300e+02, 1.1000e+01, 5.8000e+00,\n",
      "          1.3600e+02, 1.0300e+01],\n",
      "         [3.2400e+01, 9.2000e+00, 4.8000e+02, 1.1000e+01, 5.8000e+00,\n",
      "          1.4000e+02, 9.9300e+00]],\n",
      "\n",
      "        [[9.5400e+00, 1.0000e+00, 8.1000e+01, 9.9000e+00, 1.2000e+01,\n",
      "          4.2000e+01, 8.1000e-01],\n",
      "         [9.4000e+00, 1.1000e+00, 6.8100e+01, 8.5000e+00, 1.1000e+01,\n",
      "          4.2000e+01, 1.2800e+00],\n",
      "         [9.3300e+00, 1.1000e+00, 5.9000e+01, 7.6000e+00, 1.1000e+01,\n",
      "          4.2000e+01, 1.0800e+00],\n",
      "         [8.8200e+00, 1.2000e+00, 5.4500e+01, 7.7000e+00, 1.1000e+01,\n",
      "          4.2000e+01, 6.8000e-01],\n",
      "         [9.3900e+00, 1.2000e+00, 5.1300e+01, 7.7000e+00, 1.2000e+01,\n",
      "          4.2000e+01, 6.8000e-01],\n",
      "         [9.3100e+00, 1.3000e+00, 4.7700e+01, 6.7000e+00, 1.1000e+01,\n",
      "          4.2000e+01, 4.7000e-01],\n",
      "         [9.5300e+00, 1.3000e+00, 7.0300e+01, 6.1000e+00, 1.1000e+01,\n",
      "          4.2000e+01, 4.7000e-01]]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True)\n",
    "\n",
    "X, y = next(iter(train_loader))\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fbf4710a-729e-4576-9e23-ff3dcebb65d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: torch.Size([4, 7, 7])\n",
      "Target shape: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "sequence_length = 7\n",
    "\n",
    "train_dataset = SequenceDataset(\n",
    "    df_train,\n",
    "    target=target,\n",
    "    features=features,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "test_dataset = SequenceDataset(\n",
    "    df_test,\n",
    "    target=target,\n",
    "    features=features,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "X, y = next(iter(train_loader))\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "05f57748-7b5c-48b4-9784-afff54cb5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class ShallowRegressionLSTM(nn.Module):\n",
    "    def __init__(self, num_sensors, hidden_units):\n",
    "        super().__init__()\n",
    "        self.num_sensors = num_sensors  # this is the number of features\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = 1\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_sensors,\n",
    "            hidden_size=hidden_units,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_units, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "\n",
    "        _, (hn, _) = self.lstm(x, (h0, c0))\n",
    "        out = self.linear(hn[0]).flatten()  # First dim of Hn is num_layers, which is set to 1 above.\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0c331ed0-b55d-4fac-9f34-51eb0c21c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-4\n",
    "num_hidden_units = 8\n",
    "\n",
    "model = ShallowRegressionLSTM(num_sensors=len(features), hidden_units=num_hidden_units)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "20ad9801-744b-4209-b9f3-9802b7f65bb8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n",
      "Test loss: 170873.41584797148\n",
      "\n",
      "Epoch 0\n",
      "---------\n",
      "Train loss: 677741.1989021966\n",
      "Test loss: 170767.7034095088\n",
      "\n",
      "Epoch 1\n",
      "---------\n",
      "Train loss: 677501.5249025564\n",
      "Test loss: 170605.03493953656\n",
      "\n",
      "Epoch 2\n",
      "---------\n",
      "Train loss: 677299.4300107524\n",
      "Test loss: 170366.73983841907\n",
      "\n",
      "Epoch 3\n",
      "---------\n",
      "Train loss: 676706.1167311452\n",
      "Test loss: 170094.44985778423\n",
      "\n",
      "Epoch 4\n",
      "---------\n",
      "Train loss: 676884.1327460951\n",
      "Test loss: 169811.28410793256\n",
      "\n",
      "Epoch 5\n",
      "---------\n",
      "Train loss: 675669.3594616082\n",
      "Test loss: 169516.9464481209\n",
      "\n",
      "Epoch 6\n",
      "---------\n",
      "Train loss: 675072.644075799\n",
      "Test loss: 169140.05310087567\n",
      "\n",
      "Epoch 7\n",
      "---------\n",
      "Train loss: 674459.0158398525\n",
      "Test loss: 168847.5033165171\n",
      "\n",
      "Epoch 8\n",
      "---------\n",
      "Train loss: 673941.1603868598\n",
      "Test loss: 168567.038689722\n",
      "\n",
      "Epoch 9\n",
      "---------\n",
      "Train loss: 673500.5841700324\n",
      "Test loss: 168269.523753637\n",
      "\n",
      "Epoch 10\n",
      "---------\n",
      "Train loss: 673055.2345612955\n",
      "Test loss: 168014.8466104435\n",
      "\n",
      "Epoch 11\n",
      "---------\n",
      "Train loss: 672818.6869991715\n",
      "Test loss: 167716.416280167\n",
      "\n",
      "Epoch 12\n",
      "---------\n",
      "Train loss: 672130.5865072988\n",
      "Test loss: 167455.45125686066\n",
      "\n",
      "Epoch 13\n",
      "---------\n",
      "Train loss: 671704.6060938819\n",
      "Test loss: 167204.5646704903\n",
      "\n",
      "Epoch 14\n",
      "---------\n",
      "Train loss: 671241.7510037705\n",
      "Test loss: 166941.18175730525\n",
      "\n",
      "Epoch 15\n",
      "---------\n",
      "Train loss: 670803.138987724\n",
      "Test loss: 166691.87329830398\n",
      "\n",
      "Epoch 16\n",
      "---------\n",
      "Train loss: 670365.5841257647\n",
      "Test loss: 166419.0734840754\n",
      "\n",
      "Epoch 17\n",
      "---------\n",
      "Train loss: 669935.7151606224\n",
      "Test loss: 166165.04532518718\n",
      "\n",
      "Epoch 18\n",
      "---------\n",
      "Train loss: 669475.9458647405\n",
      "Test loss: 165936.76954310152\n",
      "\n",
      "Epoch 19\n",
      "---------\n",
      "Train loss: 669019.2163141497\n",
      "Test loss: 165621.60084680666\n",
      "\n",
      "Epoch 20\n",
      "---------\n",
      "Train loss: 668535.02955662\n",
      "Test loss: 165328.1257301486\n",
      "\n",
      "Epoch 21\n",
      "---------\n",
      "Train loss: 668243.5419153619\n",
      "Test loss: 165047.79578253665\n",
      "\n",
      "Epoch 22\n",
      "---------\n",
      "Train loss: 667529.0249187456\n",
      "Test loss: 164782.76084467958\n",
      "\n",
      "Epoch 23\n",
      "---------\n",
      "Train loss: 667978.3899456117\n",
      "Test loss: 164534.60009298747\n",
      "\n",
      "Epoch 24\n",
      "---------\n",
      "Train loss: 667013.0950182406\n",
      "Test loss: 164283.3196336212\n",
      "\n",
      "Epoch 25\n",
      "---------\n",
      "Train loss: 666345.8518259799\n",
      "Test loss: 164034.45130953155\n",
      "\n",
      "Epoch 26\n",
      "---------\n",
      "Train loss: 665923.3334611766\n",
      "Test loss: 163783.5959113029\n",
      "\n",
      "Epoch 27\n",
      "---------\n",
      "Train loss: 665439.6517416924\n",
      "Test loss: 163527.3831137434\n",
      "\n",
      "Epoch 28\n",
      "---------\n",
      "Train loss: 664831.5607800102\n",
      "Test loss: 163284.1700364155\n",
      "\n",
      "Epoch 29\n",
      "---------\n",
      "Train loss: 664414.2996146703\n",
      "Test loss: 163042.89257208005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(data_loader, model, loss_function, optimizer):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for X, y in data_loader:\n",
    "        output = model(X)\n",
    "        loss = loss_function(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Train loss: {avg_loss}\")\n",
    "\n",
    "def test_model(data_loader, model, loss_function):\n",
    "\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            total_loss += loss_function(output, y).item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Test loss: {avg_loss}\")\n",
    "\n",
    "\n",
    "print(\"Untrained test\\n--------\")\n",
    "test_model(test_loader, model, loss_function)\n",
    "print()\n",
    "\n",
    "for ix_epoch in range(30):\n",
    "    print(f\"Epoch {ix_epoch}\\n---------\")\n",
    "    train_model(train_loader, model, loss_function, optimizer=optimizer)\n",
    "    test_model(test_loader, model, loss_function)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "03b6d8db-4847-4aa8-b1b0-b7a508dfad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       target  Model forecast\n",
      "10958    16.6       18.184389\n",
      "10959    18.0       18.563141\n",
      "10960    17.3       18.346769\n",
      "10961    16.0       18.009441\n",
      "10962    17.4       18.667486\n",
      "...       ...             ...\n",
      "12413    23.1       17.656294\n",
      "12414    22.8       17.612049\n",
      "12415    20.9       17.542467\n",
      "12416    17.4       17.420143\n",
      "12417    18.4       17.962250\n",
      "\n",
      "[1461 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-83-eac2ac85467c>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[ystar_col] = predict(train_eval_loader, model).numpy()\n",
      "<ipython-input-83-eac2ac85467c>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[ystar_col] = predict(test_loader, model).numpy()\n"
     ]
    }
   ],
   "source": [
    "def predict(data_loader, model):\n",
    "\n",
    "    output = torch.tensor([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, _ in data_loader:\n",
    "            y_star = model(X)\n",
    "            output = torch.cat((output, y_star), 0)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "train_eval_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "ystar_col = \"Model forecast\"\n",
    "df_train[ystar_col] = predict(train_eval_loader, model).numpy()\n",
    "df_test[ystar_col] = predict(test_loader, model).numpy()\n",
    "\n",
    "df_out = pd.concat((df_train, df_test))[[target, ystar_col]]\n",
    "\n",
    "# for c in df_out.columns:\n",
    "#     df_out[c] = df_out[c] * target_stdev + target_mean\n",
    "\n",
    "print(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "11c32bfb-d72b-446d-a3ab-68c30c5ce971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Model forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>16.6</td>\n",
       "      <td>18.184389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10959</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.563141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10960</th>\n",
       "      <td>17.3</td>\n",
       "      <td>18.346769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10961</th>\n",
       "      <td>16.0</td>\n",
       "      <td>18.009441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10962</th>\n",
       "      <td>17.4</td>\n",
       "      <td>18.667486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12413</th>\n",
       "      <td>23.1</td>\n",
       "      <td>17.656294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12414</th>\n",
       "      <td>22.8</td>\n",
       "      <td>17.612049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12415</th>\n",
       "      <td>20.9</td>\n",
       "      <td>17.542467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12416</th>\n",
       "      <td>17.4</td>\n",
       "      <td>17.420143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12417</th>\n",
       "      <td>18.4</td>\n",
       "      <td>17.962250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1461 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target  Model forecast\n",
       "10958    16.6       18.184389\n",
       "10959    18.0       18.563141\n",
       "10960    17.3       18.346769\n",
       "10961    16.0       18.009441\n",
       "10962    17.4       18.667486\n",
       "...       ...             ...\n",
       "12413    23.1       17.656294\n",
       "12414    22.8       17.612049\n",
       "12415    20.9       17.542467\n",
       "12416    17.4       17.420143\n",
       "12417    18.4       17.962250\n",
       "\n",
       "[1461 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
