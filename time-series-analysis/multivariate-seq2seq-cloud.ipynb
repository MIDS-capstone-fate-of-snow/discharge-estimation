{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60bb0afb-b16d-432c-9167-214597e3c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from prophet import Prophet\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime, itertools\n",
    "# from prophet.plot import plot_yearly, plot_weekly, plot_plotly, plot_components_plotly\n",
    "# import plotly.graph_objs as go\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eeaed16-5805-4e4c-842d-1165bf7c59ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f202be27-70ac-4270-9ce0-4ea13df2e2a5",
   "metadata": {},
   "source": [
    "# Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b161fe20-f137-47a2-9f73-0f066cc02cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = os.path.join(\"..\", \"data\")\n",
    "# fp = os.path.join(DATA_DIR, \"hydrograph-excel-sheet-tp-cleaned.xlsx\")\n",
    "fp = \"hydrograph-excel-sheet-tp-cleaned.xlsx\"\n",
    "xl = pd.ExcelFile(fp)\n",
    "gages = xl.sheet_names\n",
    "hydro_data = {s: xl.parse(s) for s in gages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5bfeffd-24ae-417c-978f-4d290a6eae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_sheet(sheet_name: str, src_data: dict):\n",
    "    src_df = src_data[sheet_name]\n",
    "    \n",
    "    # Check lengths of columns, some contain only notes so will be\n",
    "    # much less than 100 and need to be dropped. Most columns\n",
    "    # should have 365/366 values but a few are missing and need to be filled.\n",
    "    col_lengths = {c: sum(src_df[c].notna()) for c in src_df.columns}\n",
    "    keep_cols = [c for c, l in col_lengths.items() if l > 100]\n",
    "    \n",
    "    # Check columns are all in the correct order to combine:\n",
    "    assert \"time\" in keep_cols[0].lower()\n",
    "    correct_order = {\"time\": \"ft\", \"ft\": \"discharge\", \"discharge\": \"time\"}\n",
    "    for i, col in enumerate(keep_cols[:-1]):\n",
    "        next_col = keep_cols[i+1]\n",
    "        for key in correct_order.keys():\n",
    "            if key in col.lower():\n",
    "                should_be = correct_order[key]\n",
    "                assert should_be in next_col.lower(), sheet_name\n",
    "    \n",
    "    # Iterate through columns and collect data:\n",
    "    data_subsets = list()\n",
    "    for start_col in range(0, len(keep_cols), 3):\n",
    "        df_columns = keep_cols[start_col: start_col+3]\n",
    "        subset = src_df[df_columns]\n",
    "        rename = dict(zip(subset.columns, [\"time\", \"ft\", \"m3\"]))\n",
    "        subset = subset.rename(columns=rename).dropna(how=\"all\")\n",
    "        data_subsets.append(subset)\n",
    "        \n",
    "    # Combine to a single df:\n",
    "    final =  pd.concat(data_subsets).reset_index(drop=True)\n",
    "    final[\"gage\"] = sheet_name\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04bf589b-0861-4c39-b06b-33e52e45bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sheets = list()\n",
    "for sname in gages:\n",
    "    all_sheets.append(flatten_sheet(sname, hydro_data)) \n",
    "df = pd.concat(all_sheets).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03c3799e-18a5-4325-bfa5-e99a4c827a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date, max_date = min(df[\"time\"]), max(df[\"time\"])\n",
    "all_dates = [min_date.to_pydatetime()]\n",
    "while all_dates[-1] < max_date:\n",
    "    all_dates.append(all_dates[-1] + datetime.timedelta(days=1))\n",
    "    \n",
    "full_index = list(itertools.product(df[\"gage\"].unique(), all_dates))\n",
    "df = df.set_index([\"gage\", \"time\"])\n",
    "df = df.reindex(full_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6218a26c-40da-4c03-9d86-3b0bd33f27ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "gage_list = df.index.get_level_values('gage').unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07dd5e6a-dc36-4c85-9309-665b53ef6e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11402000',\n",
       " '11318500',\n",
       " '11266500',\n",
       " '11208000',\n",
       " '11202710',\n",
       " '11185500',\n",
       " '11189500']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gage_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00420397-4daa-4d8d-a52e-b8389e96f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gage_ts = df.loc[gage_list[0]].reset_index(drop = False)\n",
    "gage_ts.rename(columns = {'time':'ds', 'ft': 'y'}, inplace = True)\n",
    "min_date = gage_ts['ds'].min()\n",
    "max_date = gage_ts['ds'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0086842-8bac-4fda-9570-aa7ae24bbea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ft</th>\n",
       "      <th>m3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gage</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">11402000</th>\n",
       "      <th>1984-10-01</th>\n",
       "      <td>54.00</td>\n",
       "      <td>1.529110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-10-02</th>\n",
       "      <td>52.00</td>\n",
       "      <td>1.472476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-10-03</th>\n",
       "      <td>49.00</td>\n",
       "      <td>1.387525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-10-04</th>\n",
       "      <td>49.00</td>\n",
       "      <td>1.387525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-10-05</th>\n",
       "      <td>48.00</td>\n",
       "      <td>1.359209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">11189500</th>\n",
       "      <th>2018-09-26</th>\n",
       "      <td>2.86</td>\n",
       "      <td>0.080986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-27</th>\n",
       "      <td>2.78</td>\n",
       "      <td>0.078721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-28</th>\n",
       "      <td>2.99</td>\n",
       "      <td>0.084667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-29</th>\n",
       "      <td>3.12</td>\n",
       "      <td>0.088349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-30</th>\n",
       "      <td>3.34</td>\n",
       "      <td>0.094578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86926 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ft        m3\n",
       "gage     time                       \n",
       "11402000 1984-10-01  54.00  1.529110\n",
       "         1984-10-02  52.00  1.472476\n",
       "         1984-10-03  49.00  1.387525\n",
       "         1984-10-04  49.00  1.387525\n",
       "         1984-10-05  48.00  1.359209\n",
       "...                    ...       ...\n",
       "11189500 2018-09-26   2.86  0.080986\n",
       "         2018-09-27   2.78  0.078721\n",
       "         2018-09-28   2.99  0.084667\n",
       "         2018-09-29   3.12  0.088349\n",
       "         2018-09-30   3.34  0.094578\n",
       "\n",
       "[86926 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00895bc8-c711-4262-b7b7-08700808fa33",
   "metadata": {},
   "source": [
    "# Generate Multivariate Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6610c8e7-5284-4349-bc62-4a97e2beed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "gage_df = df.loc[gage_list[0]].reset_index(drop = False)[['time','ft']]\n",
    "gage_df.rename(columns = {'ft':f'ft_{gage_list[0]}'}, inplace = True)\n",
    "for gage_num in gage_list[1:]:\n",
    "    new_gage_df =  df.loc[gage_num].reset_index(drop = False)[['time','ft']]\n",
    "    new_gage_df.rename(columns = {'ft':f'ft_{gage_num}'}, inplace = True)\n",
    "    gage_df = gage_df.merge(new_gage_df, on = 'time', how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e0fd5df-4025-46ef-8c77-8904a5131766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>ft_11402000</th>\n",
       "      <th>ft_11318500</th>\n",
       "      <th>ft_11266500</th>\n",
       "      <th>ft_11208000</th>\n",
       "      <th>ft_11202710</th>\n",
       "      <th>ft_11185500</th>\n",
       "      <th>ft_11189500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984-10-01</td>\n",
       "      <td>54.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984-10-02</td>\n",
       "      <td>52.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>279.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1984-10-03</td>\n",
       "      <td>49.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>284.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984-10-04</td>\n",
       "      <td>49.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>291.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984-10-05</td>\n",
       "      <td>48.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  ft_11402000  ft_11318500  ft_11266500  ft_11208000  ft_11202710  \\\n",
       "0 1984-10-01         54.0         10.0         53.0          1.7          NaN   \n",
       "1 1984-10-02         52.0         12.0         52.0          1.4          NaN   \n",
       "2 1984-10-03         49.0         14.0         51.0          1.4          NaN   \n",
       "3 1984-10-04         49.0         13.0         49.0          1.4          NaN   \n",
       "4 1984-10-05         48.0         14.0         46.0          1.4          NaN   \n",
       "\n",
       "   ft_11185500  ft_11189500  \n",
       "0        256.0         39.0  \n",
       "1        279.0         42.0  \n",
       "2        284.0         45.0  \n",
       "3        291.0         47.0  \n",
       "4        281.0         50.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gage_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad2d6d74-5bb0-488a-a4b9-5889b0d4d3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time           0\n",
       "ft_11402000    0\n",
       "ft_11318500    0\n",
       "ft_11266500    0\n",
       "ft_11208000    0\n",
       "ft_11202710    0\n",
       "ft_11185500    0\n",
       "ft_11189500    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most 4 years data seems to have no missing values\n",
    "gage_df.iloc[-365 * 4:].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34ae46aa-fd40-44d4-bec3-2342fed5d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gage_df = gage_df.iloc[-365 * 4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2f7d7a-4049-4003-b914-5904a10e1941",
   "metadata": {},
   "source": [
    "## Baseline Prophet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c54a4a0-a5c8-402a-ab29-2b9ff7b84bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_params = {'seasonality_mode':'multiplicative'}\n",
    "horizon = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4236136-4c81-44d6-8286-d93e6e3e4f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "gage_df.rename(columns = {'time':'ds', 'ft_11402000': 'y'}, inplace = True)\n",
    "gage_train = gage_df.iloc[: -horizon,:]\n",
    "gage_test = gage_df.iloc[-horizon:,:]\n",
    "m = Prophet(**selected_params).fit(gage_train) # **best_params\n",
    "future = m.make_future_dataframe(periods=horizon)\n",
    "forecast = m.predict(future)\n",
    "gage_test['yhat_corrected'] = forecast.iloc[-horizon:]['yhat'].apply(lambda x : max(x,0)).values\n",
    "gage_test['yhat'] = forecast.iloc[-horizon:]['yhat'].values\n",
    "forecast['yhat_corrected'] = forecast['yhat'].apply(lambda x : max(x,0))\n",
    "\n",
    "# gage_test.drop(columns = ['m3'], inplace = True)\n",
    "\n",
    "# if show_plots:\n",
    "#     fig1 = m.plot_components(forecast)\n",
    "#     fig2 = m.plot(forecast)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(gage_test['y'], gage_test['yhat_corrected']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbe5b25e-4688-4f63-a321-07d0ded12f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.947919918866564"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c14fd8-d810-41c0-ac43-808cfaefd4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04d223fe-03fe-4d79-802e-79491e2b67c5",
   "metadata": {},
   "source": [
    "# Multivariate LSTM Seq2Seq Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f206eee-3cf7-4d0a-9926-28ce43fe1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ff5beff9-e123-4b9a-9aa3-dbdad5401274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_series(series, n_past, n_future):\n",
    "#   #\n",
    "#   # n_past ==> no of past observations\n",
    "#   #\n",
    "#   # n_future ==> no of future observations \n",
    "#   #\n",
    "#     X, y = list(), list()\n",
    "#     for window_start in range(len(series)):\n",
    "#         past_end = window_start + n_past\n",
    "#         future_end = past_end + n_future\n",
    "#         if future_end > len(series):\n",
    "#             break\n",
    "#         # slicing the past and future parts of the window\n",
    "#         past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
    "#         X.append(past)\n",
    "#         y.append(future)\n",
    "#     return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def transform_seq2seq_data(df, target_col, feature_col, n_past, n_future):\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for i in range(n_past,len(df) - n_future):\n",
    "        y = df.iloc[i:i + n_future][target_col].values.tolist()\n",
    "        y_list.append(y)\n",
    "\n",
    "        X = df.iloc[i - n_past: i][feature_cols].values.tolist()\n",
    "        X_list.append(X)\n",
    "    return np.array(X_list), np.array(y_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a67b43d-7b56-4948-8e6f-0d824b3dd218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_cols = ['m3','swe_avg','swe_max','tp_avg','t2m_avg','tp_max','t2m_max','pixel_sum','pixel_mean','pixel_min','pixel_max']\n",
    "# target_col = 'm3'\n",
    "\n",
    "# gage_df_test = gage_df.copy()\n",
    "# X_list = []\n",
    "# y_list = []\n",
    "# for i in range(28,len(gage_df_test) - 14):\n",
    "#     y = gage_df_test.iloc[i:i + 14][target_col].values.tolist()\n",
    "#     y_list.append(y)\n",
    "    \n",
    "#     X = gage_df_test.iloc[i - 28: i][feature_cols].values.tolist()\n",
    "#     X_list.append(X)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dfc4ce9c-022a-4c8b-ac1c-b6fad51b106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(X_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b8c0b78-02a1-4b2e-a07c-1756f1458ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m3</th>\n",
       "      <th>swe_avg</th>\n",
       "      <th>swe_max</th>\n",
       "      <th>tp_avg</th>\n",
       "      <th>t2m_avg</th>\n",
       "      <th>tp_max</th>\n",
       "      <th>t2m_max</th>\n",
       "      <th>pixel_sum</th>\n",
       "      <th>pixel_mean</th>\n",
       "      <th>pixel_min</th>\n",
       "      <th>pixel_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>1.599902</td>\n",
       "      <td>0.010051</td>\n",
       "      <td>10.0</td>\n",
       "      <td>36.596780</td>\n",
       "      <td>0.277207</td>\n",
       "      <td>54.227730</td>\n",
       "      <td>1.021534</td>\n",
       "      <td>12514.0</td>\n",
       "      <td>49.074510</td>\n",
       "      <td>34.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>1.817942</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.432330</td>\n",
       "      <td>2.140078</td>\n",
       "      <td>40.226460</td>\n",
       "      <td>2.642189</td>\n",
       "      <td>12514.0</td>\n",
       "      <td>49.074510</td>\n",
       "      <td>34.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>1.758476</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.766869</td>\n",
       "      <td>-2.116478</td>\n",
       "      <td>1.752489</td>\n",
       "      <td>-0.916607</td>\n",
       "      <td>12514.0</td>\n",
       "      <td>49.074510</td>\n",
       "      <td>34.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>1.693347</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.016986</td>\n",
       "      <td>-1.963441</td>\n",
       "      <td>0.045573</td>\n",
       "      <td>-0.204727</td>\n",
       "      <td>12514.0</td>\n",
       "      <td>49.074510</td>\n",
       "      <td>34.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>1.662199</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.218129</td>\n",
       "      <td>0.024585</td>\n",
       "      <td>0.302439</td>\n",
       "      <td>0.961063</td>\n",
       "      <td>12514.0</td>\n",
       "      <td>49.074510</td>\n",
       "      <td>34.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>1.614060</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.852008</td>\n",
       "      <td>-0.169998</td>\n",
       "      <td>1.713131</td>\n",
       "      <td>0.659763</td>\n",
       "      <td>12514.0</td>\n",
       "      <td>49.074510</td>\n",
       "      <td>34.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>1.599902</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.847263</td>\n",
       "      <td>1.220284</td>\n",
       "      <td>30.620916</td>\n",
       "      <td>2.069096</td>\n",
       "      <td>12514.0</td>\n",
       "      <td>49.074510</td>\n",
       "      <td>34.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>1.608397</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.534594</td>\n",
       "      <td>0.431471</td>\n",
       "      <td>17.719612</td>\n",
       "      <td>1.665302</td>\n",
       "      <td>12514.0</td>\n",
       "      <td>49.074510</td>\n",
       "      <td>34.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-09</th>\n",
       "      <td>1.699011</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.499332</td>\n",
       "      <td>1.175823</td>\n",
       "      <td>7.467758</td>\n",
       "      <td>1.933275</td>\n",
       "      <td>145640.0</td>\n",
       "      <td>44.240580</td>\n",
       "      <td>27.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-10</th>\n",
       "      <td>1.772635</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.533739</td>\n",
       "      <td>0.904211</td>\n",
       "      <td>2.409155</td>\n",
       "      <td>1.725673</td>\n",
       "      <td>145640.0</td>\n",
       "      <td>44.240580</td>\n",
       "      <td>27.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-11</th>\n",
       "      <td>1.766971</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.102332</td>\n",
       "      <td>0.981723</td>\n",
       "      <td>0.186435</td>\n",
       "      <td>2.109410</td>\n",
       "      <td>145640.0</td>\n",
       "      <td>44.240580</td>\n",
       "      <td>27.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-12</th>\n",
       "      <td>3.992675</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>185.137420</td>\n",
       "      <td>2.717574</td>\n",
       "      <td>239.801000</td>\n",
       "      <td>3.636267</td>\n",
       "      <td>145640.0</td>\n",
       "      <td>44.240580</td>\n",
       "      <td>27.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-13</th>\n",
       "      <td>13.903572</td>\n",
       "      <td>0.272999</td>\n",
       "      <td>39.0</td>\n",
       "      <td>337.503720</td>\n",
       "      <td>2.362755</td>\n",
       "      <td>477.934450</td>\n",
       "      <td>3.010495</td>\n",
       "      <td>145640.0</td>\n",
       "      <td>44.240580</td>\n",
       "      <td>27.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-14</th>\n",
       "      <td>7.249113</td>\n",
       "      <td>1.071841</td>\n",
       "      <td>89.0</td>\n",
       "      <td>23.814380</td>\n",
       "      <td>-1.772130</td>\n",
       "      <td>32.868492</td>\n",
       "      <td>-0.373926</td>\n",
       "      <td>145640.0</td>\n",
       "      <td>44.240580</td>\n",
       "      <td>27.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-15</th>\n",
       "      <td>4.757230</td>\n",
       "      <td>0.455649</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.069395</td>\n",
       "      <td>-0.841212</td>\n",
       "      <td>0.087003</td>\n",
       "      <td>0.647146</td>\n",
       "      <td>145640.0</td>\n",
       "      <td>44.240580</td>\n",
       "      <td>27.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-16</th>\n",
       "      <td>3.879408</td>\n",
       "      <td>0.158208</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.031073</td>\n",
       "      <td>0.872402</td>\n",
       "      <td>0.031073</td>\n",
       "      <td>2.658576</td>\n",
       "      <td>145640.0</td>\n",
       "      <td>44.240580</td>\n",
       "      <td>27.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-17</th>\n",
       "      <td>3.794457</td>\n",
       "      <td>0.066458</td>\n",
       "      <td>63.0</td>\n",
       "      <td>106.854400</td>\n",
       "      <td>0.801335</td>\n",
       "      <td>153.129440</td>\n",
       "      <td>1.609707</td>\n",
       "      <td>5528.0</td>\n",
       "      <td>33.101795</td>\n",
       "      <td>23.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-18</th>\n",
       "      <td>10.760402</td>\n",
       "      <td>0.035041</td>\n",
       "      <td>53.0</td>\n",
       "      <td>459.054380</td>\n",
       "      <td>0.295051</td>\n",
       "      <td>607.063500</td>\n",
       "      <td>0.857865</td>\n",
       "      <td>5528.0</td>\n",
       "      <td>33.101795</td>\n",
       "      <td>23.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-19</th>\n",
       "      <td>18.689119</td>\n",
       "      <td>0.028945</td>\n",
       "      <td>48.0</td>\n",
       "      <td>395.896820</td>\n",
       "      <td>-0.006726</td>\n",
       "      <td>547.822700</td>\n",
       "      <td>1.017462</td>\n",
       "      <td>5528.0</td>\n",
       "      <td>33.101795</td>\n",
       "      <td>23.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-20</th>\n",
       "      <td>13.705354</td>\n",
       "      <td>0.023892</td>\n",
       "      <td>45.0</td>\n",
       "      <td>354.958600</td>\n",
       "      <td>-0.787572</td>\n",
       "      <td>482.404750</td>\n",
       "      <td>0.257326</td>\n",
       "      <td>5528.0</td>\n",
       "      <td>33.101795</td>\n",
       "      <td>23.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-21</th>\n",
       "      <td>10.562184</td>\n",
       "      <td>0.017740</td>\n",
       "      <td>39.0</td>\n",
       "      <td>359.446080</td>\n",
       "      <td>-1.323443</td>\n",
       "      <td>480.921540</td>\n",
       "      <td>-0.113845</td>\n",
       "      <td>5528.0</td>\n",
       "      <td>33.101795</td>\n",
       "      <td>23.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-22</th>\n",
       "      <td>7.503964</td>\n",
       "      <td>0.013017</td>\n",
       "      <td>33.0</td>\n",
       "      <td>269.737100</td>\n",
       "      <td>-1.946762</td>\n",
       "      <td>310.051800</td>\n",
       "      <td>-0.811650</td>\n",
       "      <td>5528.0</td>\n",
       "      <td>33.101795</td>\n",
       "      <td>23.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-23</th>\n",
       "      <td>5.946538</td>\n",
       "      <td>0.009502</td>\n",
       "      <td>27.0</td>\n",
       "      <td>62.756718</td>\n",
       "      <td>-3.154394</td>\n",
       "      <td>94.282260</td>\n",
       "      <td>-1.902442</td>\n",
       "      <td>5528.0</td>\n",
       "      <td>33.101795</td>\n",
       "      <td>23.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-24</th>\n",
       "      <td>5.238617</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.128628</td>\n",
       "      <td>-3.223255</td>\n",
       "      <td>33.127430</td>\n",
       "      <td>-2.121304</td>\n",
       "      <td>5528.0</td>\n",
       "      <td>33.101795</td>\n",
       "      <td>23.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-25</th>\n",
       "      <td>5.012082</td>\n",
       "      <td>0.004916</td>\n",
       "      <td>18.0</td>\n",
       "      <td>120.962360</td>\n",
       "      <td>-1.154626</td>\n",
       "      <td>170.666760</td>\n",
       "      <td>-0.626316</td>\n",
       "      <td>117368.0</td>\n",
       "      <td>48.062244</td>\n",
       "      <td>29.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-26</th>\n",
       "      <td>7.985351</td>\n",
       "      <td>0.003790</td>\n",
       "      <td>15.0</td>\n",
       "      <td>209.286560</td>\n",
       "      <td>0.691527</td>\n",
       "      <td>287.911600</td>\n",
       "      <td>1.288652</td>\n",
       "      <td>117368.0</td>\n",
       "      <td>48.062244</td>\n",
       "      <td>29.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-27</th>\n",
       "      <td>8.070301</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.586107</td>\n",
       "      <td>-0.361620</td>\n",
       "      <td>15.476177</td>\n",
       "      <td>0.513637</td>\n",
       "      <td>117368.0</td>\n",
       "      <td>48.062244</td>\n",
       "      <td>29.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-28</th>\n",
       "      <td>6.852677</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.144384</td>\n",
       "      <td>-1.123224</td>\n",
       "      <td>0.333512</td>\n",
       "      <td>0.154530</td>\n",
       "      <td>117368.0</td>\n",
       "      <td>48.062244</td>\n",
       "      <td>29.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   m3   swe_avg  swe_max      tp_avg   t2m_avg      tp_max  \\\n",
       "time                                                                         \n",
       "2010-01-01   1.599902  0.010051     10.0   36.596780  0.277207   54.227730   \n",
       "2010-01-02   1.817942  0.003433      6.0   19.432330  2.140078   40.226460   \n",
       "2010-01-03   1.758476  0.000796      4.0    0.766869 -2.116478    1.752489   \n",
       "2010-01-04   1.693347  0.000467      4.0    0.016986 -1.963441    0.045573   \n",
       "2010-01-05   1.662199  0.000412      4.0    0.218129  0.024585    0.302439   \n",
       "2010-01-06   1.614060  0.000275      3.0    0.852008 -0.169998    1.713131   \n",
       "2010-01-07   1.599902  0.000192      3.0   26.847263  1.220284   30.620916   \n",
       "2010-01-08   1.608397  0.000110      2.0   15.534594  0.431471   17.719612   \n",
       "2010-01-09   1.699011  0.000082      2.0    6.499332  1.175823    7.467758   \n",
       "2010-01-10   1.772635  0.000055      1.0    1.533739  0.904211    2.409155   \n",
       "2010-01-11   1.766971  0.000055      1.0    0.102332  0.981723    0.186435   \n",
       "2010-01-12   3.992675  0.000055      1.0  185.137420  2.717574  239.801000   \n",
       "2010-01-13  13.903572  0.272999     39.0  337.503720  2.362755  477.934450   \n",
       "2010-01-14   7.249113  1.071841     89.0   23.814380 -1.772130   32.868492   \n",
       "2010-01-15   4.757230  0.455649     84.0    0.069395 -0.841212    0.087003   \n",
       "2010-01-16   3.879408  0.158208     74.0    0.031073  0.872402    0.031073   \n",
       "2010-01-17   3.794457  0.066458     63.0  106.854400  0.801335  153.129440   \n",
       "2010-01-18  10.760402  0.035041     53.0  459.054380  0.295051  607.063500   \n",
       "2010-01-19  18.689119  0.028945     48.0  395.896820 -0.006726  547.822700   \n",
       "2010-01-20  13.705354  0.023892     45.0  354.958600 -0.787572  482.404750   \n",
       "2010-01-21  10.562184  0.017740     39.0  359.446080 -1.323443  480.921540   \n",
       "2010-01-22   7.503964  0.013017     33.0  269.737100 -1.946762  310.051800   \n",
       "2010-01-23   5.946538  0.009502     27.0   62.756718 -3.154394   94.282260   \n",
       "2010-01-24   5.238617  0.006591     22.0   24.128628 -3.223255   33.127430   \n",
       "2010-01-25   5.012082  0.004916     18.0  120.962360 -1.154626  170.666760   \n",
       "2010-01-26   7.985351  0.003790     15.0  209.286560  0.691527  287.911600   \n",
       "2010-01-27   8.070301  0.002911     14.0   11.586107 -0.361620   15.476177   \n",
       "2010-01-28   6.852677  0.002527     13.0    0.144384 -1.123224    0.333512   \n",
       "\n",
       "             t2m_max  pixel_sum  pixel_mean  pixel_min  pixel_max  \n",
       "time                                                               \n",
       "2010-01-01  1.021534    12514.0   49.074510       34.0       61.0  \n",
       "2010-01-02  2.642189    12514.0   49.074510       34.0       61.0  \n",
       "2010-01-03 -0.916607    12514.0   49.074510       34.0       61.0  \n",
       "2010-01-04 -0.204727    12514.0   49.074510       34.0       61.0  \n",
       "2010-01-05  0.961063    12514.0   49.074510       34.0       61.0  \n",
       "2010-01-06  0.659763    12514.0   49.074510       34.0       61.0  \n",
       "2010-01-07  2.069096    12514.0   49.074510       34.0       61.0  \n",
       "2010-01-08  1.665302    12514.0   49.074510       34.0       61.0  \n",
       "2010-01-09  1.933275   145640.0   44.240580       27.0       82.0  \n",
       "2010-01-10  1.725673   145640.0   44.240580       27.0       82.0  \n",
       "2010-01-11  2.109410   145640.0   44.240580       27.0       82.0  \n",
       "2010-01-12  3.636267   145640.0   44.240580       27.0       82.0  \n",
       "2010-01-13  3.010495   145640.0   44.240580       27.0       82.0  \n",
       "2010-01-14 -0.373926   145640.0   44.240580       27.0       82.0  \n",
       "2010-01-15  0.647146   145640.0   44.240580       27.0       82.0  \n",
       "2010-01-16  2.658576   145640.0   44.240580       27.0       82.0  \n",
       "2010-01-17  1.609707     5528.0   33.101795       23.0       46.0  \n",
       "2010-01-18  0.857865     5528.0   33.101795       23.0       46.0  \n",
       "2010-01-19  1.017462     5528.0   33.101795       23.0       46.0  \n",
       "2010-01-20  0.257326     5528.0   33.101795       23.0       46.0  \n",
       "2010-01-21 -0.113845     5528.0   33.101795       23.0       46.0  \n",
       "2010-01-22 -0.811650     5528.0   33.101795       23.0       46.0  \n",
       "2010-01-23 -1.902442     5528.0   33.101795       23.0       46.0  \n",
       "2010-01-24 -2.121304     5528.0   33.101795       23.0       46.0  \n",
       "2010-01-25 -0.626316   117368.0   48.062244       29.0       74.0  \n",
       "2010-01-26  1.288652   117368.0   48.062244       29.0       74.0  \n",
       "2010-01-27  0.513637   117368.0   48.062244       29.0       74.0  \n",
       "2010-01-28  0.154530   117368.0   48.062244       29.0       74.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gage_df = pd.read_csv('11402000_complete_ts.csv')\n",
    "gage_df.set_index('time', inplace = True)\n",
    "# gage_df['target'] = gage_df['m3'].shift()\n",
    "gage_df.head(28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a32bd937-fee6-46c4-9c9e-16e288300bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_past = 28\n",
    "n_future = 14 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5a066f3b-e058-4db8-a4e3-f7c9e05b36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_gage = '11402000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72234f6-af90-493a-9bbd-fe8c369eb1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "af0dceed-bf3a-4e99-8b69-38d98fb4d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(gage_df) * 0.8)\n",
    "train_df,test_df = gage_df[:train_size], gage_df[train_size:] \n",
    "\n",
    "\n",
    "feature_cols = ['m3','swe_avg','swe_max','tp_avg','t2m_avg','tp_max','t2m_max','pixel_sum','pixel_mean','pixel_min','pixel_max']\n",
    "\n",
    "train = train_df[feature_cols]\n",
    "test = test_df[feature_cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd305ee4-9ac3-412a-817d-de07a2186ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['2010-01-01', '2010-01-02', '2010-01-03', '2010-01-04', '2010-01-05',\n",
       "       '2010-01-06', '2010-01-07', '2010-01-08', '2010-01-09', '2010-01-10',\n",
       "       ...\n",
       "       '2015-07-30', '2015-07-31', '2015-08-01', '2015-08-02', '2015-08-03',\n",
       "       '2015-08-04', '2015-08-05', '2015-08-06', '2015-08-07', '2015-08-08'],\n",
       "      dtype='object', name='time', length=2046)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1d3c0a87-3a0a-48ff-a7f6-3e73bc83e872",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-70-9baa6a697004>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "<ipython-input-70-9baa6a697004>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n"
     ]
    }
   ],
   "source": [
    "# Rescaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "train = train_df\n",
    "scalers={}\n",
    "for i in train_df.columns:\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    s_s = scaler.fit_transform(train[i].values.reshape(-1,1))\n",
    "    s_s=np.reshape(s_s,len(s_s))\n",
    "    scalers['scaler_'+ i] = scaler\n",
    "    train[i]=s_s\n",
    "test = test_df\n",
    "for i in train_df.columns:\n",
    "    scaler = scalers['scaler_'+i]\n",
    "    s_s = scaler.transform(test[i].values.reshape(-1,1))\n",
    "    s_s=np.reshape(s_s,len(s_s))\n",
    "    scalers['scaler_'+i] = scaler\n",
    "    test[i]=s_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e6ed3374-5a07-4671-98d2-d504790ba5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['m3','swe_avg','swe_max','tp_avg','t2m_avg','tp_max','t2m_max','pixel_sum','pixel_mean','pixel_min','pixel_max']\n",
    "X_train, y_train = transform_seq2seq_data(train, target_col = 'm3',\n",
    "                                          feature_col = feature_cols, \n",
    "                                          n_past = 28, \n",
    "                                          n_future = 14)\n",
    "\n",
    "X_test, y_test = transform_seq2seq_data(test, target_col = 'm3',\n",
    "                                          feature_col = feature_cols, \n",
    "                                          n_past = 28, \n",
    "                                          n_future = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90b77a12-9cf4-4747-8da9-1dcf3057ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_target_col = 1\n",
    "\n",
    "\n",
    "# X_train, y_train = split_series(train.values,n_past, n_future)\n",
    "# y_train = y_train[:,:,0]\n",
    "# X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],n_features))\n",
    "# y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], num_target_col))\n",
    "# X_test, y_test = split_series(test.values,n_past, n_future)\n",
    "# y_test = y_test[:,:,0]\n",
    "# X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],n_features))\n",
    "# y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], num_target_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a51f74fd-b420-4f38-b5ad-6d2ad5164279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 28, 11)]     0           []                               \n",
      "                                                                                                  \n",
      " lstm_8 (LSTM)                  [(None, 100),        44800       ['input_3[0][0]']                \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " repeat_vector_2 (RepeatVector)  (None, 14, 100)     0           ['lstm_8[0][0]']                 \n",
      "                                                                                                  \n",
      " lstm_9 (LSTM)                  (None, 14, 100)      80400       ['repeat_vector_2[0][0]',        \n",
      "                                                                  'lstm_8[0][1]',                 \n",
      "                                                                  'lstm_8[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDistri  (None, 14, 1)       101         ['lstm_9[0][0]']                 \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 125,301\n",
      "Trainable params: 125,301\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# E1D1\n",
    "# n_features ==> no of features at each timestep in the data.\n",
    "#\n",
    "num_target_col = 1\n",
    "n_features = len(feature_cols)\n",
    "\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "encoder_l1 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "\n",
    "#\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs1[0])\n",
    "\n",
    "#\n",
    "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_outputs1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_target_col))(decoder_l1)\n",
    "\n",
    "#\n",
    "model_e1d1 = tf.keras.models.Model(encoder_inputs,decoder_outputs1)\n",
    "\n",
    "#\n",
    "model_e1d1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ae9c99d9-90f3-4ccd-93c6-33fc02bfbc2b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "63/63 - 4s - loss: 0.0196 - val_loss: 0.0137 - 4s/epoch - 65ms/step\n",
      "Epoch 2/25\n",
      "63/63 - 1s - loss: 0.0048 - val_loss: 0.0136 - 1s/epoch - 18ms/step\n",
      "Epoch 3/25\n",
      "63/63 - 1s - loss: 0.0045 - val_loss: 0.0138 - 1s/epoch - 18ms/step\n",
      "Epoch 4/25\n",
      "63/63 - 1s - loss: 0.0044 - val_loss: 0.0138 - 1s/epoch - 19ms/step\n",
      "Epoch 5/25\n",
      "63/63 - 1s - loss: 0.0044 - val_loss: 0.0131 - 1s/epoch - 18ms/step\n",
      "Epoch 6/25\n",
      "63/63 - 1s - loss: 0.0044 - val_loss: 0.0132 - 1s/epoch - 18ms/step\n",
      "Epoch 7/25\n",
      "63/63 - 1s - loss: 0.0044 - val_loss: 0.0133 - 1s/epoch - 18ms/step\n",
      "Epoch 8/25\n",
      "63/63 - 1s - loss: 0.0043 - val_loss: 0.0130 - 1s/epoch - 18ms/step\n",
      "Epoch 9/25\n",
      "63/63 - 1s - loss: 0.0042 - val_loss: 0.0130 - 1s/epoch - 18ms/step\n",
      "Epoch 10/25\n",
      "63/63 - 1s - loss: 0.0044 - val_loss: 0.0134 - 1s/epoch - 18ms/step\n",
      "Epoch 11/25\n",
      "63/63 - 1s - loss: 0.0043 - val_loss: 0.0148 - 1s/epoch - 18ms/step\n",
      "Epoch 12/25\n",
      "63/63 - 1s - loss: 0.0042 - val_loss: 0.0134 - 1s/epoch - 18ms/step\n",
      "Epoch 13/25\n",
      "63/63 - 1s - loss: 0.0041 - val_loss: 0.0139 - 1s/epoch - 18ms/step\n",
      "Epoch 14/25\n",
      "63/63 - 1s - loss: 0.0040 - val_loss: 0.0148 - 1s/epoch - 18ms/step\n",
      "Epoch 15/25\n",
      "63/63 - 1s - loss: 0.0040 - val_loss: 0.0137 - 1s/epoch - 18ms/step\n",
      "Epoch 16/25\n",
      "63/63 - 1s - loss: 0.0039 - val_loss: 0.0135 - 1s/epoch - 19ms/step\n",
      "Epoch 17/25\n",
      "63/63 - 1s - loss: 0.0039 - val_loss: 0.0134 - 1s/epoch - 18ms/step\n",
      "Epoch 18/25\n",
      "63/63 - 1s - loss: 0.0038 - val_loss: 0.0141 - 1s/epoch - 18ms/step\n",
      "Epoch 19/25\n",
      "63/63 - 1s - loss: 0.0039 - val_loss: 0.0130 - 1s/epoch - 18ms/step\n",
      "Epoch 20/25\n",
      "63/63 - 1s - loss: 0.0038 - val_loss: 0.0146 - 1s/epoch - 18ms/step\n",
      "Epoch 21/25\n",
      "63/63 - 1s - loss: 0.0038 - val_loss: 0.0136 - 1s/epoch - 18ms/step\n",
      "Epoch 22/25\n",
      "63/63 - 1s - loss: 0.0035 - val_loss: 0.0145 - 1s/epoch - 18ms/step\n",
      "Epoch 23/25\n",
      "63/63 - 1s - loss: 0.0036 - val_loss: 0.0150 - 1s/epoch - 18ms/step\n",
      "Epoch 24/25\n",
      "63/63 - 1s - loss: 0.0036 - val_loss: 0.0136 - 1s/epoch - 18ms/step\n",
      "Epoch 25/25\n",
      "63/63 - 1s - loss: 0.0036 - val_loss: 0.0143 - 1s/epoch - 18ms/step\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 0.01 * 0.90 ** x)\n",
    "model_e1d1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=tf.keras.losses.Huber())\n",
    "history_e1d1=model_e1d1.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),batch_size=32,verbose=2\n",
    "   \n",
    "                            # callbacks=[reduce_lr]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f8f384a0-0383-475f-9628-857ae1a867be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 28, 11)]     0           []                               \n",
      "                                                                                                  \n",
      " lstm_10 (LSTM)                 [(None, 28, 100),    44800       ['input_4[0][0]']                \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " lstm_11 (LSTM)                 [(None, 100),        80400       ['lstm_10[0][0]']                \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " repeat_vector_3 (RepeatVector)  (None, 14, 100)     0           ['lstm_11[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_12 (LSTM)                 (None, 14, 100)      80400       ['repeat_vector_3[0][0]',        \n",
      "                                                                  'lstm_10[0][1]',                \n",
      "                                                                  'lstm_10[0][2]']                \n",
      "                                                                                                  \n",
      " lstm_13 (LSTM)                 (None, 14, 100)      80400       ['lstm_12[0][0]',                \n",
      "                                                                  'lstm_11[0][1]',                \n",
      "                                                                  'lstm_11[0][2]']                \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDistri  (None, 14, 1)       101         ['lstm_13[0][0]']                \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 286,101\n",
      "Trainable params: 286,101\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# E2D2\n",
    "# n_features ==> no of features at each timestep in the data.\n",
    "#\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "encoder_l1 = tf.keras.layers.LSTM(100,return_sequences = True, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "encoder_l2 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
    "encoder_states2 = encoder_outputs2[1:]\n",
    "#\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n",
    "#\n",
    "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_l2 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_l1,initial_state = encoder_states2)\n",
    "decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_target_col))(decoder_l2)\n",
    "#\n",
    "model_e2d2 = tf.keras.models.Model(encoder_inputs,decoder_outputs2)\n",
    "#\n",
    "model_e2d2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "792cf2ba-be12-4911-98e8-4f7bb8601870",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "63/63 - 8s - loss: 0.0253 - val_loss: 0.0141 - lr: 0.0010 - 8s/epoch - 133ms/step\n",
      "Epoch 2/25\n",
      "63/63 - 2s - loss: 0.0049 - val_loss: 0.0142 - lr: 9.0000e-04 - 2s/epoch - 37ms/step\n",
      "Epoch 3/25\n",
      "63/63 - 2s - loss: 0.0046 - val_loss: 0.0143 - lr: 8.1000e-04 - 2s/epoch - 37ms/step\n",
      "Epoch 4/25\n",
      "63/63 - 2s - loss: 0.0045 - val_loss: 0.0144 - lr: 7.2900e-04 - 2s/epoch - 36ms/step\n",
      "Epoch 5/25\n",
      "63/63 - 2s - loss: 0.0044 - val_loss: 0.0138 - lr: 6.5610e-04 - 2s/epoch - 37ms/step\n",
      "Epoch 6/25\n",
      "63/63 - 2s - loss: 0.0044 - val_loss: 0.0137 - lr: 5.9049e-04 - 2s/epoch - 37ms/step\n",
      "Epoch 7/25\n",
      "63/63 - 2s - loss: 0.0043 - val_loss: 0.0137 - lr: 5.3144e-04 - 2s/epoch - 37ms/step\n",
      "Epoch 8/25\n",
      "63/63 - 2s - loss: 0.0043 - val_loss: 0.0139 - lr: 4.7830e-04 - 2s/epoch - 36ms/step\n",
      "Epoch 9/25\n",
      "63/63 - 2s - loss: 0.0042 - val_loss: 0.0137 - lr: 4.3047e-04 - 2s/epoch - 37ms/step\n",
      "Epoch 10/25\n",
      "63/63 - 2s - loss: 0.0044 - val_loss: 0.0138 - lr: 3.8742e-04 - 2s/epoch - 36ms/step\n",
      "Epoch 11/25\n",
      "63/63 - 2s - loss: 0.0043 - val_loss: 0.0141 - lr: 3.4868e-04 - 2s/epoch - 37ms/step\n",
      "Epoch 12/25\n",
      "63/63 - 2s - loss: 0.0042 - val_loss: 0.0140 - lr: 3.1381e-04 - 2s/epoch - 37ms/step\n",
      "Epoch 13/25\n",
      "63/63 - 2s - loss: 0.0041 - val_loss: 0.0139 - lr: 2.8243e-04 - 2s/epoch - 37ms/step\n",
      "Epoch 14/25\n",
      "63/63 - 2s - loss: 0.0041 - val_loss: 0.0141 - lr: 2.5419e-04 - 2s/epoch - 36ms/step\n",
      "Epoch 15/25\n",
      "63/63 - 2s - loss: 0.0040 - val_loss: 0.0139 - lr: 2.2877e-04 - 2s/epoch - 37ms/step\n",
      "Epoch 16/25\n",
      "63/63 - 2s - loss: 0.0040 - val_loss: 0.0137 - lr: 2.0589e-04 - 2s/epoch - 36ms/step\n",
      "Epoch 17/25\n",
      "63/63 - 2s - loss: 0.0040 - val_loss: 0.0141 - lr: 1.8530e-04 - 2s/epoch - 36ms/step\n",
      "Epoch 18/25\n",
      "63/63 - 2s - loss: 0.0040 - val_loss: 0.0141 - lr: 1.6677e-04 - 2s/epoch - 36ms/step\n",
      "Epoch 19/25\n",
      "63/63 - 2s - loss: 0.0040 - val_loss: 0.0135 - lr: 1.5009e-04 - 2s/epoch - 36ms/step\n",
      "Epoch 20/25\n",
      "63/63 - 2s - loss: 0.0039 - val_loss: 0.0142 - lr: 1.3509e-04 - 2s/epoch - 36ms/step\n",
      "Epoch 21/25\n",
      "63/63 - 2s - loss: 0.0039 - val_loss: 0.0141 - lr: 1.2158e-04 - 2s/epoch - 36ms/step\n",
      "Epoch 22/25\n",
      "63/63 - 2s - loss: 0.0039 - val_loss: 0.0144 - lr: 1.0942e-04 - 2s/epoch - 36ms/step\n",
      "Epoch 23/25\n",
      "63/63 - 2s - loss: 0.0039 - val_loss: 0.0139 - lr: 9.8477e-05 - 2s/epoch - 37ms/step\n",
      "Epoch 24/25\n",
      "63/63 - 2s - loss: 0.0038 - val_loss: 0.0139 - lr: 8.8629e-05 - 2s/epoch - 37ms/step\n",
      "Epoch 25/25\n",
      "63/63 - 2s - loss: 0.0039 - val_loss: 0.0139 - lr: 7.9766e-05 - 2s/epoch - 36ms/step\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 0.001 * 0.90 ** x)\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "model_e2d2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=tf.keras.losses.Huber())\n",
    "history_e2d2=model_e2d2.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),batch_size=32,\n",
    "                            verbose=2,\n",
    "                            callbacks=[reduce_lr,early_stopping_callback]\n",
    "                           \n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "80440028-4c0d-4f81-9423-44ce7c4b4ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 6ms/step\n",
      "15/15 [==============================] - 1s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_e1d1=model_e1d1.predict(X_test)\n",
    "pred_e2d2=model_e2d2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ea4c82-4d61-47ff-a783-18287e6d1627",
   "metadata": {},
   "source": [
    "## Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c27aa040-0868-4d5e-b901-6c214098ef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_e1d1 = pred_e1d1.reshape(y_test.shape[0], y_test.shape[1])\n",
    "pred_e2d2 = pred_e2d2.reshape(y_test.shape[0], y_test.shape[1])\n",
    "\n",
    "pred_e1d1_inverse = scalers['scaler_m3'].inverse_transform(pred_e1d1)\n",
    "pred_e2d2_inverse = scalers['scaler_m3'].inverse_transform(pred_e2d2)\n",
    "y_test_inverse = scalers['scaler_m3'].inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "92026c49-60de-4702-88e9-e696d2db9804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30865363,  0.30015857,  0.30015857, ...,  0.32847542,\n",
       "         0.35962395,  0.36528732],\n",
       "       [ 0.30015857,  0.30015857,  0.24805558, ...,  0.35962395,\n",
       "         0.36528732,  0.34546553],\n",
       "       [ 0.30015857,  0.24805558,  0.26447935, ...,  0.36528732,\n",
       "         0.34546553,  0.30015857],\n",
       "       ...,\n",
       "       [71.07528495, 24.26753753, 14.89466131, ...,  4.67227969,\n",
       "         4.38911122,  4.10594276],\n",
       "       [24.26753753, 14.89466131, 11.10020386, ...,  4.38911122,\n",
       "         4.10594276,  3.93604168],\n",
       "       [14.89466131, 11.10020386,  9.08970776, ...,  4.10594276,\n",
       "         3.93604168,  3.79445744]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "33dcbb5e-0aaf-4719-91b3-bd257cebe923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.8103908e+00, -1.2263874e+00, -9.3075371e-01, ...,\n",
       "         1.8495232e-01,  2.1352266e-01,  2.4294977e-01],\n",
       "       [-1.0934491e+00, -1.0562443e+00, -9.7216314e-01, ...,\n",
       "         1.7142780e-01,  2.1871765e-01,  2.6346225e-01],\n",
       "       [-7.5225180e-01, -1.0711981e+00, -1.1180240e+00, ...,\n",
       "        -2.0264307e-02,  3.5388507e-02,  8.7104328e-02],\n",
       "       ...,\n",
       "       [ 1.9868876e+01,  1.7269114e+01,  1.4758994e+01, ...,\n",
       "         7.4834871e+00,  7.5325823e+00,  7.6333728e+00],\n",
       "       [ 2.8800196e+01,  2.4107794e+01,  1.9865623e+01, ...,\n",
       "         7.5372882e+00,  7.5969033e+00,  7.7336950e+00],\n",
       "       [ 2.1664862e+01,  1.8283188e+01,  1.5024749e+01, ...,\n",
       "         6.0462227e+00,  6.1434269e+00,  6.2971783e+00]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_e1d1_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b63bb2f6-7530-4777-8d27-0175597234d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_root_mean_squared_error(true, pred):\n",
    "    num = np.sum(np.square(true - pred))\n",
    "    den = np.sum(np.square(pred))\n",
    "    squared_error = num/den\n",
    "    rrmse_loss = np.sqrt(squared_error)\n",
    "    return rrmse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3af39f1a-7db9-4d93-ad33-16e45230c504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c1e9e472-40bd-4483-b72b-bee24d89b153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.8103908 , -1.2263874 , -0.9307537 , -0.49775174, -0.19085045,\n",
       "       -0.02035625,  0.0604398 ,  0.09711816,  0.11794826,  0.13685584,\n",
       "        0.15898156,  0.18495232,  0.21352266,  0.24294977, -1.0934491 ,\n",
       "       -1.0562443 , -0.97216314, -0.6396255 , -0.36937746, -0.19723657,\n",
       "       -0.0943984 , -0.02726061,  0.0255335 ,  0.07439061,  0.12294681,\n",
       "        0.1714278 ,  0.21871765,  0.26346225], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_e1d1_inverse.reshape(-1)[:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b37fa2e3-ab12-4e3f-872d-8710058c7898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 12.119650953513935\n",
      "MAPE = 1.377658662358193\n",
      "RRMSE = 1.6816127975189923\n"
     ]
    }
   ],
   "source": [
    "# 1st run\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test_inverse.reshape(-1), pred_e1d1_inverse.reshape(-1)))\n",
    "final_mape = mean_absolute_percentage_error(y_test_inverse.reshape(-1), pred_e1d1_inverse.reshape(-1))\n",
    "final_rrmse = relative_root_mean_squared_error(y_test_inverse.reshape(-1), pred_e1d1_inverse.reshape(-1))\n",
    "                     \n",
    "print(f'RMSE = {final_rmse}')\n",
    "print(f'MAPE = {final_mape}')\n",
    "print(f'RRMSE = {final_rrmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f3d2b390-7235-44a8-9729-ea9584428d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 5.859020443844475\n",
      "MAPE = 1.377658662358193\n",
      "RRMSE = 1.380964439144476\n"
     ]
    }
   ],
   "source": [
    "# 1nd run\n",
    "rmse_list = []\n",
    "mape_list = []\n",
    "rrmse_list = []\n",
    "\n",
    "for pred, truth in zip(pred_e1d1_inverse, y_test_inverse):\n",
    "    rmse_list.append(np.sqrt(mean_squared_error(truth, pred)))\n",
    "    mape_list.append(mean_absolute_percentage_error(truth, pred))\n",
    "    rrmse_list.append(relative_root_mean_squared_error(truth, pred))\n",
    "    \n",
    "final_rmse = np.mean(rmse_list)\n",
    "final_mape = np.mean(mape_list)\n",
    "final_rrmse = np.mean(rrmse_list)\n",
    "\n",
    "print(f'RMSE = {final_rmse}')\n",
    "print(f'MAPE = {final_mape}')\n",
    "print(f'RRMSE = {final_rrmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f6ec210-6824-4e92-a6d9-d658091b5d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 12.182589283034813\n",
      "MAPE = 1.5755370753380615\n",
      "RRMSE = 2.2385338903336236\n"
     ]
    }
   ],
   "source": [
    "# for pred, truth in zip(pred_e1d1_inverse, y_test_inverse):\n",
    "#     rmse_list.append(np.sqrt(mean_squared_error(truth, pred)))\n",
    "#     mape_list.append(mean_absolute_percentage_error(truth, pred))\n",
    "#     rrmse_list.append(relative_root_mean_squared_error(truth, pred))\n",
    "\n",
    "# 2nd run\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test_inverse.reshape(-1), pred_e1d1_inverse.reshape(-1)))\n",
    "final_mape = mean_absolute_percentage_error(y_test_inverse.reshape(-1), pred_e1d1_inverse.reshape(-1))\n",
    "final_rrmse = relative_root_mean_squared_error(y_test_inverse.reshape(-1), pred_e1d1_inverse.reshape(-1))\n",
    "                     \n",
    "print(f'RMSE = {final_rmse}')\n",
    "print(f'MAPE = {final_mape}')\n",
    "print(f'RRMSE = {final_rrmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1fc37ce-4d06-4367-ae60-4ff341ce00c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 5.989928050479377\n",
      "MAPE = 1.5755370753380615\n",
      "RRMSE = 1.4608263049468748\n"
     ]
    }
   ],
   "source": [
    "# 2nd run\n",
    "\n",
    "rmse_list = []\n",
    "mape_list = []\n",
    "rrmse_list = []\n",
    "\n",
    "for pred, truth in zip(pred_e1d1_inverse, y_test_inverse):\n",
    "    rmse_list.append(np.sqrt(mean_squared_error(truth, pred)))\n",
    "    mape_list.append(mean_absolute_percentage_error(truth, pred))\n",
    "    rrmse_list.append(relative_root_mean_squared_error(truth, pred))\n",
    "    \n",
    "final_rmse = np.mean(rmse_list)\n",
    "final_mape = np.mean(mape_list)\n",
    "final_rrmse = np.mean(rrmse_list)\n",
    "\n",
    "print(f'RMSE = {final_rmse}')\n",
    "print(f'MAPE = {final_mape}')\n",
    "print(f'RRMSE = {final_rrmse}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd24e896-af9e-4e96-88c4-724a17136e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 5.770056141377242\n",
      "MAPE = 1.1326347326031592\n",
      "RRMSE = 1.5695356506080462\n"
     ]
    }
   ],
   "source": [
    "# reported\n",
    "rmse_list = []\n",
    "mape_list = []\n",
    "rrmse_list = []\n",
    "\n",
    "for pred, truth in zip(pred_e2d2_inverse, y_test_inverse):\n",
    "    rmse_list.append(np.sqrt(mean_squared_error(truth, pred)))\n",
    "    mape_list.append(mean_absolute_percentage_error(truth, pred))\n",
    "    rrmse_list.append(relative_root_mean_squared_error(truth, pred))\n",
    "    \n",
    "final_rmse = np.mean(rmse_list)\n",
    "final_mape = np.mean(mape_list)\n",
    "final_rrmse = np.mean(rrmse_list)\n",
    "\n",
    "print(f'RMSE = {final_rmse}')\n",
    "print(f'MAPE = {final_mape}')\n",
    "print(f'RRMSE = {final_rrmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6a745b0a-ef6f-4270-86a7-5b3e69de1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index,i in enumerate(train.columns):\n",
    "#     scaler = scalers['scaler_'+i]\n",
    "#     # pred1_e1d1[:,:,index]=scaler.inverse_transform(pred1_e1d1[:,:,index])\n",
    "#     pred_e1d1[:,:,index]=scaler.inverse_transform(pred_e1d1[:,:,index])\n",
    "#     # pred1_e2d2[:,:,index]=scaler.inverse_transform(pred1_e2d2[:,:,index])\n",
    "#     pred_e2d2[:,:,index]=scaler.inverse_transform(pred_e2d2[:,:,index])\n",
    "#     y_train[:,:,index]=scaler.inverse_transform(y_train[:,:,index])\n",
    "#     y_test[:,:,index]=scaler.inverse_transform(y_test[:,:,index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26294e6c-ab85-4f8d-9c87-79dd1596dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_e1d1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a126b2a-ba7c-4f58-bc50-98ccd3b6a8c1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# for index,i in enumerate([target_gage]):\n",
    "#     print(i)\n",
    "#     for j in range(1,6):\n",
    "#         print(\"Day \",j,\":\")\n",
    "#         print(\"MAE-E1D1 : \",mean_absolute_error(y_test[:,j-1,index],pred_e1d1[:,j-1,index]),end=\", \")\n",
    "#         print(\"MAE-E2D2 : \",mean_absolute_error(y_test[:,j-1,index],pred_e2d2[:,j-1,index]))\n",
    "#         print(\"RMSE-E1D1 : \",np.sqrt(mean_squared_error(y_test[:,j-1,index],pred_e1d1[:,j-1,index])),end=\", \")\n",
    "#         print(\"RMSE-E2D2 : \",np.sqrt(mean_squared_error(y_test[:,j-1,index],pred_e2d2[:,j-1,index])))\n",
    "        \n",
    "#     print()\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d0e0f7bd-f17f-4c4a-b64a-67aa69ec71ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# biweekly_error = []\n",
    "# for pred, ground_truth in zip(pred_e1d1.reshape(pred_e1d1.shape[0],pred_e1d1.shape[1]),\n",
    "#                               y_test.reshape(y_test.shape[0],y_test.shape[1])):\n",
    "#     rmse = np.sqrt(mean_squared_error(pred, ground_truth))\n",
    "#     biweekly_error.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ea80701d-3089-4f7b-a8ec-bf25bc6d2307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24849b5d-0097-4d0c-b6c4-01b4e77f2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(biweekly_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c77088e5-c8f9-4b93-9bd3-9abdc61ad415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled_biweekly_error = [n for n in biweekly_error if n < 100]\n",
    "# sns.histplot(sampled_biweekly_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b986a629-66d9-430b-9203-28390ca25712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a4c45ac-edcf-49d3-a5c5-2568a3eeadcf",
   "metadata": {},
   "source": [
    "# Multivariate LSTM Single-Step Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29f519fa-2d53-4442-a4a4-b71efd720ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "# tf.random.set_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3d6bc78-5f9d-4e65-900a-b861ff140927",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['m3','swe_avg','swe_max','tp_avg','t2m_avg','tp_max','t2m_max','pixel_sum','pixel_mean','pixel_min','pixel_max']\n",
    "X_train, y_train = transform_seq2seq_data(train, target_col = 'm3',\n",
    "                                          feature_col = feature_cols, \n",
    "                                          n_past = 28, \n",
    "                                          n_future = 1)\n",
    "\n",
    "X_test, y_test = transform_seq2seq_data(test, target_col = 'm3',\n",
    "                                          feature_col = feature_cols, \n",
    "                                          n_past = 28, \n",
    "                                          n_future = 1)\n",
    "\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test = y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a4fe0d8e-504a-48e7-ab41-76257bf400e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_past = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dcb958df-dddc-455b-89af-d1595e9cfa3a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "505/505 - 4s - loss: 0.0451 - 4s/epoch - 8ms/step\n",
      "Epoch 2/20\n",
      "505/505 - 3s - loss: 0.0105 - 3s/epoch - 5ms/step\n",
      "Epoch 3/20\n",
      "505/505 - 3s - loss: 0.0092 - 3s/epoch - 5ms/step\n",
      "Epoch 4/20\n",
      "505/505 - 3s - loss: 0.0082 - 3s/epoch - 5ms/step\n",
      "Epoch 5/20\n",
      "505/505 - 3s - loss: 0.0075 - 3s/epoch - 5ms/step\n",
      "Epoch 6/20\n",
      "505/505 - 3s - loss: 0.0070 - 3s/epoch - 5ms/step\n",
      "Epoch 7/20\n",
      "505/505 - 3s - loss: 0.0069 - 3s/epoch - 6ms/step\n",
      "Epoch 8/20\n",
      "505/505 - 3s - loss: 0.0065 - 3s/epoch - 6ms/step\n",
      "Epoch 9/20\n",
      "505/505 - 3s - loss: 0.0064 - 3s/epoch - 5ms/step\n",
      "Epoch 10/20\n",
      "505/505 - 3s - loss: 0.0063 - 3s/epoch - 5ms/step\n",
      "Epoch 11/20\n",
      "505/505 - 3s - loss: 0.0060 - 3s/epoch - 5ms/step\n",
      "Epoch 12/20\n",
      "505/505 - 3s - loss: 0.0059 - 3s/epoch - 6ms/step\n",
      "Epoch 13/20\n",
      "505/505 - 3s - loss: 0.0058 - 3s/epoch - 5ms/step\n",
      "Epoch 14/20\n",
      "505/505 - 3s - loss: 0.0058 - 3s/epoch - 5ms/step\n",
      "Epoch 15/20\n",
      "505/505 - 3s - loss: 0.0057 - 3s/epoch - 6ms/step\n",
      "Epoch 16/20\n",
      "505/505 - 3s - loss: 0.0056 - 3s/epoch - 5ms/step\n",
      "Epoch 17/20\n",
      "505/505 - 3s - loss: 0.0056 - 3s/epoch - 5ms/step\n",
      "Epoch 18/20\n",
      "505/505 - 3s - loss: 0.0054 - 3s/epoch - 6ms/step\n",
      "Epoch 19/20\n",
      "505/505 - 3s - loss: 0.0054 - 3s/epoch - 5ms/step\n",
      "Epoch 20/20\n",
      "505/505 - 3s - loss: 0.0053 - 3s/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb97e2050d0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(n_past,11)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=4, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5ca33fd-2aae-496a-8924-e78e0b07b364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 4)                 256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 261\n",
      "Trainable params: 261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a08ca16f-8327-4d01-8302-f112db38d189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "single_step_lstm_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fcb192a3-15b9-47a9-bd2c-ad56a2f6fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_step_lstm_pred = single_step_lstm_pred.reshape(y_test.shape[0])\n",
    "\n",
    "\n",
    "single_step_lstm_pred_inverse = scalers['scaler_m3'].inverse_transform([single_step_lstm_pred])\n",
    "y_test_inverse = scalers['scaler_m3'].inverse_transform([y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76186ef0-d51a-4a7b-af73-99161a85c71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.11770290937528494\n",
      "MAPE = 0.2031870309762798\n",
      "RRMSE = 0.12671778208413098\n"
     ]
    }
   ],
   "source": [
    "final_rmse = np.sqrt(mean_squared_error(y_test_inverse, single_step_lstm_pred_inverse))\n",
    "final_mape = mean_absolute_percentage_error(y_test_inverse, single_step_lstm_pred_inverse)\n",
    "final_rrmse = relative_root_mean_squared_error(y_test_inverse, single_step_lstm_pred_inverse)\n",
    "\n",
    "print(f'RMSE = {final_rmse}')\n",
    "print(f'MAPE = {final_mape}')\n",
    "print(f'RRMSE = {final_rrmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9197e8-6dbf-417a-8224-c31424cb2c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f92da5d-3da9-4534-84c3-f2708f9ec53a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002f6384-6f70-4f24-a305-f68afabda03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442439e9-86fc-4536-a832-71519561c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transform_single_step_data(df, target_col, feature_col, n_past, n_future = 1):\n",
    "\n",
    "#     X_list = []\n",
    "#     y_list = []\n",
    "#     for i in range(n_past,len(df) - n_future):\n",
    "#         y = df.iloc[i:i + 14][target_col].values.tolist()\n",
    "#         y_list.append(y)\n",
    "\n",
    "#         X = df.iloc[i - n_past: i][feature_cols].values.tolist()\n",
    "#         X_list.append(X)\n",
    "#     return np.array(X_list), np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9be57ac1-55be-4363-b5d5-ca24c6f3c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['m3','swe_avg','swe_max','tp_avg','t2m_avg','tp_max','t2m_max','pixel_sum','pixel_mean','pixel_min','pixel_max']\n",
    "X_train, y_train = transform_seq2seq_data(train, target_col = 'm3',\n",
    "                                          feature_col = feature_cols, \n",
    "                                          n_past = 28, \n",
    "                                          n_future = 1)\n",
    "\n",
    "X_test, y_test = transform_seq2seq_data(test, target_col = 'm3',\n",
    "                                          feature_col = feature_cols, \n",
    "                                          n_past = 28, \n",
    "                                          n_future = 1)\n",
    "\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test = y_test.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "39139dc5-e98b-4725-b788-6f86eec3dd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m3</th>\n",
       "      <th>swe_avg</th>\n",
       "      <th>swe_max</th>\n",
       "      <th>tp_avg</th>\n",
       "      <th>t2m_avg</th>\n",
       "      <th>tp_max</th>\n",
       "      <th>t2m_max</th>\n",
       "      <th>pixel_sum</th>\n",
       "      <th>pixel_mean</th>\n",
       "      <th>pixel_min</th>\n",
       "      <th>pixel_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>-0.980240</td>\n",
       "      <td>-0.999977</td>\n",
       "      <td>-0.992416</td>\n",
       "      <td>-0.932862</td>\n",
       "      <td>-0.269596</td>\n",
       "      <td>-0.917210</td>\n",
       "      <td>-0.284100</td>\n",
       "      <td>-0.981680</td>\n",
       "      <td>-0.710263</td>\n",
       "      <td>-0.591837</td>\n",
       "      <td>-0.925203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>-0.977130</td>\n",
       "      <td>-0.999992</td>\n",
       "      <td>-0.995449</td>\n",
       "      <td>-0.964351</td>\n",
       "      <td>-0.184114</td>\n",
       "      <td>-0.938586</td>\n",
       "      <td>-0.211043</td>\n",
       "      <td>-0.981680</td>\n",
       "      <td>-0.710263</td>\n",
       "      <td>-0.591837</td>\n",
       "      <td>-0.925203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>-0.977978</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>-0.996966</td>\n",
       "      <td>-0.998593</td>\n",
       "      <td>-0.379435</td>\n",
       "      <td>-0.997324</td>\n",
       "      <td>-0.371469</td>\n",
       "      <td>-0.981680</td>\n",
       "      <td>-0.710263</td>\n",
       "      <td>-0.591837</td>\n",
       "      <td>-0.925203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>-0.978907</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-0.996966</td>\n",
       "      <td>-0.999969</td>\n",
       "      <td>-0.372413</td>\n",
       "      <td>-0.999930</td>\n",
       "      <td>-0.339378</td>\n",
       "      <td>-0.981680</td>\n",
       "      <td>-0.710263</td>\n",
       "      <td>-0.591837</td>\n",
       "      <td>-0.925203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>-0.979352</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-0.996966</td>\n",
       "      <td>-0.999600</td>\n",
       "      <td>-0.281188</td>\n",
       "      <td>-0.999538</td>\n",
       "      <td>-0.286826</td>\n",
       "      <td>-0.981680</td>\n",
       "      <td>-0.710263</td>\n",
       "      <td>-0.591837</td>\n",
       "      <td>-0.925203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>-0.980038</td>\n",
       "      <td>-0.999999</td>\n",
       "      <td>-0.997725</td>\n",
       "      <td>-0.998437</td>\n",
       "      <td>-0.290117</td>\n",
       "      <td>-0.997385</td>\n",
       "      <td>-0.300408</td>\n",
       "      <td>-0.981680</td>\n",
       "      <td>-0.710263</td>\n",
       "      <td>-0.591837</td>\n",
       "      <td>-0.925203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>-0.980240</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.997725</td>\n",
       "      <td>-0.950748</td>\n",
       "      <td>-0.226321</td>\n",
       "      <td>-0.953251</td>\n",
       "      <td>-0.236877</td>\n",
       "      <td>-0.981680</td>\n",
       "      <td>-0.710263</td>\n",
       "      <td>-0.591837</td>\n",
       "      <td>-0.925203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>-0.980119</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.998483</td>\n",
       "      <td>-0.971501</td>\n",
       "      <td>-0.262517</td>\n",
       "      <td>-0.972947</td>\n",
       "      <td>-0.255080</td>\n",
       "      <td>-0.981680</td>\n",
       "      <td>-0.710263</td>\n",
       "      <td>-0.591837</td>\n",
       "      <td>-0.925203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-09</th>\n",
       "      <td>-0.978827</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.998483</td>\n",
       "      <td>-0.988077</td>\n",
       "      <td>-0.228361</td>\n",
       "      <td>-0.988599</td>\n",
       "      <td>-0.243000</td>\n",
       "      <td>-0.786785</td>\n",
       "      <td>-0.755045</td>\n",
       "      <td>-0.687075</td>\n",
       "      <td>-0.856911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-10</th>\n",
       "      <td>-0.977777</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999242</td>\n",
       "      <td>-0.997186</td>\n",
       "      <td>-0.240825</td>\n",
       "      <td>-0.996322</td>\n",
       "      <td>-0.252358</td>\n",
       "      <td>-0.786785</td>\n",
       "      <td>-0.755045</td>\n",
       "      <td>-0.687075</td>\n",
       "      <td>-0.856911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-11</th>\n",
       "      <td>-0.977857</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999242</td>\n",
       "      <td>-0.999812</td>\n",
       "      <td>-0.237268</td>\n",
       "      <td>-0.999715</td>\n",
       "      <td>-0.235060</td>\n",
       "      <td>-0.786785</td>\n",
       "      <td>-0.755045</td>\n",
       "      <td>-0.687075</td>\n",
       "      <td>-0.856911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-12</th>\n",
       "      <td>-0.946115</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999242</td>\n",
       "      <td>-0.660361</td>\n",
       "      <td>-0.157615</td>\n",
       "      <td>-0.633892</td>\n",
       "      <td>-0.166231</td>\n",
       "      <td>-0.786785</td>\n",
       "      <td>-0.755045</td>\n",
       "      <td>-0.687075</td>\n",
       "      <td>-0.856911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-13</th>\n",
       "      <td>-0.804771</td>\n",
       "      <td>-0.999374</td>\n",
       "      <td>-0.970421</td>\n",
       "      <td>-0.380842</td>\n",
       "      <td>-0.173896</td>\n",
       "      <td>-0.270329</td>\n",
       "      <td>-0.194440</td>\n",
       "      <td>-0.786785</td>\n",
       "      <td>-0.755045</td>\n",
       "      <td>-0.687075</td>\n",
       "      <td>-0.856911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-14</th>\n",
       "      <td>-0.899673</td>\n",
       "      <td>-0.997541</td>\n",
       "      <td>-0.932499</td>\n",
       "      <td>-0.956312</td>\n",
       "      <td>-0.363634</td>\n",
       "      <td>-0.949819</td>\n",
       "      <td>-0.347005</td>\n",
       "      <td>-0.786785</td>\n",
       "      <td>-0.755045</td>\n",
       "      <td>-0.687075</td>\n",
       "      <td>-0.856911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-15</th>\n",
       "      <td>-0.935212</td>\n",
       "      <td>-0.998955</td>\n",
       "      <td>-0.936291</td>\n",
       "      <td>-0.999873</td>\n",
       "      <td>-0.320917</td>\n",
       "      <td>-0.999867</td>\n",
       "      <td>-0.300977</td>\n",
       "      <td>-0.786785</td>\n",
       "      <td>-0.755045</td>\n",
       "      <td>-0.687075</td>\n",
       "      <td>-0.856911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-16</th>\n",
       "      <td>-0.947731</td>\n",
       "      <td>-0.999637</td>\n",
       "      <td>-0.943876</td>\n",
       "      <td>-0.999943</td>\n",
       "      <td>-0.242284</td>\n",
       "      <td>-0.999953</td>\n",
       "      <td>-0.210304</td>\n",
       "      <td>-0.786785</td>\n",
       "      <td>-0.755045</td>\n",
       "      <td>-0.687075</td>\n",
       "      <td>-0.856911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-17</th>\n",
       "      <td>-0.948942</td>\n",
       "      <td>-0.999848</td>\n",
       "      <td>-0.952218</td>\n",
       "      <td>-0.803973</td>\n",
       "      <td>-0.245545</td>\n",
       "      <td>-0.766215</td>\n",
       "      <td>-0.257586</td>\n",
       "      <td>-0.991907</td>\n",
       "      <td>-0.858235</td>\n",
       "      <td>-0.741497</td>\n",
       "      <td>-0.973984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-18</th>\n",
       "      <td>-0.849597</td>\n",
       "      <td>-0.999920</td>\n",
       "      <td>-0.959803</td>\n",
       "      <td>-0.157855</td>\n",
       "      <td>-0.268777</td>\n",
       "      <td>-0.073186</td>\n",
       "      <td>-0.291478</td>\n",
       "      <td>-0.991907</td>\n",
       "      <td>-0.858235</td>\n",
       "      <td>-0.741497</td>\n",
       "      <td>-0.973984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-19</th>\n",
       "      <td>-0.736521</td>\n",
       "      <td>-0.999934</td>\n",
       "      <td>-0.963595</td>\n",
       "      <td>-0.273719</td>\n",
       "      <td>-0.282625</td>\n",
       "      <td>-0.163630</td>\n",
       "      <td>-0.284283</td>\n",
       "      <td>-0.991907</td>\n",
       "      <td>-0.858235</td>\n",
       "      <td>-0.741497</td>\n",
       "      <td>-0.973984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-20</th>\n",
       "      <td>-0.807597</td>\n",
       "      <td>-0.999945</td>\n",
       "      <td>-0.965870</td>\n",
       "      <td>-0.348821</td>\n",
       "      <td>-0.318456</td>\n",
       "      <td>-0.263504</td>\n",
       "      <td>-0.318549</td>\n",
       "      <td>-0.991907</td>\n",
       "      <td>-0.858235</td>\n",
       "      <td>-0.741497</td>\n",
       "      <td>-0.973984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-21</th>\n",
       "      <td>-0.852424</td>\n",
       "      <td>-0.999959</td>\n",
       "      <td>-0.970421</td>\n",
       "      <td>-0.340588</td>\n",
       "      <td>-0.343045</td>\n",
       "      <td>-0.265769</td>\n",
       "      <td>-0.335281</td>\n",
       "      <td>-0.991907</td>\n",
       "      <td>-0.858235</td>\n",
       "      <td>-0.741497</td>\n",
       "      <td>-0.973984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-22</th>\n",
       "      <td>-0.896039</td>\n",
       "      <td>-0.999970</td>\n",
       "      <td>-0.974972</td>\n",
       "      <td>-0.505162</td>\n",
       "      <td>-0.371648</td>\n",
       "      <td>-0.526639</td>\n",
       "      <td>-0.366737</td>\n",
       "      <td>-0.991907</td>\n",
       "      <td>-0.858235</td>\n",
       "      <td>-0.741497</td>\n",
       "      <td>-0.973984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-23</th>\n",
       "      <td>-0.918250</td>\n",
       "      <td>-0.999978</td>\n",
       "      <td>-0.979522</td>\n",
       "      <td>-0.884871</td>\n",
       "      <td>-0.427062</td>\n",
       "      <td>-0.856058</td>\n",
       "      <td>-0.415909</td>\n",
       "      <td>-0.991907</td>\n",
       "      <td>-0.858235</td>\n",
       "      <td>-0.741497</td>\n",
       "      <td>-0.973984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-24</th>\n",
       "      <td>-0.928346</td>\n",
       "      <td>-0.999985</td>\n",
       "      <td>-0.983314</td>\n",
       "      <td>-0.955736</td>\n",
       "      <td>-0.430222</td>\n",
       "      <td>-0.949424</td>\n",
       "      <td>-0.425775</td>\n",
       "      <td>-0.991907</td>\n",
       "      <td>-0.858235</td>\n",
       "      <td>-0.741497</td>\n",
       "      <td>-0.973984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-25</th>\n",
       "      <td>-0.931577</td>\n",
       "      <td>-0.999989</td>\n",
       "      <td>-0.986348</td>\n",
       "      <td>-0.778092</td>\n",
       "      <td>-0.335299</td>\n",
       "      <td>-0.739440</td>\n",
       "      <td>-0.358383</td>\n",
       "      <td>-0.828175</td>\n",
       "      <td>-0.719640</td>\n",
       "      <td>-0.659864</td>\n",
       "      <td>-0.882927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-26</th>\n",
       "      <td>-0.889174</td>\n",
       "      <td>-0.999991</td>\n",
       "      <td>-0.988623</td>\n",
       "      <td>-0.616059</td>\n",
       "      <td>-0.250584</td>\n",
       "      <td>-0.560440</td>\n",
       "      <td>-0.272059</td>\n",
       "      <td>-0.828175</td>\n",
       "      <td>-0.719640</td>\n",
       "      <td>-0.659864</td>\n",
       "      <td>-0.882927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-27</th>\n",
       "      <td>-0.887962</td>\n",
       "      <td>-0.999993</td>\n",
       "      <td>-0.989382</td>\n",
       "      <td>-0.978745</td>\n",
       "      <td>-0.298910</td>\n",
       "      <td>-0.976372</td>\n",
       "      <td>-0.306995</td>\n",
       "      <td>-0.828175</td>\n",
       "      <td>-0.719640</td>\n",
       "      <td>-0.659864</td>\n",
       "      <td>-0.882927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-28</th>\n",
       "      <td>-0.905327</td>\n",
       "      <td>-0.999994</td>\n",
       "      <td>-0.990140</td>\n",
       "      <td>-0.999735</td>\n",
       "      <td>-0.333858</td>\n",
       "      <td>-0.999491</td>\n",
       "      <td>-0.323183</td>\n",
       "      <td>-0.828175</td>\n",
       "      <td>-0.719640</td>\n",
       "      <td>-0.659864</td>\n",
       "      <td>-0.882927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  m3   swe_avg   swe_max    tp_avg   t2m_avg    tp_max  \\\n",
       "time                                                                     \n",
       "2010-01-01 -0.980240 -0.999977 -0.992416 -0.932862 -0.269596 -0.917210   \n",
       "2010-01-02 -0.977130 -0.999992 -0.995449 -0.964351 -0.184114 -0.938586   \n",
       "2010-01-03 -0.977978 -0.999998 -0.996966 -0.998593 -0.379435 -0.997324   \n",
       "2010-01-04 -0.978907 -0.999999 -0.996966 -0.999969 -0.372413 -0.999930   \n",
       "2010-01-05 -0.979352 -0.999999 -0.996966 -0.999600 -0.281188 -0.999538   \n",
       "2010-01-06 -0.980038 -0.999999 -0.997725 -0.998437 -0.290117 -0.997385   \n",
       "2010-01-07 -0.980240 -1.000000 -0.997725 -0.950748 -0.226321 -0.953251   \n",
       "2010-01-08 -0.980119 -1.000000 -0.998483 -0.971501 -0.262517 -0.972947   \n",
       "2010-01-09 -0.978827 -1.000000 -0.998483 -0.988077 -0.228361 -0.988599   \n",
       "2010-01-10 -0.977777 -1.000000 -0.999242 -0.997186 -0.240825 -0.996322   \n",
       "2010-01-11 -0.977857 -1.000000 -0.999242 -0.999812 -0.237268 -0.999715   \n",
       "2010-01-12 -0.946115 -1.000000 -0.999242 -0.660361 -0.157615 -0.633892   \n",
       "2010-01-13 -0.804771 -0.999374 -0.970421 -0.380842 -0.173896 -0.270329   \n",
       "2010-01-14 -0.899673 -0.997541 -0.932499 -0.956312 -0.363634 -0.949819   \n",
       "2010-01-15 -0.935212 -0.998955 -0.936291 -0.999873 -0.320917 -0.999867   \n",
       "2010-01-16 -0.947731 -0.999637 -0.943876 -0.999943 -0.242284 -0.999953   \n",
       "2010-01-17 -0.948942 -0.999848 -0.952218 -0.803973 -0.245545 -0.766215   \n",
       "2010-01-18 -0.849597 -0.999920 -0.959803 -0.157855 -0.268777 -0.073186   \n",
       "2010-01-19 -0.736521 -0.999934 -0.963595 -0.273719 -0.282625 -0.163630   \n",
       "2010-01-20 -0.807597 -0.999945 -0.965870 -0.348821 -0.318456 -0.263504   \n",
       "2010-01-21 -0.852424 -0.999959 -0.970421 -0.340588 -0.343045 -0.265769   \n",
       "2010-01-22 -0.896039 -0.999970 -0.974972 -0.505162 -0.371648 -0.526639   \n",
       "2010-01-23 -0.918250 -0.999978 -0.979522 -0.884871 -0.427062 -0.856058   \n",
       "2010-01-24 -0.928346 -0.999985 -0.983314 -0.955736 -0.430222 -0.949424   \n",
       "2010-01-25 -0.931577 -0.999989 -0.986348 -0.778092 -0.335299 -0.739440   \n",
       "2010-01-26 -0.889174 -0.999991 -0.988623 -0.616059 -0.250584 -0.560440   \n",
       "2010-01-27 -0.887962 -0.999993 -0.989382 -0.978745 -0.298910 -0.976372   \n",
       "2010-01-28 -0.905327 -0.999994 -0.990140 -0.999735 -0.333858 -0.999491   \n",
       "\n",
       "             t2m_max  pixel_sum  pixel_mean  pixel_min  pixel_max  \n",
       "time                                                               \n",
       "2010-01-01 -0.284100  -0.981680   -0.710263  -0.591837  -0.925203  \n",
       "2010-01-02 -0.211043  -0.981680   -0.710263  -0.591837  -0.925203  \n",
       "2010-01-03 -0.371469  -0.981680   -0.710263  -0.591837  -0.925203  \n",
       "2010-01-04 -0.339378  -0.981680   -0.710263  -0.591837  -0.925203  \n",
       "2010-01-05 -0.286826  -0.981680   -0.710263  -0.591837  -0.925203  \n",
       "2010-01-06 -0.300408  -0.981680   -0.710263  -0.591837  -0.925203  \n",
       "2010-01-07 -0.236877  -0.981680   -0.710263  -0.591837  -0.925203  \n",
       "2010-01-08 -0.255080  -0.981680   -0.710263  -0.591837  -0.925203  \n",
       "2010-01-09 -0.243000  -0.786785   -0.755045  -0.687075  -0.856911  \n",
       "2010-01-10 -0.252358  -0.786785   -0.755045  -0.687075  -0.856911  \n",
       "2010-01-11 -0.235060  -0.786785   -0.755045  -0.687075  -0.856911  \n",
       "2010-01-12 -0.166231  -0.786785   -0.755045  -0.687075  -0.856911  \n",
       "2010-01-13 -0.194440  -0.786785   -0.755045  -0.687075  -0.856911  \n",
       "2010-01-14 -0.347005  -0.786785   -0.755045  -0.687075  -0.856911  \n",
       "2010-01-15 -0.300977  -0.786785   -0.755045  -0.687075  -0.856911  \n",
       "2010-01-16 -0.210304  -0.786785   -0.755045  -0.687075  -0.856911  \n",
       "2010-01-17 -0.257586  -0.991907   -0.858235  -0.741497  -0.973984  \n",
       "2010-01-18 -0.291478  -0.991907   -0.858235  -0.741497  -0.973984  \n",
       "2010-01-19 -0.284283  -0.991907   -0.858235  -0.741497  -0.973984  \n",
       "2010-01-20 -0.318549  -0.991907   -0.858235  -0.741497  -0.973984  \n",
       "2010-01-21 -0.335281  -0.991907   -0.858235  -0.741497  -0.973984  \n",
       "2010-01-22 -0.366737  -0.991907   -0.858235  -0.741497  -0.973984  \n",
       "2010-01-23 -0.415909  -0.991907   -0.858235  -0.741497  -0.973984  \n",
       "2010-01-24 -0.425775  -0.991907   -0.858235  -0.741497  -0.973984  \n",
       "2010-01-25 -0.358383  -0.828175   -0.719640  -0.659864  -0.882927  \n",
       "2010-01-26 -0.272059  -0.828175   -0.719640  -0.659864  -0.882927  \n",
       "2010-01-27 -0.306995  -0.828175   -0.719640  -0.659864  -0.882927  \n",
       "2010-01-28 -0.323183  -0.828175   -0.719640  -0.659864  -0.882927  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a6491758-cf06-4c9d-a312-c9fd6b8a6353",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.98024   , -0.99997694, -0.99241562, -0.93286242, -0.26959613,\n",
       "        -0.91720958, -0.28409993, -0.98167968, -0.71026266, -0.59183673,\n",
       "        -0.92520325],\n",
       "       [-0.97713042, -0.99999213, -0.99544937, -0.96435097, -0.18411436,\n",
       "        -0.93858556, -0.21104293, -0.98167968, -0.71026266, -0.59183673,\n",
       "        -0.92520325],\n",
       "       [-0.97797849, -0.99999817, -0.99696625, -0.99859316, -0.37943538,\n",
       "        -0.99732444, -0.37146876, -0.98167968, -0.71026266, -0.59183673,\n",
       "        -0.92520325],\n",
       "       [-0.97890732, -0.99999893, -0.99696625, -0.99996884, -0.37241293,\n",
       "        -0.99993042, -0.33937816, -0.98167968, -0.71026266, -0.59183673,\n",
       "        -0.92520325],\n",
       "       [-0.97935155, -0.99999906, -0.99696625, -0.99959984, -0.28118819,\n",
       "        -0.99953826, -0.28682589, -0.98167968, -0.71026266, -0.59183673,\n",
       "        -0.92520325],\n",
       "       [-0.98003808, -0.99999937, -0.99772469, -0.99843697, -0.29011704,\n",
       "        -0.99738453, -0.30040808, -0.98167968, -0.71026266, -0.59183673,\n",
       "        -0.92520325],\n",
       "       [-0.98024   , -0.99999956, -0.99772469, -0.95074812, -0.22632104,\n",
       "        -0.95325051, -0.23687722, -0.98167968, -0.71026266, -0.59183673,\n",
       "        -0.92520325],\n",
       "       [-0.98011885, -0.99999975, -0.99848312, -0.97150145, -0.26251739,\n",
       "        -0.97294716, -0.25507971, -0.98167968, -0.71026266, -0.59183673,\n",
       "        -0.92520325],\n",
       "       [-0.97882656, -0.99999981, -0.99848312, -0.98807684, -0.22836122,\n",
       "        -0.98859884, -0.24299985, -0.78678503, -0.75504457, -0.68707483,\n",
       "        -0.85691057],\n",
       "       [-0.97777657, -0.99999987, -0.99924156, -0.99718632, -0.24082472,\n",
       "        -0.9963219 , -0.25235829, -0.78678503, -0.75504457, -0.68707483,\n",
       "        -0.85691057],\n",
       "       [-0.97785733, -0.99999987, -0.99924156, -0.99981227, -0.23726794,\n",
       "        -0.99971537, -0.2350599 , -0.78678503, -0.75504457, -0.68707483,\n",
       "        -0.85691057],\n",
       "       [-0.94611534, -0.99999987, -0.99924156, -0.66036144, -0.15761473,\n",
       "        -0.63389163, -0.16623121, -0.78678503, -0.75504457, -0.68707483,\n",
       "        -0.85691057],\n",
       "       [-0.80477059, -0.99937378, -0.97042093, -0.3808422 , -0.17389635,\n",
       "        -0.27032914, -0.19444021, -0.78678503, -0.75504457, -0.68707483,\n",
       "        -0.85691057],\n",
       "       [-0.89967349, -0.99754134, -0.93249905, -0.95631201, -0.36363423,\n",
       "        -0.9498191 , -0.3470054 , -0.78678503, -0.75504457, -0.68707483,\n",
       "        -0.85691057],\n",
       "       [-0.9352116 , -0.9989548 , -0.93629124, -0.99987269, -0.32091711,\n",
       "        -0.99986717, -0.30097684, -0.78678503, -0.75504457, -0.68707483,\n",
       "        -0.85691057],\n",
       "       [-0.94773071, -0.99963709, -0.94387562, -0.999943  , -0.24228434,\n",
       "        -0.99995256, -0.21030423, -0.78678503, -0.75504457, -0.68707483,\n",
       "        -0.85691057],\n",
       "       [-0.94894224, -0.99984755, -0.95221843, -0.80397332, -0.24554541,\n",
       "        -0.76621461, -0.25758587, -0.99190708, -0.85823514, -0.7414966 ,\n",
       "        -0.97398374],\n",
       "       [-0.84959707, -0.99991962, -0.95980281, -0.15785492, -0.26877728,\n",
       "        -0.07318557, -0.29147791, -0.99190708, -0.85823514, -0.7414966 ,\n",
       "        -0.97398374],\n",
       "       [-0.73652126, -0.9999336 , -0.96359499, -0.27371881, -0.28262497,\n",
       "        -0.16362953, -0.28428347, -0.99190708, -0.85823514, -0.7414966 ,\n",
       "        -0.97398374],\n",
       "       [-0.80759748, -0.9999452 , -0.96587031, -0.34882085, -0.31845573,\n",
       "        -0.26350425, -0.3185494 , -0.99190708, -0.85823514, -0.7414966 ,\n",
       "        -0.97398374],\n",
       "       [-0.85242396, -0.99995931, -0.97042093, -0.34058847, -0.34304527,\n",
       "        -0.2657687 , -0.33528129, -0.99190708, -0.85823514, -0.7414966 ,\n",
       "        -0.97398374],\n",
       "       [-0.89603891, -0.99997014, -0.97497156, -0.50516152, -0.3716476 ,\n",
       "        -0.52663851, -0.36673743, -0.99190708, -0.85823514, -0.7414966 ,\n",
       "        -0.97398374],\n",
       "       [-0.91825023, -0.9999782 , -0.97952218, -0.88487146, -0.42706234,\n",
       "        -0.85605763, -0.41590888, -0.99190708, -0.85823514, -0.7414966 ,\n",
       "        -0.97398374],\n",
       "       [-0.92834629, -0.99998488, -0.98331437, -0.95573552, -0.43022216,\n",
       "        -0.94942377, -0.42577489, -0.99190708, -0.85823514, -0.7414966 ,\n",
       "        -0.97398374],\n",
       "       [-0.93157702, -0.99998872, -0.98634812, -0.77809196, -0.33529877,\n",
       "        -0.73944008, -0.35838281, -0.82817486, -0.71964037, -0.65986395,\n",
       "        -0.88292683],\n",
       "       [-0.8891736 , -0.99999131, -0.98862344, -0.61605933, -0.25058418,\n",
       "        -0.56044034, -0.27205859, -0.82817486, -0.71964037, -0.65986395,\n",
       "        -0.88292683],\n",
       "       [-0.88796207, -0.99999332, -0.98938187, -0.97874504, -0.29891004,\n",
       "        -0.97637225, -0.30699525, -0.82817486, -0.71964037, -0.65986395,\n",
       "        -0.88292683],\n",
       "       [-0.90532728, -0.9999942 , -0.99014031, -0.99973513, -0.33385784,\n",
       "        -0.99949082, -0.3231833 , -0.82817486, -0.71964037, -0.65986395,\n",
       "        -0.88292683]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c0a99956-f4c2-42ff-8737-a4b1542d8831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 28, 11)]     0           []                               \n",
      "                                                                                                  \n",
      " lstm_14 (LSTM)                 [(None, 100),        44800       ['input_7[0][0]']                \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " repeat_vector_6 (RepeatVector)  (None, 1, 100)      0           ['lstm_14[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_15 (LSTM)                 (None, 1, 100)       80400       ['repeat_vector_6[0][0]',        \n",
      "                                                                  'lstm_14[0][1]',                \n",
      "                                                                  'lstm_14[0][2]']                \n",
      "                                                                                                  \n",
      " time_distributed_6 (TimeDistri  (None, 1, 1)        101         ['lstm_15[0][0]']                \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 125,301\n",
      "Trainable params: 125,301\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_target_col = 1\n",
    "n_past = 28\n",
    "n_future = 1\n",
    "n_features = len(feature_cols)\n",
    "\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "encoder_l1 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "\n",
    "#\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs1[0])\n",
    "\n",
    "#\n",
    "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_outputs1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_target_col))(decoder_l1)\n",
    "\n",
    "#\n",
    "single_step_lstm = tf.keras.models.Model(encoder_inputs,decoder_outputs1)\n",
    "\n",
    "#\n",
    "single_step_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2f8337f1-a040-4ad0-af74-7fb5b223f399",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "64/64 - 5s - loss: 0.0290 - val_loss: 0.0158 - 5s/epoch - 72ms/step\n",
      "Epoch 2/25\n",
      "64/64 - 1s - loss: 0.0088 - val_loss: 0.0155 - 991ms/epoch - 15ms/step\n",
      "Epoch 3/25\n",
      "64/64 - 1s - loss: 0.0093 - val_loss: 0.0156 - 988ms/epoch - 15ms/step\n",
      "Epoch 4/25\n",
      "64/64 - 1s - loss: 0.0084 - val_loss: 0.0156 - 989ms/epoch - 15ms/step\n",
      "Epoch 5/25\n",
      "64/64 - 1s - loss: 0.0085 - val_loss: 0.0163 - 977ms/epoch - 15ms/step\n",
      "Epoch 6/25\n",
      "64/64 - 1s - loss: 0.0084 - val_loss: 0.0160 - 967ms/epoch - 15ms/step\n",
      "Epoch 7/25\n",
      "64/64 - 1s - loss: 0.0083 - val_loss: 0.0164 - 985ms/epoch - 15ms/step\n",
      "Epoch 8/25\n",
      "64/64 - 1s - loss: 0.0082 - val_loss: 0.0168 - 981ms/epoch - 15ms/step\n",
      "Epoch 9/25\n",
      "64/64 - 1s - loss: 0.0082 - val_loss: 0.0177 - 975ms/epoch - 15ms/step\n",
      "Epoch 10/25\n",
      "64/64 - 1s - loss: 0.0087 - val_loss: 0.0158 - 985ms/epoch - 15ms/step\n",
      "Epoch 11/25\n",
      "64/64 - 1s - loss: 0.0081 - val_loss: 0.0163 - 990ms/epoch - 15ms/step\n",
      "Epoch 12/25\n",
      "64/64 - 1s - loss: 0.0088 - val_loss: 0.0171 - 979ms/epoch - 15ms/step\n",
      "Epoch 13/25\n",
      "64/64 - 1s - loss: 0.0081 - val_loss: 0.0163 - 994ms/epoch - 16ms/step\n",
      "Epoch 14/25\n",
      "64/64 - 1s - loss: 0.0082 - val_loss: 0.0172 - 997ms/epoch - 16ms/step\n",
      "Epoch 15/25\n",
      "64/64 - 1s - loss: 0.0081 - val_loss: 0.0167 - 981ms/epoch - 15ms/step\n",
      "Epoch 16/25\n",
      "64/64 - 1s - loss: 0.0083 - val_loss: 0.0170 - 991ms/epoch - 15ms/step\n",
      "Epoch 17/25\n",
      "64/64 - 1s - loss: 0.0083 - val_loss: 0.0165 - 983ms/epoch - 15ms/step\n",
      "Epoch 18/25\n",
      "64/64 - 1s - loss: 0.0081 - val_loss: 0.0163 - 988ms/epoch - 15ms/step\n",
      "Epoch 19/25\n",
      "64/64 - 1s - loss: 0.0081 - val_loss: 0.0172 - 984ms/epoch - 15ms/step\n",
      "Epoch 20/25\n",
      "64/64 - 1s - loss: 0.0081 - val_loss: 0.0173 - 987ms/epoch - 15ms/step\n",
      "Epoch 21/25\n",
      "64/64 - 1s - loss: 0.0082 - val_loss: 0.0163 - 975ms/epoch - 15ms/step\n",
      "Epoch 22/25\n",
      "64/64 - 1s - loss: 0.0081 - val_loss: 0.0168 - 993ms/epoch - 16ms/step\n",
      "Epoch 23/25\n",
      "64/64 - 1s - loss: 0.0080 - val_loss: 0.0168 - 984ms/epoch - 15ms/step\n",
      "Epoch 24/25\n",
      "64/64 - 1s - loss: 0.0080 - val_loss: 0.0166 - 979ms/epoch - 15ms/step\n",
      "Epoch 25/25\n",
      "64/64 - 1s - loss: 0.0080 - val_loss: 0.0160 - 986ms/epoch - 15ms/step\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 0.01 * 0.90 ** x)\n",
    "single_step_lstm.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=tf.keras.losses.Huber())\n",
    "history_single_step_lstm=single_step_lstm.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),batch_size=32,verbose=2\n",
    "                            # callbacks=[reduce_lr]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cf3c5321-0e8d-4b4f-8024-2c0f6c6e9839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_single_step = single_step_lstm.predict(X_test)\n",
    "pred_single_step = pred_single_step.reshape(y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "81d65b74-5e1b-4112-86b7-99ec3b7dff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_single_step_inverse = scalers['scaler_m3'].inverse_transform([pred_single_step])\n",
    "y_test_inverse = scalers['scaler_m3'].inverse_transform([y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8cb69fcd-edc6-4157-99dd-ceb2ef5f7665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 12.6423502459464\n",
      "MAPE = 5.925804591904566\n",
      "RRMSE = 1.673161707339849\n"
     ]
    }
   ],
   "source": [
    "rmse_list = []\n",
    "mape_list = []\n",
    "rrmse_list = []\n",
    "\n",
    "for pred, truth in zip(pred_single_step_inverse, y_test_inverse):\n",
    "    rmse_list.append(np.sqrt(mean_squared_error(truth, pred)))\n",
    "    mape_list.append(mean_absolute_percentage_error(truth, pred))\n",
    "    rrmse_list.append(relative_root_mean_squared_error(truth, pred))\n",
    "    \n",
    "final_rmse = np.mean(rmse_list)\n",
    "final_mape = np.mean(mape_list)\n",
    "final_rrmse = np.mean(rrmse_list)\n",
    "\n",
    "print(f'RMSE = {final_rmse}')\n",
    "print(f'MAPE = {final_mape}')\n",
    "print(f'RRMSE = {final_rrmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "547de732-9f36-4e17-8248-331267adc983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.6423502459464"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test_inverse, pred_single_step_inverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ca05fa-3f32-43e1-8b20-4bf9433a6b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = 5.884456679626631\n",
    "MAPE = 1.9748009506470705\n",
    "RRMSE = 0.9109061023635227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278ce22-0079-4aec-ad60-c0fb0fa55e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a47d1b9-c9b6-48e6-ae69-3955045cf1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc42939-41a2-4c97-bb79-cfd16ffacc53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "404ca1dc-7cac-45a2-947a-0c627b52c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gage_df = df.loc[gage_list[0]].reset_index(drop = False)[['time','ft']]\n",
    "gage_df.rename(columns = {'ft':f'ft_{gage_list[0]}'}, inplace = True)\n",
    "for gage_num in gage_list[1:]:\n",
    "    new_gage_df =  df.loc[gage_num].reset_index(drop = False)[['time','ft']]\n",
    "    new_gage_df.rename(columns = {'ft':f'ft_{gage_num}'}, inplace = True)\n",
    "    gage_df = gage_df.merge(new_gage_df, on = 'time', how = 'outer')\n",
    "    \n",
    "gage_df = gage_df.iloc[-365 * 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "71443a7e-7d8b-441f-9721-5a53b8d4c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'ft_11402000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "487b70bc-637f-4018-a04a-7d12d0055021",
   "metadata": {},
   "outputs": [],
   "source": [
    "gage_df['target'] = gage_df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2bba029c-2b93-4f01-8216-ad44ce3a8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_shift = 30\n",
    "target_data = gage_df['target'].shift(time_shift)\n",
    "data = gage_df.iloc[:-time_shift]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8f620cae-2ea7-4c21-aeea-d29d899eb643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>ft_11402000</th>\n",
       "      <th>ft_11318500</th>\n",
       "      <th>ft_11266500</th>\n",
       "      <th>ft_11208000</th>\n",
       "      <th>ft_11202710</th>\n",
       "      <th>ft_11185500</th>\n",
       "      <th>ft_11189500</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>2014-10-02</td>\n",
       "      <td>16.6</td>\n",
       "      <td>2.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.27</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10959</th>\n",
       "      <td>2014-10-03</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.21</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10960</th>\n",
       "      <td>2014-10-04</td>\n",
       "      <td>17.3</td>\n",
       "      <td>2.10</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10961</th>\n",
       "      <td>2014-10-05</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.30</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.22</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10962</th>\n",
       "      <td>2014-10-06</td>\n",
       "      <td>17.4</td>\n",
       "      <td>2.60</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.16</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12383</th>\n",
       "      <td>2018-08-27</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.82</td>\n",
       "      <td>40.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.79</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12384</th>\n",
       "      <td>2018-08-28</td>\n",
       "      <td>19.2</td>\n",
       "      <td>5.72</td>\n",
       "      <td>38.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12385</th>\n",
       "      <td>2018-08-29</td>\n",
       "      <td>18.6</td>\n",
       "      <td>5.87</td>\n",
       "      <td>37.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12386</th>\n",
       "      <td>2018-08-30</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.94</td>\n",
       "      <td>36.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12387</th>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>19.8</td>\n",
       "      <td>6.08</td>\n",
       "      <td>35.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1430 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time  ft_11402000  ft_11318500  ft_11266500  ft_11208000  \\\n",
       "10958 2014-10-02         16.6         2.00         11.0          1.5   \n",
       "10959 2014-10-03         18.0         2.00         10.8          1.4   \n",
       "10960 2014-10-04         17.3         2.10         10.7          1.5   \n",
       "10961 2014-10-05         16.0         2.30         10.3          1.5   \n",
       "10962 2014-10-06         17.4         2.60         10.1          1.5   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "12383 2018-08-27         17.0         5.82         40.2          4.1   \n",
       "12384 2018-08-28         19.2         5.72         38.6          4.1   \n",
       "12385 2018-08-29         18.6         5.87         37.7          4.0   \n",
       "12386 2018-08-30         20.0         5.94         36.2          4.1   \n",
       "12387 2018-08-31         19.8         6.08         35.1          4.1   \n",
       "\n",
       "       ft_11202710  ft_11185500  ft_11189500  target  \n",
       "10958         13.0          0.0         2.27    16.6  \n",
       "10959         13.0          0.0         2.21    18.0  \n",
       "10960         13.0          0.0         2.20    17.3  \n",
       "10961         13.0          0.0         2.22    16.0  \n",
       "10962         12.0          0.0         2.16    17.4  \n",
       "...            ...          ...          ...     ...  \n",
       "12383         22.0         55.0         2.79    17.0  \n",
       "12384         23.0         55.0         2.75    19.2  \n",
       "12385         23.0         55.0         2.77    18.6  \n",
       "12386         23.0         52.0         2.48    20.0  \n",
       "12387         23.0         42.0         2.14    19.8  \n",
       "\n",
       "[1430 rows x 9 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "548b20bf-65bb-4c2a-a3e5-c427fd9e23ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ft_11402000',\n",
       " 'ft_11318500',\n",
       " 'ft_11266500',\n",
       " 'ft_11208000',\n",
       " 'ft_11202710',\n",
       " 'ft_11185500',\n",
       " 'ft_11189500']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = data.drop(columns = ['time','target']).columns.tolist()\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0049fae0-ef92-421c-9b6a-d7f18bad96d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_head = data.index[int(0.8*len(data))]\n",
    "\n",
    "df_train = gage_df.loc[:test_head,:]\n",
    "df_test = gage_df.loc[test_head:,:]\n",
    "target_train = target_data.loc[:test_head]\n",
    "target_test = target_data.loc[test_head:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "40985ed5-828b-49ab-8f89-ff0c3d13c533",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [124], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSequenceDataset\u001b[39;00m(Dataset):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, dataframe, target, features, sequence_length=5):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.sequence_length = sequence_length\n",
    "        self.y = torch.tensor(dataframe[target].values).float()\n",
    "        self.X = torch.tensor(dataframe[features].values).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, i): \n",
    "        if i >= self.sequence_length - 1:\n",
    "            i_start = i - self.sequence_length + 1\n",
    "            x = self.X[i_start:(i + 1), :]\n",
    "        else:\n",
    "            padding = self.X[0].repeat(self.sequence_length - i - 1, 1)\n",
    "            x = self.X[0:(i + 1), :]\n",
    "            x = torch.cat((padding, x), 0)\n",
    "\n",
    "        return x, self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "78d0cd05-8644-4cfa-966f-13b1cf0da35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[22.5000,  2.6000, 10.6000,  1.4000, 14.0000,  0.0000,  2.6600],\n",
      "        [22.5000,  2.7000, 10.5000,  1.4000, 13.0000,  0.0000,  3.1500],\n",
      "        [23.2000,  3.3000, 10.4000,  1.4000, 13.0000,  0.0000,  3.0700],\n",
      "        [35.5000,  3.7000, 10.5000,  1.5000, 14.0000,  0.0000,  3.0300],\n",
      "        [35.0000,  3.7000, 10.7000,  1.5000, 14.0000,  0.0000,  3.1500],\n",
      "        [28.1000,  3.4000, 10.6000,  1.5000, 14.0000,  0.0000,  3.2200],\n",
      "        [26.3000,  3.2000, 10.7000,  1.5000, 14.0000,  0.0000,  3.2400]])\n"
     ]
    }
   ],
   "source": [
    "i = 27\n",
    "sequence_length = 7\n",
    "features = feature_cols\n",
    "target = 'target'\n",
    "\n",
    "train_dataset = SequenceDataset(\n",
    "    df_train,\n",
    "    target=target,\n",
    "    features=features,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "X, y = train_dataset[i]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0aa7fe7f-a1f9-4cc1-9281-99f2b0d0e084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 7, 7])\n",
      "tensor([[[6.9600e+02, 1.7600e+02, 6.0800e+03, 3.4000e+00, 4.0800e+02,\n",
      "          5.6500e+02, 1.2500e+03],\n",
      "         [6.6400e+02, 1.7000e+02, 5.6900e+03, 3.0000e+00, 4.3800e+02,\n",
      "          5.7600e+02, 1.2400e+03],\n",
      "         [5.9100e+02, 1.6400e+02, 3.9200e+03, 3.0000e+00, 4.1100e+02,\n",
      "          5.6000e+02, 1.2300e+03],\n",
      "         [5.3200e+02, 1.5800e+02, 3.4400e+03, 1.3000e+00, 3.7500e+02,\n",
      "          5.5300e+02, 1.1600e+03],\n",
      "         [4.8600e+02, 1.5500e+02, 3.0700e+03, 0.0000e+00, 3.4000e+02,\n",
      "          5.5000e+02, 1.0800e+03],\n",
      "         [4.6300e+02, 1.5400e+02, 2.5800e+03, 0.0000e+00, 3.0100e+02,\n",
      "          5.3000e+02, 1.0200e+03],\n",
      "         [4.7200e+02, 1.5300e+02, 2.3800e+03, 3.1000e+00, 2.8300e+02,\n",
      "          5.2700e+02, 9.7500e+02]],\n",
      "\n",
      "        [[3.6700e+01, 3.8000e+00, 4.0100e+02, 1.1000e+01, 6.1000e+00,\n",
      "          1.9900e+02, 8.7700e+00],\n",
      "         [3.8800e+01, 7.8000e+00, 3.7800e+02, 1.1000e+01, 6.3000e+00,\n",
      "          1.8900e+02, 8.6500e+00],\n",
      "         [4.4800e+01, 1.6000e+01, 4.6700e+02, 1.1000e+01, 7.2000e+00,\n",
      "          1.7900e+02, 8.8300e+00],\n",
      "         [4.6000e+01, 1.2000e+01, 6.0900e+02, 1.1000e+01, 6.2000e+00,\n",
      "          1.6400e+02, 1.0200e+01],\n",
      "         [4.0700e+01, 1.1000e+01, 6.4300e+02, 1.1000e+01, 6.0000e+00,\n",
      "          1.4700e+02, 1.0900e+01],\n",
      "         [3.7500e+01, 9.8000e+00, 5.7300e+02, 1.1000e+01, 5.8000e+00,\n",
      "          1.3600e+02, 1.0300e+01],\n",
      "         [3.2400e+01, 9.2000e+00, 4.8000e+02, 1.1000e+01, 5.8000e+00,\n",
      "          1.4000e+02, 9.9300e+00]],\n",
      "\n",
      "        [[9.5400e+00, 1.0000e+00, 8.1000e+01, 9.9000e+00, 1.2000e+01,\n",
      "          4.2000e+01, 8.1000e-01],\n",
      "         [9.4000e+00, 1.1000e+00, 6.8100e+01, 8.5000e+00, 1.1000e+01,\n",
      "          4.2000e+01, 1.2800e+00],\n",
      "         [9.3300e+00, 1.1000e+00, 5.9000e+01, 7.6000e+00, 1.1000e+01,\n",
      "          4.2000e+01, 1.0800e+00],\n",
      "         [8.8200e+00, 1.2000e+00, 5.4500e+01, 7.7000e+00, 1.1000e+01,\n",
      "          4.2000e+01, 6.8000e-01],\n",
      "         [9.3900e+00, 1.2000e+00, 5.1300e+01, 7.7000e+00, 1.2000e+01,\n",
      "          4.2000e+01, 6.8000e-01],\n",
      "         [9.3100e+00, 1.3000e+00, 4.7700e+01, 6.7000e+00, 1.1000e+01,\n",
      "          4.2000e+01, 4.7000e-01],\n",
      "         [9.5300e+00, 1.3000e+00, 7.0300e+01, 6.1000e+00, 1.1000e+01,\n",
      "          4.2000e+01, 4.7000e-01]]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True)\n",
    "\n",
    "X, y = next(iter(train_loader))\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fbf4710a-729e-4576-9e23-ff3dcebb65d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: torch.Size([4, 7, 7])\n",
      "Target shape: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "sequence_length = 7\n",
    "\n",
    "train_dataset = SequenceDataset(\n",
    "    df_train,\n",
    "    target=target,\n",
    "    features=features,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "test_dataset = SequenceDataset(\n",
    "    df_test,\n",
    "    target=target,\n",
    "    features=features,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "X, y = next(iter(train_loader))\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "05f57748-7b5c-48b4-9784-afff54cb5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class ShallowRegressionLSTM(nn.Module):\n",
    "    def __init__(self, num_sensors, hidden_units):\n",
    "        super().__init__()\n",
    "        self.num_sensors = num_sensors  # this is the number of features\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = 1\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_sensors,\n",
    "            hidden_size=hidden_units,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_units, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "\n",
    "        _, (hn, _) = self.lstm(x, (h0, c0))\n",
    "        out = self.linear(hn[0]).flatten()  # First dim of Hn is num_layers, which is set to 1 above.\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0c331ed0-b55d-4fac-9f34-51eb0c21c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-4\n",
    "num_hidden_units = 8\n",
    "\n",
    "model = ShallowRegressionLSTM(num_sensors=len(features), hidden_units=num_hidden_units)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "20ad9801-744b-4209-b9f3-9802b7f65bb8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n",
      "Test loss: 170873.41584797148\n",
      "\n",
      "Epoch 0\n",
      "---------\n",
      "Train loss: 677741.1989021966\n",
      "Test loss: 170767.7034095088\n",
      "\n",
      "Epoch 1\n",
      "---------\n",
      "Train loss: 677501.5249025564\n",
      "Test loss: 170605.03493953656\n",
      "\n",
      "Epoch 2\n",
      "---------\n",
      "Train loss: 677299.4300107524\n",
      "Test loss: 170366.73983841907\n",
      "\n",
      "Epoch 3\n",
      "---------\n",
      "Train loss: 676706.1167311452\n",
      "Test loss: 170094.44985778423\n",
      "\n",
      "Epoch 4\n",
      "---------\n",
      "Train loss: 676884.1327460951\n",
      "Test loss: 169811.28410793256\n",
      "\n",
      "Epoch 5\n",
      "---------\n",
      "Train loss: 675669.3594616082\n",
      "Test loss: 169516.9464481209\n",
      "\n",
      "Epoch 6\n",
      "---------\n",
      "Train loss: 675072.644075799\n",
      "Test loss: 169140.05310087567\n",
      "\n",
      "Epoch 7\n",
      "---------\n",
      "Train loss: 674459.0158398525\n",
      "Test loss: 168847.5033165171\n",
      "\n",
      "Epoch 8\n",
      "---------\n",
      "Train loss: 673941.1603868598\n",
      "Test loss: 168567.038689722\n",
      "\n",
      "Epoch 9\n",
      "---------\n",
      "Train loss: 673500.5841700324\n",
      "Test loss: 168269.523753637\n",
      "\n",
      "Epoch 10\n",
      "---------\n",
      "Train loss: 673055.2345612955\n",
      "Test loss: 168014.8466104435\n",
      "\n",
      "Epoch 11\n",
      "---------\n",
      "Train loss: 672818.6869991715\n",
      "Test loss: 167716.416280167\n",
      "\n",
      "Epoch 12\n",
      "---------\n",
      "Train loss: 672130.5865072988\n",
      "Test loss: 167455.45125686066\n",
      "\n",
      "Epoch 13\n",
      "---------\n",
      "Train loss: 671704.6060938819\n",
      "Test loss: 167204.5646704903\n",
      "\n",
      "Epoch 14\n",
      "---------\n",
      "Train loss: 671241.7510037705\n",
      "Test loss: 166941.18175730525\n",
      "\n",
      "Epoch 15\n",
      "---------\n",
      "Train loss: 670803.138987724\n",
      "Test loss: 166691.87329830398\n",
      "\n",
      "Epoch 16\n",
      "---------\n",
      "Train loss: 670365.5841257647\n",
      "Test loss: 166419.0734840754\n",
      "\n",
      "Epoch 17\n",
      "---------\n",
      "Train loss: 669935.7151606224\n",
      "Test loss: 166165.04532518718\n",
      "\n",
      "Epoch 18\n",
      "---------\n",
      "Train loss: 669475.9458647405\n",
      "Test loss: 165936.76954310152\n",
      "\n",
      "Epoch 19\n",
      "---------\n",
      "Train loss: 669019.2163141497\n",
      "Test loss: 165621.60084680666\n",
      "\n",
      "Epoch 20\n",
      "---------\n",
      "Train loss: 668535.02955662\n",
      "Test loss: 165328.1257301486\n",
      "\n",
      "Epoch 21\n",
      "---------\n",
      "Train loss: 668243.5419153619\n",
      "Test loss: 165047.79578253665\n",
      "\n",
      "Epoch 22\n",
      "---------\n",
      "Train loss: 667529.0249187456\n",
      "Test loss: 164782.76084467958\n",
      "\n",
      "Epoch 23\n",
      "---------\n",
      "Train loss: 667978.3899456117\n",
      "Test loss: 164534.60009298747\n",
      "\n",
      "Epoch 24\n",
      "---------\n",
      "Train loss: 667013.0950182406\n",
      "Test loss: 164283.3196336212\n",
      "\n",
      "Epoch 25\n",
      "---------\n",
      "Train loss: 666345.8518259799\n",
      "Test loss: 164034.45130953155\n",
      "\n",
      "Epoch 26\n",
      "---------\n",
      "Train loss: 665923.3334611766\n",
      "Test loss: 163783.5959113029\n",
      "\n",
      "Epoch 27\n",
      "---------\n",
      "Train loss: 665439.6517416924\n",
      "Test loss: 163527.3831137434\n",
      "\n",
      "Epoch 28\n",
      "---------\n",
      "Train loss: 664831.5607800102\n",
      "Test loss: 163284.1700364155\n",
      "\n",
      "Epoch 29\n",
      "---------\n",
      "Train loss: 664414.2996146703\n",
      "Test loss: 163042.89257208005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(data_loader, model, loss_function, optimizer):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for X, y in data_loader:\n",
    "        output = model(X)\n",
    "        loss = loss_function(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Train loss: {avg_loss}\")\n",
    "\n",
    "def test_model(data_loader, model, loss_function):\n",
    "\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            total_loss += loss_function(output, y).item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Test loss: {avg_loss}\")\n",
    "\n",
    "\n",
    "print(\"Untrained test\\n--------\")\n",
    "test_model(test_loader, model, loss_function)\n",
    "print()\n",
    "\n",
    "for ix_epoch in range(30):\n",
    "    print(f\"Epoch {ix_epoch}\\n---------\")\n",
    "    train_model(train_loader, model, loss_function, optimizer=optimizer)\n",
    "    test_model(test_loader, model, loss_function)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "03b6d8db-4847-4aa8-b1b0-b7a508dfad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       target  Model forecast\n",
      "10958    16.6       18.184389\n",
      "10959    18.0       18.563141\n",
      "10960    17.3       18.346769\n",
      "10961    16.0       18.009441\n",
      "10962    17.4       18.667486\n",
      "...       ...             ...\n",
      "12413    23.1       17.656294\n",
      "12414    22.8       17.612049\n",
      "12415    20.9       17.542467\n",
      "12416    17.4       17.420143\n",
      "12417    18.4       17.962250\n",
      "\n",
      "[1461 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-83-eac2ac85467c>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[ystar_col] = predict(train_eval_loader, model).numpy()\n",
      "<ipython-input-83-eac2ac85467c>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[ystar_col] = predict(test_loader, model).numpy()\n"
     ]
    }
   ],
   "source": [
    "def predict(data_loader, model):\n",
    "\n",
    "    output = torch.tensor([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, _ in data_loader:\n",
    "            y_star = model(X)\n",
    "            output = torch.cat((output, y_star), 0)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "train_eval_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "ystar_col = \"Model forecast\"\n",
    "df_train[ystar_col] = predict(train_eval_loader, model).numpy()\n",
    "df_test[ystar_col] = predict(test_loader, model).numpy()\n",
    "\n",
    "df_out = pd.concat((df_train, df_test))[[target, ystar_col]]\n",
    "\n",
    "# for c in df_out.columns:\n",
    "#     df_out[c] = df_out[c] * target_stdev + target_mean\n",
    "\n",
    "print(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "11c32bfb-d72b-446d-a3ab-68c30c5ce971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Model forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>16.6</td>\n",
       "      <td>18.184389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10959</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.563141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10960</th>\n",
       "      <td>17.3</td>\n",
       "      <td>18.346769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10961</th>\n",
       "      <td>16.0</td>\n",
       "      <td>18.009441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10962</th>\n",
       "      <td>17.4</td>\n",
       "      <td>18.667486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12413</th>\n",
       "      <td>23.1</td>\n",
       "      <td>17.656294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12414</th>\n",
       "      <td>22.8</td>\n",
       "      <td>17.612049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12415</th>\n",
       "      <td>20.9</td>\n",
       "      <td>17.542467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12416</th>\n",
       "      <td>17.4</td>\n",
       "      <td>17.420143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12417</th>\n",
       "      <td>18.4</td>\n",
       "      <td>17.962250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1461 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target  Model forecast\n",
       "10958    16.6       18.184389\n",
       "10959    18.0       18.563141\n",
       "10960    17.3       18.346769\n",
       "10961    16.0       18.009441\n",
       "10962    17.4       18.667486\n",
       "...       ...             ...\n",
       "12413    23.1       17.656294\n",
       "12414    22.8       17.612049\n",
       "12415    20.9       17.542467\n",
       "12416    17.4       17.420143\n",
       "12417    18.4       17.962250\n",
       "\n",
       "[1461 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
