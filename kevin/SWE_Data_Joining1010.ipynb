{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42dd03b0-8fc5-4cea-bd9d-fb0d90dba17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from datetime import datetime, date\n",
    "# from mpl_toolkits.basemap import Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8a1d70d-30b8-4fcb-9581-14c686270bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SN_SWE_WY1985.h5',\n",
       " 'SN_SWE_WY1986.h5',\n",
       " 'SN_SWE_WY1987.h5',\n",
       " 'SN_SWE_WY1988.h5',\n",
       " 'SN_SWE_WY1989.h5',\n",
       " 'SN_SWE_WY1990.h5',\n",
       " 'SN_SWE_WY1991.h5',\n",
       " 'SN_SWE_WY1992.h5',\n",
       " 'SN_SWE_WY1993.h5',\n",
       " 'SN_SWE_WY1994.h5',\n",
       " 'SN_SWE_WY1995.h5',\n",
       " 'SN_SWE_WY1996.h5',\n",
       " 'SN_SWE_WY1997.h5',\n",
       " 'SN_SWE_WY1998.h5',\n",
       " 'SN_SWE_WY1999.h5',\n",
       " 'SN_SWE_WY2000.h5',\n",
       " 'SN_SWE_WY2001.h5',\n",
       " 'SN_SWE_WY2002.h5',\n",
       " 'SN_SWE_WY2003.h5',\n",
       " 'SN_SWE_WY2004.h5',\n",
       " 'SN_SWE_WY2005.h5',\n",
       " 'SN_SWE_WY2006.h5',\n",
       " 'SN_SWE_WY2007.h5',\n",
       " 'SN_SWE_WY2008.h5',\n",
       " 'SN_SWE_WY2009.h5',\n",
       " 'SN_SWE_WY2010.h5',\n",
       " 'SN_SWE_WY2011.h5',\n",
       " 'SN_SWE_WY2012.h5',\n",
       " 'SN_SWE_WY2013.h5',\n",
       " 'SN_SWE_WY2014.h5',\n",
       " 'SN_SWE_WY2015.h5',\n",
       " 'SN_SWE_WY2016.h5']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change Directory\n",
    "import os\n",
    "os.chdir('swe_data/')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e94b24f-137d-4056-a62f-cd5baab8a033",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function Used in Later Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79be8099-8793-4dd3-b65e-e415ee0a60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Function for Extracting Index\n",
    "def index_finder(lon,lat):\n",
    "    # Longtitude finder\n",
    "    if lon < -123.3 or lon > -117.6:\n",
    "        print('Longitude of Input is out of range! lon:',lon)\n",
    "        return None\n",
    "    elif lat < 35.4 or lat > 42:\n",
    "        print('Latitude of Input is out of range! lat:',lat)\n",
    "    else: #longtitude and latitude are within reasonable range\n",
    "        lon_idx = round((lon + 123.3) * 1000)\n",
    "        lat_idx = round((lat - 35.4) * 1000)\n",
    "    \n",
    "        return lon_idx,lat_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7725f-56c0-4981-b0f6-08f4deac5241",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e48371b4-01ad-47b4-92ce-6b4bd4210c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discharge Data\n",
    "gage = pd.read_csv('../gage_discharge_lat_lon.csv')\n",
    "gage['swe'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2fdc6c93-a4c9-488e-8201-71aff4db9032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>ft</th>\n",
       "      <th>m3</th>\n",
       "      <th>gage</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>swe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984-10-01</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.529110</td>\n",
       "      <td>11402000</td>\n",
       "      <td>40.002947</td>\n",
       "      <td>-120.954399</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984-10-02</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.472476</td>\n",
       "      <td>11402000</td>\n",
       "      <td>40.002947</td>\n",
       "      <td>-120.954399</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1984-10-03</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.387525</td>\n",
       "      <td>11402000</td>\n",
       "      <td>40.002947</td>\n",
       "      <td>-120.954399</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984-10-04</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.387525</td>\n",
       "      <td>11402000</td>\n",
       "      <td>40.002947</td>\n",
       "      <td>-120.954399</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984-10-05</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.359209</td>\n",
       "      <td>11402000</td>\n",
       "      <td>40.002947</td>\n",
       "      <td>-120.954399</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time    ft        m3      gage        lat         lon  swe\n",
       "0  1984-10-01  54.0  1.529110  11402000  40.002947 -120.954399   -1\n",
       "1  1984-10-02  52.0  1.472476  11402000  40.002947 -120.954399   -1\n",
       "2  1984-10-03  49.0  1.387525  11402000  40.002947 -120.954399   -1\n",
       "3  1984-10-04  49.0  1.387525  11402000  40.002947 -120.954399   -1\n",
       "4  1984-10-05  48.0  1.359209  11402000  40.002947 -120.954399   -1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4251226a-43fb-49f6-9179-4c344df315b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable Defining\n",
    "prev_year = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e805ce74-6661-4266-ad2b-ba84208a8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "for row_num in range(len(gage)):\n",
    "    #if row_num == 0:\n",
    "    row_data = gage.iloc[row_num,:]\n",
    "    row_time = row_data['time']\n",
    "    if row_time[0:4] == '2015' and row_data['gage']==11202710:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61fe5778-0747-449f-ae0f-106c97520b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGage with swe values: 11266500 \\nGage with no swe values: 11402000, 11318500,11208000\\nGage with certain swe values: 11185500\\nGage with limited swe values: 11189500, 11202710\\nNote: Gage 11202710 starts from 1988 while others start from 1984\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Gage with swe values: 11266500 \n",
    "Gage with no swe values: 11402000, 11318500,11208000\n",
    "Gage with certain swe values: 11185500\n",
    "Gage with limited swe values: 11189500, 11202710\n",
    "Note: Gage 11202710 starts from 1988 while others start from 1985\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a03121ea-4897-4adc-9a47-2e9944ea7046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time    2015-01-01\n",
       "ft             6.6\n",
       "m3        0.186891\n",
       "gage      11202710\n",
       "lat        36.1613\n",
       "lon        -118.71\n",
       "swe             -1\n",
       "Name: 58530, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d649f343-2886-4c83-b46d-37c8d89e5b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Inside For Loop -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25d60198-f7b3-4df4-a64d-72b69a29c49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2015  Day: 0\n"
     ]
    }
   ],
   "source": [
    "### Extract Date from Gage Data to match SWE\n",
    "date_format = \"%Y-%m-%d\"\n",
    "d_date = datetime.strptime(row_time, date_format)\n",
    "\n",
    "# Extract year of date\n",
    "d_year = d_date.year\n",
    "# Extract number of days from SWE Data\n",
    "num_days = d_date- datetime.strptime('{}-1-1'.format(d_year),date_format)\n",
    "num_days = num_days.days\n",
    "\n",
    "print(f'Year: {d_year}  Day: {num_days}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19c03a74-c579-4aba-ba74-29b0c8806610",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtain swe data\n",
    "# if year of previous row does not match year of current row. Then Read Data\n",
    "if prev_year != d_year: \n",
    "    swe = h5py.File(f'SN_SWE_WY{d_year}.h5', 'r')\n",
    "    lat = swe['lat'][0][::-1]\n",
    "    lon = swe['lon'][:,0]\n",
    "    lats,lons = np.meshgrid(lat,lon)\n",
    "prev_year = d_year\n",
    "\n",
    "swe_data = swe['SWE'][num_days]\n",
    "# flip over yaxis as lats are in a descending order --> need to change to ascending order\n",
    "swe_data_flip = swe_data[:,::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7687f3b-0365-4d03-be53-19672454892b",
   "metadata": {},
   "source": [
    "## Find SWE Interested Region with Lat Lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4590.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lon_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1671c5bb-9b67-495e-abab-9b5ea74293c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4. Find closest idx to the lower left & upper right corner\n",
    "# ll_lon_idx,ll_lat_idx = index_finder(row_data['lon'],row_data['lat'])\n",
    "# tr_lon_idx,tr_lat_idx = index_finder(day['tr_lon'],day['tr_lat'])\n",
    "# region = swe_data_flip[ll_lon_idx:tr_lon_idx,ll_lat_idx:tr_lat_idx]\n",
    "\n",
    "sur = 20\n",
    "\n",
    "lon_idx,lat_idx = index_finder(row_data['lon'],row_data['lat'])\n",
    "lon_idx,lat_idx = int(lon_idx),int(lat_idx)\n",
    "region = swe_data_flip[lon_idx-sur:lon_idx+sur,lat_idx-sur:lat_idx+sur]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cb7204c-80b9-4bc8-84bc-5fc9d289f8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-32768, -32768, -32768, ..., -32768, -32768, -32768],\n",
       "       [-32768, -32768, -32768, ..., -32768, -32768, -32768],\n",
       "       [-32768, -32768, -32768, ..., -32768, -32768, -32768],\n",
       "       ...,\n",
       "       [     0,      0, -32768, ..., -32768, -32768, -32768],\n",
       "       [     0, -32768, -32768, ..., -32768, -32768, -32768],\n",
       "       [     0, -32768, -32768, ..., -32768, -32768, -32768]], dtype=int16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "554b2f72-eeb5-4c98-b2a8-4557dedca410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -1\n",
       "1       -1\n",
       "2       -1\n",
       "3       -1\n",
       "4       -1\n",
       "        ..\n",
       "83269   -1\n",
       "83270   -1\n",
       "83271   -1\n",
       "83272   -1\n",
       "83273   -1\n",
       "Name: swe, Length: 83274, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gage.iloc[:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daf3546-2c3e-43f6-bd2c-31ea339f1880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f7f4347e-787b-4c6e-9bb8-552e28b98288",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Obtain Value of Interested Region\n",
    "\n",
    "# change null values to null\n",
    "region=region.astype('float')\n",
    "region[region == -32768] = np.nan\n",
    "\n",
    "region_avg = np.nanmean(region)\n",
    "\n",
    "if region_avg == np.nan:\n",
    "    gage.iloc[row_num,6] = -1\n",
    "else: # region avg is not null\n",
    "    gage.iloc[row_num,6] = region_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c63ab6e3-925f-4730-a011-9b2fd1a66300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gage.iloc[row_num,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1985'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### RUN Data\n",
    "row_time[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Joining Between Gage Time Series Data & SWE Value\n",
    "- matching swe data to the gage time series data based on lat & lon of the gage\n",
    "- **main code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Processing Row Number 0 out of 83274 ---------\n",
      "---- Round 0 Save to CSV file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Downloads\\anaconda3\\envs\\python37\\lib\\site-packages\\ipykernel_launcher.py:56: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Processing Row Number 100 out of 83274 ---------\n",
      "-------- Processing Row Number 200 out of 83274 ---------\n",
      "-------- Processing Row Number 300 out of 83274 ---------\n",
      "-------- Processing Row Number 400 out of 83274 ---------\n",
      "-------- Processing Row Number 500 out of 83274 ---------\n",
      "-------- Processing Row Number 600 out of 83274 ---------\n",
      "-------- Processing Row Number 700 out of 83274 ---------\n",
      "-------- Processing Row Number 800 out of 83274 ---------\n",
      "-------- Processing Row Number 900 out of 83274 ---------\n",
      "-------- Processing Row Number 1000 out of 83274 ---------\n",
      "---- Round 1000 Save to CSV file\n",
      "-------- Processing Row Number 1100 out of 83274 ---------\n",
      "-------- Processing Row Number 1200 out of 83274 ---------\n",
      "-------- Processing Row Number 1300 out of 83274 ---------\n",
      "-------- Processing Row Number 1400 out of 83274 ---------\n",
      "-------- Processing Row Number 1500 out of 83274 ---------\n",
      "-------- Processing Row Number 1600 out of 83274 ---------\n",
      "-------- Processing Row Number 1700 out of 83274 ---------\n",
      "-------- Processing Row Number 1800 out of 83274 ---------\n",
      "-------- Processing Row Number 1900 out of 83274 ---------\n",
      "-------- Processing Row Number 2000 out of 83274 ---------\n",
      "---- Round 2000 Save to CSV file\n",
      "-------- Processing Row Number 2100 out of 83274 ---------\n",
      "-------- Processing Row Number 2200 out of 83274 ---------\n",
      "-------- Processing Row Number 2300 out of 83274 ---------\n",
      "-------- Processing Row Number 2400 out of 83274 ---------\n",
      "-------- Processing Row Number 2500 out of 83274 ---------\n",
      "-------- Processing Row Number 2600 out of 83274 ---------\n",
      "-------- Processing Row Number 2700 out of 83274 ---------\n",
      "-------- Processing Row Number 2800 out of 83274 ---------\n",
      "-------- Processing Row Number 2900 out of 83274 ---------\n",
      "-------- Processing Row Number 3000 out of 83274 ---------\n",
      "---- Round 3000 Save to CSV file\n",
      "-------- Processing Row Number 3100 out of 83274 ---------\n",
      "-------- Processing Row Number 3200 out of 83274 ---------\n",
      "-------- Processing Row Number 3300 out of 83274 ---------\n",
      "-------- Processing Row Number 3400 out of 83274 ---------\n",
      "-------- Processing Row Number 3500 out of 83274 ---------\n",
      "-------- Processing Row Number 3600 out of 83274 ---------\n",
      "-------- Processing Row Number 3700 out of 83274 ---------\n",
      "-------- Processing Row Number 3800 out of 83274 ---------\n",
      "-------- Processing Row Number 3900 out of 83274 ---------\n",
      "-------- Processing Row Number 4000 out of 83274 ---------\n",
      "---- Round 4000 Save to CSV file\n",
      "-------- Processing Row Number 4100 out of 83274 ---------\n",
      "-------- Processing Row Number 4200 out of 83274 ---------\n",
      "-------- Processing Row Number 4300 out of 83274 ---------\n",
      "-------- Processing Row Number 4400 out of 83274 ---------\n",
      "-------- Processing Row Number 4500 out of 83274 ---------\n",
      "-------- Processing Row Number 4600 out of 83274 ---------\n",
      "-------- Processing Row Number 4700 out of 83274 ---------\n",
      "-------- Processing Row Number 4800 out of 83274 ---------\n",
      "-------- Processing Row Number 4900 out of 83274 ---------\n",
      "-------- Processing Row Number 5000 out of 83274 ---------\n",
      "---- Round 5000 Save to CSV file\n",
      "-------- Processing Row Number 5100 out of 83274 ---------\n",
      "-------- Processing Row Number 5200 out of 83274 ---------\n",
      "-------- Processing Row Number 5300 out of 83274 ---------\n",
      "-------- Processing Row Number 5400 out of 83274 ---------\n",
      "-------- Processing Row Number 5500 out of 83274 ---------\n",
      "-------- Processing Row Number 5600 out of 83274 ---------\n",
      "-------- Processing Row Number 5700 out of 83274 ---------\n",
      "-------- Processing Row Number 5800 out of 83274 ---------\n",
      "-------- Processing Row Number 5900 out of 83274 ---------\n",
      "-------- Processing Row Number 6000 out of 83274 ---------\n",
      "---- Round 6000 Save to CSV file\n",
      "-------- Processing Row Number 6100 out of 83274 ---------\n",
      "-------- Processing Row Number 6200 out of 83274 ---------\n",
      "-------- Processing Row Number 6300 out of 83274 ---------\n",
      "-------- Processing Row Number 6400 out of 83274 ---------\n",
      "-------- Processing Row Number 6500 out of 83274 ---------\n",
      "-------- Processing Row Number 6600 out of 83274 ---------\n",
      "-------- Processing Row Number 6700 out of 83274 ---------\n",
      "-------- Processing Row Number 6800 out of 83274 ---------\n",
      "-------- Processing Row Number 6900 out of 83274 ---------\n",
      "-------- Processing Row Number 7000 out of 83274 ---------\n",
      "---- Round 7000 Save to CSV file\n",
      "-------- Processing Row Number 7100 out of 83274 ---------\n",
      "-------- Processing Row Number 7200 out of 83274 ---------\n",
      "-------- Processing Row Number 7300 out of 83274 ---------\n",
      "-------- Processing Row Number 7400 out of 83274 ---------\n",
      "-------- Processing Row Number 7500 out of 83274 ---------\n",
      "-------- Processing Row Number 7600 out of 83274 ---------\n",
      "-------- Processing Row Number 7700 out of 83274 ---------\n",
      "-------- Processing Row Number 7800 out of 83274 ---------\n",
      "-------- Processing Row Number 7900 out of 83274 ---------\n",
      "-------- Processing Row Number 8000 out of 83274 ---------\n",
      "---- Round 8000 Save to CSV file\n",
      "-------- Processing Row Number 8100 out of 83274 ---------\n",
      "-------- Processing Row Number 8200 out of 83274 ---------\n",
      "-------- Processing Row Number 8300 out of 83274 ---------\n",
      "-------- Processing Row Number 8400 out of 83274 ---------\n",
      "-------- Processing Row Number 8500 out of 83274 ---------\n",
      "-------- Processing Row Number 8600 out of 83274 ---------\n",
      "-------- Processing Row Number 8700 out of 83274 ---------\n",
      "-------- Processing Row Number 8800 out of 83274 ---------\n",
      "-------- Processing Row Number 8900 out of 83274 ---------\n",
      "-------- Processing Row Number 9000 out of 83274 ---------\n",
      "---- Round 9000 Save to CSV file\n",
      "-------- Processing Row Number 9100 out of 83274 ---------\n",
      "-------- Processing Row Number 9200 out of 83274 ---------\n",
      "-------- Processing Row Number 9300 out of 83274 ---------\n",
      "-------- Processing Row Number 9400 out of 83274 ---------\n",
      "-------- Processing Row Number 9500 out of 83274 ---------\n",
      "-------- Processing Row Number 9600 out of 83274 ---------\n",
      "-------- Processing Row Number 9700 out of 83274 ---------\n",
      "-------- Processing Row Number 9800 out of 83274 ---------\n",
      "-------- Processing Row Number 9900 out of 83274 ---------\n",
      "-------- Processing Row Number 10000 out of 83274 ---------\n",
      "---- Round 10000 Save to CSV file\n",
      "-------- Processing Row Number 10100 out of 83274 ---------\n",
      "-------- Processing Row Number 10200 out of 83274 ---------\n",
      "-------- Processing Row Number 10300 out of 83274 ---------\n",
      "-------- Processing Row Number 10400 out of 83274 ---------\n",
      "-------- Processing Row Number 10500 out of 83274 ---------\n",
      "-------- Processing Row Number 10600 out of 83274 ---------\n",
      "-------- Processing Row Number 10700 out of 83274 ---------\n",
      "-------- Processing Row Number 10800 out of 83274 ---------\n",
      "-------- Processing Row Number 10900 out of 83274 ---------\n",
      "-------- Processing Row Number 11000 out of 83274 ---------\n",
      "---- Round 11000 Save to CSV file\n",
      "-------- Processing Row Number 11100 out of 83274 ---------\n",
      "-------- Processing Row Number 11200 out of 83274 ---------\n",
      "-------- Processing Row Number 11300 out of 83274 ---------\n",
      "-------- Processing Row Number 11400 out of 83274 ---------\n",
      "-------- Processing Row Number 11500 out of 83274 ---------\n",
      "-------- Processing Row Number 11600 out of 83274 ---------\n",
      "-------- Processing Row Number 11700 out of 83274 ---------\n",
      "-------- Processing Row Number 11800 out of 83274 ---------\n",
      "-------- Processing Row Number 11900 out of 83274 ---------\n",
      "-------- Processing Row Number 12000 out of 83274 ---------\n",
      "---- Round 12000 Save to CSV file\n",
      "-------- Processing Row Number 12100 out of 83274 ---------\n",
      "-------- Processing Row Number 12200 out of 83274 ---------\n",
      "-------- Processing Row Number 12300 out of 83274 ---------\n",
      "-------- Processing Row Number 12400 out of 83274 ---------\n",
      "-------- Processing Row Number 12500 out of 83274 ---------\n",
      "-------- Processing Row Number 12600 out of 83274 ---------\n",
      "-------- Processing Row Number 12700 out of 83274 ---------\n",
      "-------- Processing Row Number 12800 out of 83274 ---------\n",
      "-------- Processing Row Number 12900 out of 83274 ---------\n",
      "-------- Processing Row Number 13000 out of 83274 ---------\n",
      "---- Round 13000 Save to CSV file\n",
      "-------- Processing Row Number 13100 out of 83274 ---------\n",
      "-------- Processing Row Number 13200 out of 83274 ---------\n",
      "-------- Processing Row Number 13300 out of 83274 ---------\n",
      "-------- Processing Row Number 13400 out of 83274 ---------\n",
      "-------- Processing Row Number 13500 out of 83274 ---------\n",
      "-------- Processing Row Number 13600 out of 83274 ---------\n",
      "-------- Processing Row Number 13700 out of 83274 ---------\n",
      "-------- Processing Row Number 13800 out of 83274 ---------\n",
      "-------- Processing Row Number 13900 out of 83274 ---------\n",
      "-------- Processing Row Number 14000 out of 83274 ---------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Round 14000 Save to CSV file\n",
      "-------- Processing Row Number 14100 out of 83274 ---------\n",
      "-------- Processing Row Number 14200 out of 83274 ---------\n",
      "-------- Processing Row Number 14300 out of 83274 ---------\n",
      "-------- Processing Row Number 14400 out of 83274 ---------\n",
      "-------- Processing Row Number 14500 out of 83274 ---------\n",
      "-------- Processing Row Number 14600 out of 83274 ---------\n",
      "-------- Processing Row Number 14700 out of 83274 ---------\n",
      "-------- Processing Row Number 14800 out of 83274 ---------\n",
      "-------- Processing Row Number 14900 out of 83274 ---------\n",
      "-------- Processing Row Number 15000 out of 83274 ---------\n",
      "---- Round 15000 Save to CSV file\n",
      "-------- Processing Row Number 15100 out of 83274 ---------\n",
      "-------- Processing Row Number 15200 out of 83274 ---------\n",
      "-------- Processing Row Number 15300 out of 83274 ---------\n",
      "-------- Processing Row Number 15400 out of 83274 ---------\n",
      "-------- Processing Row Number 15500 out of 83274 ---------\n",
      "-------- Processing Row Number 15600 out of 83274 ---------\n",
      "-------- Processing Row Number 15700 out of 83274 ---------\n",
      "-------- Processing Row Number 15800 out of 83274 ---------\n",
      "-------- Processing Row Number 15900 out of 83274 ---------\n",
      "-------- Processing Row Number 16000 out of 83274 ---------\n",
      "---- Round 16000 Save to CSV file\n",
      "-------- Processing Row Number 16100 out of 83274 ---------\n",
      "-------- Processing Row Number 16200 out of 83274 ---------\n",
      "-------- Processing Row Number 16300 out of 83274 ---------\n",
      "-------- Processing Row Number 16400 out of 83274 ---------\n",
      "-------- Processing Row Number 16500 out of 83274 ---------\n",
      "-------- Processing Row Number 16600 out of 83274 ---------\n",
      "-------- Processing Row Number 16700 out of 83274 ---------\n",
      "-------- Processing Row Number 16800 out of 83274 ---------\n",
      "-------- Processing Row Number 16900 out of 83274 ---------\n",
      "-------- Processing Row Number 17000 out of 83274 ---------\n",
      "---- Round 17000 Save to CSV file\n",
      "-------- Processing Row Number 17100 out of 83274 ---------\n",
      "-------- Processing Row Number 17200 out of 83274 ---------\n",
      "-------- Processing Row Number 17300 out of 83274 ---------\n",
      "-------- Processing Row Number 17400 out of 83274 ---------\n",
      "-------- Processing Row Number 17500 out of 83274 ---------\n",
      "-------- Processing Row Number 17600 out of 83274 ---------\n",
      "-------- Processing Row Number 17700 out of 83274 ---------\n",
      "-------- Processing Row Number 17800 out of 83274 ---------\n",
      "-------- Processing Row Number 17900 out of 83274 ---------\n",
      "-------- Processing Row Number 18000 out of 83274 ---------\n",
      "---- Round 18000 Save to CSV file\n",
      "-------- Processing Row Number 18100 out of 83274 ---------\n",
      "-------- Processing Row Number 18200 out of 83274 ---------\n",
      "-------- Processing Row Number 18300 out of 83274 ---------\n",
      "-------- Processing Row Number 18400 out of 83274 ---------\n",
      "-------- Processing Row Number 18500 out of 83274 ---------\n",
      "-------- Processing Row Number 18600 out of 83274 ---------\n",
      "-------- Processing Row Number 18700 out of 83274 ---------\n",
      "-------- Processing Row Number 18800 out of 83274 ---------\n",
      "-------- Processing Row Number 18900 out of 83274 ---------\n",
      "-------- Processing Row Number 19000 out of 83274 ---------\n",
      "---- Round 19000 Save to CSV file\n",
      "-------- Processing Row Number 19100 out of 83274 ---------\n",
      "-------- Processing Row Number 19200 out of 83274 ---------\n",
      "-------- Processing Row Number 19300 out of 83274 ---------\n",
      "-------- Processing Row Number 19400 out of 83274 ---------\n",
      "-------- Processing Row Number 19500 out of 83274 ---------\n",
      "-------- Processing Row Number 19600 out of 83274 ---------\n",
      "-------- Processing Row Number 19700 out of 83274 ---------\n",
      "-------- Processing Row Number 19800 out of 83274 ---------\n",
      "-------- Processing Row Number 19900 out of 83274 ---------\n",
      "-------- Processing Row Number 20000 out of 83274 ---------\n",
      "---- Round 20000 Save to CSV file\n",
      "-------- Processing Row Number 20100 out of 83274 ---------\n",
      "-------- Processing Row Number 20200 out of 83274 ---------\n",
      "-------- Processing Row Number 20300 out of 83274 ---------\n",
      "-------- Processing Row Number 20400 out of 83274 ---------\n",
      "-------- Processing Row Number 20500 out of 83274 ---------\n",
      "-------- Processing Row Number 20600 out of 83274 ---------\n",
      "-------- Processing Row Number 20700 out of 83274 ---------\n",
      "-------- Processing Row Number 20800 out of 83274 ---------\n",
      "-------- Processing Row Number 20900 out of 83274 ---------\n",
      "-------- Processing Row Number 21000 out of 83274 ---------\n",
      "---- Round 21000 Save to CSV file\n",
      "-------- Processing Row Number 21100 out of 83274 ---------\n",
      "-------- Processing Row Number 21200 out of 83274 ---------\n",
      "-------- Processing Row Number 21300 out of 83274 ---------\n",
      "-------- Processing Row Number 21400 out of 83274 ---------\n",
      "-------- Processing Row Number 21500 out of 83274 ---------\n",
      "-------- Processing Row Number 21600 out of 83274 ---------\n",
      "-------- Processing Row Number 21700 out of 83274 ---------\n",
      "-------- Processing Row Number 21800 out of 83274 ---------\n",
      "-------- Processing Row Number 21900 out of 83274 ---------\n",
      "-------- Processing Row Number 22000 out of 83274 ---------\n",
      "---- Round 22000 Save to CSV file\n",
      "-------- Processing Row Number 22100 out of 83274 ---------\n",
      "-------- Processing Row Number 22200 out of 83274 ---------\n",
      "-------- Processing Row Number 22300 out of 83274 ---------\n",
      "-------- Processing Row Number 22400 out of 83274 ---------\n",
      "-------- Processing Row Number 22500 out of 83274 ---------\n",
      "-------- Processing Row Number 22600 out of 83274 ---------\n",
      "-------- Processing Row Number 22700 out of 83274 ---------\n",
      "-------- Processing Row Number 22800 out of 83274 ---------\n",
      "-------- Processing Row Number 22900 out of 83274 ---------\n",
      "-------- Processing Row Number 23000 out of 83274 ---------\n",
      "---- Round 23000 Save to CSV file\n",
      "-------- Processing Row Number 23100 out of 83274 ---------\n",
      "-------- Processing Row Number 23200 out of 83274 ---------\n",
      "-------- Processing Row Number 23300 out of 83274 ---------\n",
      "-------- Processing Row Number 23400 out of 83274 ---------\n",
      "-------- Processing Row Number 23500 out of 83274 ---------\n",
      "-------- Processing Row Number 23600 out of 83274 ---------\n",
      "-------- Processing Row Number 23700 out of 83274 ---------\n",
      "-------- Processing Row Number 23800 out of 83274 ---------\n",
      "-------- Processing Row Number 23900 out of 83274 ---------\n",
      "-------- Processing Row Number 24000 out of 83274 ---------\n",
      "---- Round 24000 Save to CSV file\n",
      "-------- Processing Row Number 24100 out of 83274 ---------\n",
      "-------- Processing Row Number 24200 out of 83274 ---------\n",
      "-------- Processing Row Number 24300 out of 83274 ---------\n",
      "-------- Processing Row Number 24400 out of 83274 ---------\n",
      "-------- Processing Row Number 24500 out of 83274 ---------\n",
      "-------- Processing Row Number 24600 out of 83274 ---------\n",
      "-------- Processing Row Number 24700 out of 83274 ---------\n",
      "-------- Processing Row Number 24800 out of 83274 ---------\n",
      "-------- Processing Row Number 24900 out of 83274 ---------\n",
      "-------- Processing Row Number 25000 out of 83274 ---------\n",
      "---- Round 25000 Save to CSV file\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-5513d30ae905>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[0mprev_year\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_year\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                 \u001b[0mswe_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SWE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_days\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m                 \u001b[1;31m# flip over yaxis as lats are in a descending order --> need to change to ascending order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0mswe_data_flip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswe_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads\\anaconda3\\envs\\python37\\lib\\site-packages\\h5py\\_hl\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         \u001b[1;31m# Patch up the output for NumPy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m     \u001b[1;31m# Single-field recarray convention\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# gage = pd.read_csv('../gage_swe.csv')\n",
    "date_format = \"%Y-%m-%d\"\n",
    "sur = 20\n",
    "index_list = []\n",
    "\n",
    "### Run through all data\n",
    "for ii,row_num in enumerate(range(len(gage))):\n",
    "    \n",
    "    ### Start from row xx\n",
    "    if ii >=0:\n",
    "    \n",
    "        if ii % 100 == 0:\n",
    "            print(f'-------- Processing Row Number {ii} out of {len(gage)} ---------')\n",
    "        # Start with each row\n",
    "        row_data = gage.iloc[row_num,:]\n",
    "        row_time = row_data['time']\n",
    "\n",
    "        if 1984 < int(row_time[0:4]) <2017  : # SWE has only data files from 1984 - 2016\n",
    "            \n",
    "            ### Obtain Value of Interested Region\n",
    "            lon_idx,lat_idx = index_finder(row_data['lon'],row_data['lat'])\n",
    "            lon_idx,lat_idx = int(lon_idx),int(lat_idx)\n",
    "            \n",
    "            if (lon_idx,lat_idx) not in index_list:\n",
    "\n",
    "                ### Extract Date from Gage Data to match SWE\n",
    "                d_date = datetime.strptime(row_time, date_format)\n",
    "\n",
    "                # Extract year of date\n",
    "                d_year = d_date.year\n",
    "                # Extract number of days from SWE Data\n",
    "                num_days = d_date- datetime.strptime('{}-1-1'.format(d_year),date_format)\n",
    "                num_days = num_days.days\n",
    "\n",
    "                ## Obtain swe data\n",
    "                # if year of previous row does not match year of current row. Then Read Data\n",
    "                if prev_year != d_year: \n",
    "                    swe = h5py.File(f'SN_SWE_WY{d_year}.h5', 'r')\n",
    "                    lat = swe['lat'][0][::-1]\n",
    "                    lon = swe['lon'][:,0]\n",
    "                    lats,lons = np.meshgrid(lat,lon)\n",
    "                prev_year = d_year\n",
    "\n",
    "                swe_data = swe['SWE'][num_days]\n",
    "                # flip over yaxis as lats are in a descending order --> need to change to ascending order\n",
    "                swe_data_flip = swe_data[:,::-1]\n",
    "\n",
    "                # get SWE values of surrounding region\n",
    "                region = swe_data_flip[lon_idx-sur:lon_idx+sur,lat_idx-sur:lat_idx+sur]\n",
    "\n",
    "                # change -32768 (null values) to null\n",
    "                region=region.astype('float')\n",
    "                region[region == -32768] = np.nan\n",
    "                region_avg = np.nanmean(region)\n",
    "\n",
    "\n",
    "                if pd.isna(region_avg): # if region_avg is null, change to -2\n",
    "                    gage.iloc[row_num,6] = -2\n",
    "                    index_list.append((lon_idx,lat_idx))\n",
    "                else: # region avg is not null, assign the value with average\n",
    "                    gage.iloc[row_num,6] = region_avg\n",
    "            else: # (lon_idx,lat_idx) in index_list\n",
    "                gage.iloc[row_num,6] = -2\n",
    "    \n",
    "        if ii % 1000 == 0:\n",
    "            gage.to_csv('../gage_swe_1010.csv',index=False)\n",
    "            print(f'---- Round {ii} Save to CSV file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save gage file to csv\n",
    "gage.to_csv('../gage_swe.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.000    2615\n",
       "-1.000     638\n",
       " 1.000       9\n",
       " 0.500       3\n",
       " 0.625       2\n",
       " 0.750       2\n",
       " 1.250       1\n",
       " 1.750       1\n",
       " 1.500       1\n",
       " 4.250       1\n",
       " 0.875       1\n",
       "Name: swe, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gage.iloc[80000:,6].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "## SWE value indication\n",
    "Initial Assigned Value: -1\n",
    "N/A value: -2\n",
    "Rest are normal values\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11672"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gage['swe'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75329701-f875-47a7-be53-359b0e2a5db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read Gage Lat Lon Data\n",
    "# tar_gage = pd.read_csv('target_gages.csv')\n",
    "# tar_gage\n",
    "\n",
    "# # ----------- Finish For Loop -----------\n",
    "# # Convert to DataFrame\n",
    "# re = pd.DataFrame(region)\n",
    "# # re.index = lon[ll_lon_idx:tr_lon_idx]\n",
    "# # re.columns = lat[ll_lat_idx:tr_lat_idx]\n",
    "# print(re)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
